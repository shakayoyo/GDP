{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826a1b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.21\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Apr 30 20:24:04 UTC 2025\n",
      "CPU Count:          128\n",
      "Pytorch Version:    2.6.0+cu124\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       738.47 GB / 755.32 GB (97.8%)\n",
      "Disk Space Avail:   835890.29 GB / 931322.58 GB (89.8%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t4 unique label values:  [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "\n",
      "AutoMM starts to create your model. ✨✨✨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /users/1/tianx/GDP/GDP/outputs/ag_models\n",
      "    ```\n",
      "\n",
      "[rank: 0] Seed set to 555\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "GPU 0 Name: NVIDIA L40S\n",
      "GPU 0 Memory: 0.47GB/44.99GB (Used/Total)\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA L40S') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 11.2 M | train\n",
      "1 | validation_metric | MulticlassAccuracy              | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss                | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.714    Total estimated model params size (MB)\n",
      "101       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Epoch 0:  50%|█████████████████                 | 40/80 [00:00<00:00, 61.00it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 197.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 199.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 73.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.00it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.19it/s]\u001b[A\n",
      "Epoch 0:  50%|█████████████████                 | 40/80 [00:00<00:00, 41.02it/s]Epoch 0, global step 2: 'val_accuracy' reached 0.16875 (best 0.16875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=0-step=2.ckpt' as top 3\n",
      "Epoch 0: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 39.14it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 243.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 209.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.83it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.01it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 34.03it/s]Epoch 0, global step 5: 'val_accuracy' reached 0.15000 (best 0.16875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=0-step=5.ckpt' as top 3\n",
      "Epoch 1:  50%|█████████████████                 | 40/80 [00:00<00:00, 69.57it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 244.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 209.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 80.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 94.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 72.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 81.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 69.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 76.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 69.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 71.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 71.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 74.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 68.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 71.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 68.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 71.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 69.07it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 71.48it/s]\u001b[A\n",
      "Epoch 1:  50%|█████████████████                 | 40/80 [00:00<00:00, 44.57it/s]Epoch 1, global step 7: 'val_accuracy' reached 0.18125 (best 0.18125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=1-step=7.ckpt' as top 3\n",
      "Epoch 1: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 36.29it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 243.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 178.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 80.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 93.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.05it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 31.74it/s]Epoch 1, global step 10: 'val_accuracy' was not in top 3\n",
      "Epoch 2:  50%|█████████████████                 | 40/80 [00:00<00:00, 68.51it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 247.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 210.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 89.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 81.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 82.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.93it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.68it/s]\u001b[A\n",
      "Epoch 2:  50%|█████████████████                 | 40/80 [00:00<00:00, 44.83it/s]Epoch 2, global step 12: 'val_accuracy' reached 0.15625 (best 0.18125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=2-step=12.ckpt' as top 3\n",
      "Epoch 2: 100%|██████████████████████████████████| 80/80 [00:01<00:00, 41.53it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 251.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 212.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 81.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 76.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.28it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 35.78it/s]Epoch 2, global step 15: 'val_accuracy' reached 0.18750 (best 0.18750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=2-step=15.ckpt' as top 3\n",
      "Epoch 3:  50%|█████████████████                 | 40/80 [00:00<00:00, 65.96it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 241.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 209.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 83.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 96.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.64it/s]\u001b[A\n",
      "Epoch 3:  50%|█████████████████                 | 40/80 [00:00<00:00, 43.64it/s]Epoch 3, global step 17: 'val_accuracy' reached 0.19375 (best 0.19375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=3-step=17.ckpt' as top 3\n",
      "Epoch 3: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 36.66it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 252.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 213.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 98.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 78.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 87.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 77.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 75.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 73.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.72it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.83it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 31.88it/s]Epoch 3, global step 20: 'val_accuracy' reached 0.21875 (best 0.21875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=3-step=20.ckpt' as top 3\n",
      "Epoch 4:  50%|█████████████████                 | 40/80 [00:00<00:00, 68.62it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 243.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 199.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 80.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 93.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 75.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 80.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 81.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 80.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.44it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.54it/s]\u001b[A\n",
      "Epoch 4:  50%|█████████████████                 | 40/80 [00:00<00:00, 45.13it/s]Epoch 4, global step 22: 'val_accuracy' reached 0.20625 (best 0.21875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=4-step=22.ckpt' as top 3\n",
      "Epoch 4: 100%|██████████████████████████████████| 80/80 [00:01<00:00, 41.65it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 251.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 213.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 97.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.57it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.54it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 35.95it/s]Epoch 4, global step 25: 'val_accuracy' reached 0.21875 (best 0.21875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=4-step=25.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  50%|█████████████████                 | 40/80 [00:00<00:00, 69.92it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 247.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 211.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 80.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 93.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 75.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 73.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 77.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 73.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 71.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 73.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 72.54it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.80it/s]\u001b[A\n",
      "Epoch 5:  50%|█████████████████                 | 40/80 [00:00<00:00, 45.55it/s]Epoch 5, global step 27: 'val_accuracy' reached 0.21250 (best 0.21875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=5-step=27.ckpt' as top 3\n",
      "Epoch 5: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 37.81it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 250.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 211.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 87.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 77.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 77.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.44it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.30it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 32.99it/s]Epoch 5, global step 30: 'val_accuracy' reached 0.25000 (best 0.25000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=5-step=30.ckpt' as top 3\n",
      "Epoch 6:  50%|█████████████████                 | 40/80 [00:00<00:00, 69.81it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 253.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 219.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 80.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 94.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 69.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 72.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 73.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 70.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 73.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 70.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 73.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 71.53it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 73.93it/s]\u001b[A\n",
      "Epoch 6:  50%|█████████████████                 | 40/80 [00:00<00:00, 45.31it/s]Epoch 6, global step 32: 'val_accuracy' was not in top 3\n",
      "Epoch 6: 100%|██████████████████████████████████| 80/80 [00:01<00:00, 48.46it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 249.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 189.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 85.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 74.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 73.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 75.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 73.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 72.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.09it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████████████████████████████| 80/80 [00:01<00:00, 40.86it/s]Epoch 6, global step 35: 'val_accuracy' reached 0.29375 (best 0.29375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=6-step=35.ckpt' as top 3\n",
      "Epoch 7:  50%|█████████████████                 | 40/80 [00:00<00:00, 71.73it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 246.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 201.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 98.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.20it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.75it/s]\u001b[A\n",
      "Epoch 7:  50%|█████████████████                 | 40/80 [00:00<00:00, 46.31it/s]Epoch 7, global step 37: 'val_accuracy' reached 0.26250 (best 0.29375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=7-step=37.ckpt' as top 3\n",
      "Epoch 7: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 37.03it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 167.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 171.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.36it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.71it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 32.28it/s]\u001b[AEpoch 7, global step 40: 'val_accuracy' reached 0.30625 (best 0.30625), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=7-step=40.ckpt' as top 3\n",
      "Epoch 8:  50%|█████████████████                 | 40/80 [00:00<00:00, 69.58it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 250.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 209.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.58it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.07it/s]\u001b[A\n",
      "Epoch 8:  50%|█████████████████                 | 40/80 [00:00<00:00, 45.44it/s]Epoch 8, global step 42: 'val_accuracy' reached 0.34375 (best 0.34375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=8-step=42.ckpt' as top 3\n",
      "Epoch 8: 100%|██████████████████████████████████| 80/80 [00:01<00:00, 42.00it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 251.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 217.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 81.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 95.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 82.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 73.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 76.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 77.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 75.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 77.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 75.68it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.28it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 36.26it/s]Epoch 8, global step 45: 'val_accuracy' reached 0.32500 (best 0.34375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=8-step=45.ckpt' as top 3\n",
      "Epoch 9:  50%|█████████████████                 | 40/80 [00:00<00:00, 71.15it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 242.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 199.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 70.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 75.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 72.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 76.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 76.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 75.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 76.42it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.17it/s]\u001b[A\n",
      "Epoch 9:  50%|█████████████████                 | 40/80 [00:00<00:00, 45.77it/s]Epoch 9, global step 47: 'val_accuracy' reached 0.36250 (best 0.36250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=9-step=47.ckpt' as top 3\n",
      "Epoch 9: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 37.17it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 280.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 233.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 76.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 85.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 68.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 75.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 70.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 73.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 77.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 72.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.41it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████████████████████████████| 80/80 [00:02<00:00, 32.46it/s]Epoch 9, global step 50: 'val_accuracy' reached 0.37500 (best 0.37500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=9-step=50.ckpt' as top 3\n",
      "Epoch 10:  50%|████████████████▌                | 40/80 [00:00<00:00, 67.19it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 193.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 167.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 75.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 90.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 70.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 79.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 71.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 77.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 70.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 75.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 72.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 76.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 73.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 71.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 73.00it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.72it/s]\u001b[A\n",
      "Epoch 10:  50%|████████████████▌                | 40/80 [00:00<00:00, 43.70it/s]Epoch 10, global step 52: 'val_accuracy' reached 0.42500 (best 0.42500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=10-step=52.ckpt' as top 3\n",
      "Epoch 10: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.12it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 226.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 204.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 71.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 83.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 71.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 79.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 72.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 77.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 72.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 77.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 75.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 78.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 73.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 74.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.93it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 74.24it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 30.88it/s]Epoch 10, global step 55: 'val_accuracy' reached 0.46875 (best 0.46875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=10-step=55.ckpt' as top 3\n",
      "Epoch 11:  50%|████████████████▌                | 40/80 [00:00<00:00, 61.50it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 216.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 181.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 74.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 77.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 76.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 81.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 78.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 78.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 76.99it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.23it/s]\u001b[A\n",
      "Epoch 11:  50%|████████████████▌                | 40/80 [00:00<00:00, 42.13it/s]Epoch 11, global step 57: 'val_accuracy' reached 0.49375 (best 0.49375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=11-step=57.ckpt' as top 3\n",
      "Epoch 11: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.35it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 227.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 203.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 76.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 90.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 73.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 81.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 81.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 81.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 78.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.40it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.62it/s]\u001b[A\n",
      "Epoch 11: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.25it/s]Epoch 11, global step 60: 'val_accuracy' reached 0.53125 (best 0.53125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=11-step=60.ckpt' as top 3\n",
      "Epoch 12:  50%|████████████████▌                | 40/80 [00:00<00:00, 64.81it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 214.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 198.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 82.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 92.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 67.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 73.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 70.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 72.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 76.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 74.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 73.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 77.42it/s]\u001b[A\n",
      "Epoch 12:  50%|████████████████▌                | 40/80 [00:00<00:00, 43.66it/s]Epoch 12, global step 62: 'val_accuracy' reached 0.56875 (best 0.56875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=12-step=62.ckpt' as top 3\n",
      "Epoch 12: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 36.15it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 220.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 160.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 78.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 92.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 83.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 78.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.30it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.76it/s]\u001b[A\n",
      "Epoch 12: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.88it/s]Epoch 12, global step 65: 'val_accuracy' reached 0.57500 (best 0.57500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=12-step=65.ckpt' as top 3\n",
      "Epoch 13:  50%|████████████████▌                | 40/80 [00:00<00:00, 65.76it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 217.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 202.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 73.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 81.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 83.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.31it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.43it/s]\u001b[A\n",
      "Epoch 13:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.50it/s]Epoch 13, global step 67: 'val_accuracy' reached 0.56250 (best 0.57500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=13-step=67.ckpt' as top 3\n",
      "Epoch 13: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 32.24it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 229.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 175.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 75.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 88.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 71.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 78.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 81.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.69it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.18it/s]\u001b[A\n",
      "Epoch 13: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 28.80it/s]Epoch 13, global step 70: 'val_accuracy' reached 0.60000 (best 0.60000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=13-step=70.ckpt' as top 3\n",
      "Epoch 14:  50%|████████████████▌                | 40/80 [00:00<00:00, 66.14it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 220.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 199.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 77.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 90.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 70.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 78.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 71.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 77.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 69.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 74.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 76.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 74.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.18it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.67it/s]\u001b[A\n",
      "Epoch 14:  50%|████████████████▌                | 40/80 [00:00<00:00, 43.97it/s]Epoch 14, global step 72: 'val_accuracy' reached 0.60625 (best 0.60625), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=14-step=72.ckpt' as top 3\n",
      "Epoch 14: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 41.57it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 221.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 204.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 79.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 93.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 73.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 82.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 74.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 78.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.83it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.23it/s]\u001b[A\n",
      "Epoch 14: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 36.08it/s]Epoch 14, global step 75: 'val_accuracy' reached 0.62500 (best 0.62500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=14-step=75.ckpt' as top 3\n",
      "Epoch 15:  50%|████████████████▌                | 40/80 [00:00<00:00, 68.55it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 222.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 173.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 103.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 76.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 85.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 85.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 85.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 82.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 82.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.31it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 82.88it/s]\u001b[A\n",
      "Epoch 15:  50%|████████████████▌                | 40/80 [00:00<00:00, 46.02it/s]Epoch 15, global step 77: 'val_accuracy' reached 0.60625 (best 0.62500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=15-step=77.ckpt' as top 3\n",
      "Epoch 15: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 37.20it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 227.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 202.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 74.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 85.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 66.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 74.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 66.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 70.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 69.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 73.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 72.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 76.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 73.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.95it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 77.15it/s]\u001b[A\n",
      "Epoch 15: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 32.48it/s]Epoch 15, global step 80: 'val_accuracy' reached 0.67500 (best 0.67500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=15-step=80.ckpt' as top 3\n",
      "Epoch 16:  50%|████████████████▌                | 40/80 [00:00<00:00, 65.04it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 215.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 185.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 98.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 81.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.66it/s]\u001b[A\n",
      "Epoch 16:  50%|████████████████▌                | 40/80 [00:00<00:00, 43.96it/s]Epoch 16, global step 82: 'val_accuracy' reached 0.68750 (best 0.68750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=16-step=82.ckpt' as top 3\n",
      "Epoch 16: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 40.12it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 216.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 195.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 74.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 83.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 65.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 72.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 65.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 71.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 66.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 70.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 70.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 74.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 72.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 71.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 71.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 72.61it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.06it/s]\u001b[A\n",
      "Epoch 16: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 34.74it/s]Epoch 16, global step 85: 'val_accuracy' reached 0.68750 (best 0.68750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=16-step=85.ckpt' as top 3\n",
      "Epoch 17:  50%|████████████████▌                | 40/80 [00:00<00:00, 64.94it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 218.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 192.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 82.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.64it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.83it/s]\u001b[A\n",
      "Epoch 17:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.17it/s]Epoch 17, global step 87: 'val_accuracy' was not in top 3\n",
      "Epoch 17: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 39.62it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 230.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 207.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 97.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 72.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 80.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 72.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 73.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 76.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 77.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 80.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 75.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 78.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.08it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.60it/s]\u001b[A\n",
      "Epoch 17: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 34.43it/s]Epoch 17, global step 90: 'val_accuracy' reached 0.71250 (best 0.71250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=17-step=90.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  50%|████████████████▌                | 40/80 [00:00<00:00, 67.41it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 248.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 223.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 79.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 93.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 67.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 75.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 66.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 71.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 63.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 68.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 67.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 70.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 66.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 69.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 63.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 65.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 63.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 66.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 64.82it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 67.15it/s]\u001b[A\n",
      "Epoch 18:  50%|████████████████▌                | 40/80 [00:00<00:00, 42.77it/s]Epoch 18, global step 92: 'val_accuracy' reached 0.70000 (best 0.71250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=18-step=92.ckpt' as top 3\n",
      "Epoch 18: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 39.10it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 205.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 189.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 72.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 85.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 69.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 78.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 66.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 72.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 63.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 68.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 67.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 70.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 68.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 71.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 66.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 69.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 66.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 69.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 67.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 70.14it/s]\u001b[A\n",
      "Epoch 18: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 33.70it/s]Epoch 18, global step 95: 'val_accuracy' reached 0.69375 (best 0.71250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=18-step=95.ckpt' as top 3\n",
      "Epoch 19:  50%|████████████████▌                | 40/80 [00:00<00:00, 66.17it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 262.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 228.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 93.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 108.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 78.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 78.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.97it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 78.46it/s]\u001b[A\n",
      "Epoch 19:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.44it/s]Epoch 19, global step 97: 'val_accuracy' reached 0.71875 (best 0.71875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=19-step=97.ckpt' as top 3\n",
      "Epoch 19: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.70it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 176.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 172.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 83.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.98it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.44it/s]\u001b[A\n",
      "Epoch 19: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.55it/s]Epoch 19, global step 100: 'val_accuracy' was not in top 3\n",
      "Epoch 20:  50%|████████████████▌                | 40/80 [00:00<00:00, 67.47it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 267.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 170.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 91.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 106.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.30it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.17it/s]\u001b[A\n",
      "Epoch 20:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.09it/s]Epoch 20, global step 102: 'val_accuracy' reached 0.72500 (best 0.72500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=20-step=102.ckpt' as top 3\n",
      "Epoch 20: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 32.74it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 281.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 235.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 91.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 106.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.45it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.55it/s]\u001b[A\n",
      "Epoch 20: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 29.27it/s]Epoch 20, global step 105: 'val_accuracy' reached 0.73125 (best 0.73125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=20-step=105.ckpt' as top 3\n",
      "Epoch 21:  50%|████████████████▌                | 40/80 [00:00<00:00, 66.63it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 249.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 217.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 78.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 87.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 83.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.16it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.47it/s]\u001b[A\n",
      "Epoch 21:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.78it/s]Epoch 21, global step 107: 'val_accuracy' reached 0.75000 (best 0.75000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=21-step=107.ckpt' as top 3\n",
      "Epoch 21: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 30.18it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 250.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 216.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 78.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 87.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 83.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.17it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.49it/s]\u001b[A\n",
      "Epoch 21: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 27.15it/s]Epoch 21, global step 110: 'val_accuracy' reached 0.76250 (best 0.76250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=21-step=110.ckpt' as top 3\n",
      "Epoch 22:  50%|████████████████▌                | 40/80 [00:00<00:00, 67.24it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 154.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 172.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 89.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 104.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 82.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.57it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.80it/s]\u001b[A\n",
      "Epoch 22:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.51it/s]Epoch 22, global step 112: 'val_accuracy' reached 0.76875 (best 0.76875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=22-step=112.ckpt' as top 3\n",
      "Epoch 22: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 41.00it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 271.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 207.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 89.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 104.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 82.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.72it/s]\u001b[A\n",
      "Epoch 22: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.70it/s]Epoch 22, global step 115: 'val_accuracy' reached 0.78125 (best 0.78125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=22-step=115.ckpt' as top 3\n",
      "Epoch 23:  50%|████████████████▌                | 40/80 [00:00<00:00, 66.68it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 199.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 178.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 79.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 80.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 78.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.36it/s]\u001b[A\n",
      "Epoch 23:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.29it/s]Epoch 23, global step 117: 'val_accuracy' was not in top 3\n",
      "Epoch 23: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 41.51it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 246.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 213.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 84.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.21it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.77it/s]\u001b[A\n",
      "Epoch 23: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.98it/s]Epoch 23, global step 120: 'val_accuracy' reached 0.78125 (best 0.78125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=23-step=120.ckpt' as top 3\n",
      "Epoch 24:  50%|████████████████▌                | 40/80 [00:00<00:00, 70.08it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 170.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 147.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 82.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 91.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 80.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 79.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.28it/s]\u001b[A\n",
      "Epoch 24:  50%|████████████████▌                | 40/80 [00:00<00:00, 46.43it/s]Epoch 24, global step 122: 'val_accuracy' was not in top 3\n",
      "Epoch 24: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 48.09it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 222.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 203.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 78.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 77.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 77.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.42it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.96it/s]\u001b[A\n",
      "Epoch 24: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 40.68it/s]Epoch 24, global step 125: 'val_accuracy' reached 0.78750 (best 0.78750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=24-step=125.ckpt' as top 3\n",
      "Epoch 25:  50%|████████████████▌                | 40/80 [00:00<00:00, 68.08it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 208.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 196.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.88it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 78.83it/s]\u001b[A\n",
      "Epoch 25:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.25it/s]Epoch 25, global step 127: 'val_accuracy' reached 0.78750 (best 0.78750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=25-step=127.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.78it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 144.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 161.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 98.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 112.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 84.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 93.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 81.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 87.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 80.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 85.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 82.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 86.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 83.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 80.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 80.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 81.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 81.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 81.48it/s]\u001b[A\n",
      "Epoch 25: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.57it/s]Epoch 25, global step 130: 'val_accuracy' reached 0.78750 (best 0.78750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=25-step=130.ckpt' as top 3\n",
      "Epoch 26:  50%|████████████████▌                | 40/80 [00:00<00:00, 69.92it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 213.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 176.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 90.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 81.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 79.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 76.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 80.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 80.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 77.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 78.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.63it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 78.45it/s]\u001b[A\n",
      "Epoch 26:  50%|████████████████▌                | 40/80 [00:00<00:00, 46.07it/s]Epoch 26, global step 132: 'val_accuracy' was not in top 3\n",
      "Epoch 26: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 47.97it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 254.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 223.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.55it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.38it/s]\u001b[A\n",
      "Epoch 26: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 40.70it/s]Epoch 26, global step 135: 'val_accuracy' reached 0.79375 (best 0.79375), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=26-step=135.ckpt' as top 3\n",
      "Epoch 27:  50%|████████████████▌                | 40/80 [00:00<00:00, 65.99it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 201.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 195.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 79.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 92.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 67.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 74.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 68.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 74.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 68.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 73.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 71.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 73.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.12it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.29it/s]\u001b[A\n",
      "Epoch 27:  50%|████████████████▌                | 40/80 [00:00<00:00, 43.92it/s]Epoch 27, global step 137: 'val_accuracy' reached 0.80625 (best 0.80625), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=27-step=137.ckpt' as top 3\n",
      "Epoch 27: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.35it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 140.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 153.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 87.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 83.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 81.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.67it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.18it/s]\u001b[A\n",
      "Epoch 27: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.03it/s]Epoch 27, global step 140: 'val_accuracy' reached 0.81250 (best 0.81250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=27-step=140.ckpt' as top 3\n",
      "Epoch 28:  50%|████████████████▌                | 40/80 [00:00<00:00, 69.98it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 239.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 213.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 81.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 95.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 70.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 76.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 71.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 76.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 71.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 72.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 73.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.58it/s]\u001b[A\n",
      "Epoch 28:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.49it/s]Epoch 28, global step 142: 'val_accuracy' reached 0.81875 (best 0.81875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=28-step=142.ckpt' as top 3\n",
      "Epoch 28: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 40.18it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 207.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 197.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 82.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 84.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.67it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 78.85it/s]\u001b[A\n",
      "Epoch 28: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 34.52it/s]Epoch 28, global step 145: 'val_accuracy' was not in top 3\n",
      "Epoch 29:  50%|████████████████▌                | 40/80 [00:00<00:00, 69.29it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 236.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 187.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 87.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 83.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 82.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 84.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.44it/s]\u001b[A\n",
      "Epoch 29:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.67it/s]Epoch 29, global step 147: 'val_accuracy' reached 0.83125 (best 0.83125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=29-step=147.ckpt' as top 3\n",
      "Epoch 29: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 34.60it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 243.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 194.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 72.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 75.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.98it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.68it/s]\u001b[A\n",
      "Epoch 29: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 30.42it/s]Epoch 29, global step 150: 'val_accuracy' reached 0.83125 (best 0.83125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=29-step=150.ckpt' as top 3\n",
      "Epoch 30:  50%|████████████████▌                | 40/80 [00:00<00:00, 66.00it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 229.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 205.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 90.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 104.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 81.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 79.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 79.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 82.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 85.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.58it/s]\u001b[A\n",
      "Epoch 30:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.51it/s]\u001b[AEpoch 30, global step 152: 'val_accuracy' reached 0.83125 (best 0.83125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=30-step=152.ckpt' as top 3\n",
      "Epoch 30: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 41.42it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 229.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 218.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 76.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 80.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 74.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 76.69it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 73.38it/s]\u001b[A\n",
      "Epoch 30: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.60it/s]Epoch 30, global step 155: 'val_accuracy' was not in top 3\n",
      "Epoch 31:  50%|████████████████▌                | 40/80 [00:00<00:00, 65.85it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 239.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 148.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 72.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 74.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 73.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 75.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 76.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 74.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 76.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 74.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 74.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 71.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 74.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 71.46it/s]\u001b[A\n",
      "Epoch 31:  50%|████████████████▌                | 40/80 [00:00<00:00, 43.10it/s]Epoch 31, global step 157: 'val_accuracy' reached 0.85000 (best 0.85000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=31-step=157.ckpt' as top 3\n",
      "Epoch 31: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.55it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 224.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 198.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 82.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 95.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 77.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 80.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 77.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 77.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.11it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 77.89it/s]\u001b[A\n",
      "Epoch 31: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.29it/s]Epoch 31, global step 160: 'val_accuracy' reached 0.83750 (best 0.85000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=31-step=160.ckpt' as top 3\n",
      "Epoch 32:  50%|████████████████▌                | 40/80 [00:00<00:00, 68.02it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 141.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 163.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 71.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 76.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 63.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 67.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 68.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 70.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 70.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 66.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 63.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 66.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 64.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 67.27it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 64.75it/s]\u001b[A\n",
      "Epoch 32:  50%|████████████████▌                | 40/80 [00:00<00:00, 42.62it/s]Epoch 32, global step 162: 'val_accuracy' reached 0.86250 (best 0.86250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=32-step=162.ckpt' as top 3\n",
      "Epoch 32: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 36.19it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 236.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 191.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 77.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 77.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 80.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 74.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 71.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.09it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 71.15it/s]\u001b[A\n",
      "Epoch 32: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.57it/s]Epoch 32, global step 165: 'val_accuracy' was not in top 3\n",
      "Epoch 33:  50%|████████████████▌                | 40/80 [00:00<00:00, 70.74it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 220.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 208.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 82.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 97.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 82.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 71.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 71.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 76.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 72.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 77.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 73.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 69.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 71.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 69.86it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.29it/s]\u001b[A\n",
      "Epoch 33:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.04it/s]Epoch 33, global step 167: 'val_accuracy' reached 0.85625 (best 0.86250), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=33-step=167.ckpt' as top 3\n",
      "Epoch 33: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 34.30it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 253.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 221.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 68.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 82.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 63.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 72.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 65.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 71.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 67.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 72.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 69.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 74.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 70.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 74.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 69.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 70.43it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.85it/s]\u001b[A\n",
      "Epoch 33: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 29.99it/s]Epoch 33, global step 170: 'val_accuracy' reached 0.86875 (best 0.86875), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=33-step=170.ckpt' as top 3\n",
      "Epoch 34:  50%|████████████████▌                | 40/80 [00:00<00:00, 70.66it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 157.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 158.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 90.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 105.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 79.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 78.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 78.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 80.43it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 77.83it/s]\u001b[A\n",
      "Epoch 34:  50%|████████████████▌                | 40/80 [00:00<00:00, 46.27it/s]Epoch 34, global step 172: 'val_accuracy' reached 0.87500 (best 0.87500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=34-step=172.ckpt' as top 3\n",
      "Epoch 34: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 42.07it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 180.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 185.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 89.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 103.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 89.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 84.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 83.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 81.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 82.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 79.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 77.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 79.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 73.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 75.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.66it/s]\u001b[A\n",
      "Epoch 34: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 36.04it/s]Epoch 34, global step 175: 'val_accuracy' reached 0.87500 (best 0.87500), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=34-step=175.ckpt' as top 3\n",
      "Epoch 35:  50%|████████████████▌                | 40/80 [00:00<00:00, 68.64it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 231.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 217.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 98.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 70.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 78.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 77.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 76.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 73.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 77.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 73.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 74.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 75.59it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 73.12it/s]\u001b[A\n",
      "Epoch 35:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.58it/s]Epoch 35, global step 177: 'val_accuracy' reached 0.88125 (best 0.88125), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=35-step=177.ckpt' as top 3\n",
      "Epoch 35: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.13it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 266.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 227.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 69.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 82.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 76.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 75.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 75.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 71.99it/s]\u001b[A\n",
      "Epoch 35: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 27.64it/s]Epoch 35, global step 180: 'val_accuracy' was not in top 3\n",
      "Epoch 36:  50%|████████████████▌                | 40/80 [00:00<00:00, 71.02it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 242.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 210.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 80.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 74.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 73.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 75.55it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.26it/s]\u001b[A\n",
      "Epoch 36:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.52it/s]Epoch 36, global step 182: 'val_accuracy' was not in top 3\n",
      "Epoch 36: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 47.93it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 182.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 187.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 78.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 78.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 82.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 80.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 81.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 80.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 78.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 77.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 78.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 79.03it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.66it/s]\u001b[A\n",
      "Epoch 36: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 40.54it/s]Epoch 36, global step 185: 'val_accuracy' was not in top 3\n",
      "Epoch 37:  50%|████████████████▌                | 40/80 [00:00<00:00, 71.11it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 244.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 220.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 83.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 98.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 75.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 78.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 79.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 83.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 77.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 80.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 77.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 80.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 78.53it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 80.93it/s]\u001b[A\n",
      "Epoch 37:  50%|████████████████▌                | 40/80 [00:00<00:00, 46.97it/s]Epoch 37, global step 187: 'val_accuracy' reached 0.88750 (best 0.88750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=37-step=187.ckpt' as top 3\n",
      "Epoch 37: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 38.16it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 240.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 214.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 97.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 79.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 77.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 82.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 77.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 81.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 79.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 74.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 66.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 69.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 68.51it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 70.96it/s]\u001b[A\n",
      "Epoch 37: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 33.00it/s]Epoch 37, global step 190: 'val_accuracy' reached 0.88125 (best 0.88750), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=37-step=190.ckpt' as top 3\n",
      "Epoch 38:  50%|████████████████▌                | 40/80 [00:00<00:00, 73.64it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 239.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 218.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 76.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 85.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 75.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 80.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 77.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 82.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 78.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 82.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 76.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 79.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 76.85it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 78.86it/s]\u001b[A\n",
      "Epoch 38:  50%|████████████████▌                | 40/80 [00:00<00:00, 47.84it/s]Epoch 38, global step 192: 'val_accuracy' was not in top 3\n",
      "Epoch 38: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 48.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 234.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 186.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 78.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 86.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 74.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 72.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 77.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 74.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 73.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 76.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 74.84it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 77.19it/s]\u001b[A\n",
      "Epoch 38: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 40.71it/s]Epoch 38, global step 195: 'val_accuracy' reached 0.90000 (best 0.90000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=38-step=195.ckpt' as top 3\n",
      "Epoch 39:  50%|████████████████▌                | 40/80 [00:00<00:00, 71.53it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 222.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 206.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 89.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 104.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 80.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 76.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 76.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 77.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 80.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 76.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 79.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 75.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 77.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 77.05it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 79.26it/s]\u001b[A\n",
      "Epoch 39:  50%|████████████████▌                | 40/80 [00:00<00:00, 46.35it/s]Epoch 39, global step 197: 'val_accuracy' reached 0.88750 (best 0.90000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=39-step=197.ckpt' as top 3\n",
      "Epoch 39: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 36.62it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 228.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 206.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 88.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 102.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 73.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 80.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 75.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 81.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 74.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 79.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 75.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 79.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 71.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 73.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 73.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.26it/s]\u001b[A\n",
      "Epoch 39: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 32.06it/s]Epoch 39, global step 200: 'val_accuracy' reached 0.90000 (best 0.90000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=39-step=200.ckpt' as top 3\n",
      "Epoch 40:  50%|████████████████▌                | 40/80 [00:00<00:00, 68.33it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 224.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 207.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 82.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 96.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 72.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 71.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 76.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 73.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 77.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 73.71it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 77.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 74.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 72.79it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.32it/s]\u001b[A\n",
      "Epoch 40:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.89it/s]Epoch 40, global step 202: 'val_accuracy' was not in top 3\n",
      "Epoch 40: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 46.87it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 249.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 214.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 71.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 80.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 68.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 74.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 68.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 73.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 69.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 72.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 70.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 73.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 68.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 71.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 67.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 69.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 68.67it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 71.02it/s]\u001b[A\n",
      "Epoch 40: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 39.42it/s]Epoch 40, global step 205: 'val_accuracy' was not in top 3\n",
      "Epoch 41:  50%|████████████████▌                | 40/80 [00:00<00:00, 69.42it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 254.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 218.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 85.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 99.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 73.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 81.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 70.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 77.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 72.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 77.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 72.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 76.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 73.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 76.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 70.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 70.62it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.99it/s]\u001b[A\n",
      "Epoch 41:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.87it/s]Epoch 41, global step 207: 'val_accuracy' reached 0.90000 (best 0.90000), saving model to '/users/1/tianx/GDP/GDP/outputs/ag_models/epoch=41-step=207.ckpt' as top 3\n",
      "Epoch 41: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 36.08it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 220.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 189.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 84.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 98.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 75.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 84.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 73.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 74.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 79.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 75.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 73.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 76.46it/s]\u001b[A\n",
      "Epoch 41: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.67it/s]Epoch 41, global step 210: 'val_accuracy' was not in top 3\n",
      "Epoch 42:  50%|████████████████▌                | 40/80 [00:00<00:00, 71.30it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 260.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 233.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 95.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 78.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 88.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 73.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 79.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 73.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 78.25it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 75.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 80.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 76.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 80.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 74.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 78.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 73.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 76.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 70.98it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 73.43it/s]\u001b[A\n",
      "Epoch 42:  50%|████████████████▌                | 40/80 [00:00<00:00, 45.72it/s]Epoch 42, global step 212: 'val_accuracy' was not in top 3\n",
      "Epoch 42: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 47.35it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 244.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 216.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 87.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 101.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 72.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 81.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 69.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 75.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 70.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 71.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 71.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 75.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 72.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 69.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 72.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 69.70it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 72.07it/s]\u001b[A\n",
      "Epoch 42: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 39.82it/s]Epoch 42, global step 215: 'val_accuracy' was not in top 3\n",
      "Epoch 43:  50%|████████████████▌                | 40/80 [00:00<00:00, 68.30it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 231.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 210.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 86.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▌              | 4/20 [00:00<00:00, 100.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 74.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 83.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 72.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 78.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 72.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 77.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 74.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 78.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 74.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 78.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 72.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 75.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 72.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 75.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 73.37it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 75.93it/s]\u001b[A\n",
      "Epoch 43:  50%|████████████████▌                | 40/80 [00:00<00:00, 44.95it/s]Epoch 43, global step 217: 'val_accuracy' was not in top 3\n",
      "Epoch 43: 100%|█████████████████████████████████| 80/80 [00:01<00:00, 42.00it/s]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▉                 | 1/20 [00:00<00:00, 191.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▊                | 2/20 [00:00<00:00, 172.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▊                | 3/20 [00:00<00:00, 83.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|███▊               | 4/20 [00:00<00:00, 97.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|████▊              | 5/20 [00:00<00:00, 72.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|█████▋             | 6/20 [00:00<00:00, 80.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|██████▋            | 7/20 [00:00<00:00, 70.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|███████▌           | 8/20 [00:00<00:00, 76.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████████▌          | 9/20 [00:00<00:00, 69.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████████         | 10/20 [00:00<00:00, 74.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████████▉        | 11/20 [00:00<00:00, 71.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|██████████▊       | 12/20 [00:00<00:00, 75.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|███████████▋      | 13/20 [00:00<00:00, 71.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|████████████▌     | 14/20 [00:00<00:00, 74.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████████▌    | 15/20 [00:00<00:00, 69.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████████▍   | 16/20 [00:00<00:00, 70.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████████▎  | 17/20 [00:00<00:00, 69.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████████████▏ | 18/20 [00:00<00:00, 71.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|█████████████████ | 19/20 [00:00<00:00, 69.30it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████████████| 20/20 [00:00<00:00, 71.56it/s]\u001b[A\n",
      "Epoch 43: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 35.85it/s]Epoch 43, global step 220: 'val_accuracy' was not in top 3\n",
      "Epoch 43: 100%|█████████████████████████████████| 80/80 [00:02<00:00, 31.87it/s]\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Predicting DataLoader 0: 100%|████████████████████| 5/5 [00:00<00:00, 24.27it/s]\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Predicting DataLoader 0: 100%|████████████████████| 5/5 [00:00<00:00, 24.91it/s]\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Predicting DataLoader 0: 100%|████████████████████| 5/5 [00:00<00:00, 24.97it/s]\n",
      "AutoMM has created your model. 🎉🎉🎉\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/users/1/tianx/GDP/GDP/outputs/ag_models\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:00<00:00, 45.81it/s]\n",
      "AutoGluon multimodal predictor score: {'accuracy': 0.8875}\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Predicting DataLoader 0: 100%|██████████████████| 25/25 [00:01<00:00, 20.68it/s]\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "Predicting DataLoader 0: 100%|████████████████████| 3/3 [00:00<00:00, 47.05it/s]\n",
      "\u001b[32m[I 2025-06-22 16:35:09,553]\u001b[0m A new study created in memory with name: no-name-fd9c7998-6740-46c2-b792-939e44674889\u001b[0m\n",
      "/users/1/tianx/GDP/GDP/train.py:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr              = trial.suggest_loguniform('lr', *param_ranges['lr'])\n",
      "Epoch 1/200  Train: 9.1470  Val: 1.8059\n",
      "Epoch 2/200  Train: 2.4019  Val: 1.1373\n",
      "Epoch 3/200  Train: 1.5289  Val: 1.0967\n",
      "Epoch 4/200  Train: 1.1288  Val: 1.1765\n",
      "Epoch 5/200  Train: 1.1861  Val: 1.2518\n",
      "Epoch 6/200  Train: 1.2584  Val: 0.9695\n",
      "Epoch 7/200  Train: 1.0387  Val: 1.0703\n",
      "Epoch 8/200  Train: 1.1600  Val: 1.0356\n",
      "Epoch 9/200  Train: 1.1527  Val: 1.0857\n",
      "Epoch 10/200  Train: 1.0112  Val: 1.1233\n",
      "Epoch 11/200  Train: 1.0643  Val: 1.0746\n",
      "Epoch 12/200  Train: 0.9810  Val: 1.1345\n",
      "Epoch 13/200  Train: 1.0751  Val: 0.8489\n",
      "Epoch 14/200  Train: 1.0257  Val: 0.8872\n",
      "Epoch 15/200  Train: 1.0195  Val: 1.0160\n",
      "Epoch 16/200  Train: 1.0344  Val: 1.1290\n",
      "Epoch 17/200  Train: 1.0703  Val: 0.9554\n",
      "Epoch 18/200  Train: 1.0185  Val: 0.9891\n",
      "Epoch 19/200  Train: 0.9997  Val: 1.1232\n",
      "Epoch 20/200  Train: 1.2544  Val: 1.0967\n",
      "Epoch 21/200  Train: 1.1226  Val: 0.9519\n",
      "Epoch 22/200  Train: 1.0267  Val: 0.8509\n",
      "Epoch 23/200  Train: 1.0184  Val: 1.1757\n",
      "Epoch 24/200  Train: 1.0040  Val: 0.9463\n",
      "Epoch 25/200  Train: 1.0130  Val: 1.1107\n",
      "Epoch 26/200  Train: 0.9147  Val: 1.0665\n",
      "Epoch 27/200  Train: 0.9813  Val: 1.0415\n",
      "Epoch 28/200  Train: 0.9169  Val: 0.8935\n",
      "Epoch 29/200  Train: 0.9299  Val: 0.8349\n",
      "Epoch 30/200  Train: 1.0193  Val: 0.9902\n",
      "Epoch 31/200  Train: 0.9300  Val: 0.8740\n",
      "Epoch 32/200  Train: 0.9633  Val: 1.0023\n",
      "Epoch 33/200  Train: 0.9288  Val: 0.8836\n",
      "Epoch 34/200  Train: 0.9795  Val: 0.9598\n",
      "Epoch 35/200  Train: 0.9985  Val: 1.1081\n",
      "Epoch 36/200  Train: 0.9817  Val: 1.1140\n",
      "Epoch 37/200  Train: 1.0608  Val: 0.8855\n",
      "Epoch 38/200  Train: 1.1000  Val: 0.8620\n",
      "Epoch 39/200  Train: 1.0081  Val: 0.8694\n",
      "Epoch 40/200  Train: 0.9865  Val: 0.9611\n",
      "Epoch 41/200  Train: 0.9882  Val: 1.0502\n",
      "Epoch 42/200  Train: 0.9901  Val: 1.0351\n",
      "Epoch 43/200  Train: 1.0635  Val: 1.0434\n",
      "Epoch 44/200  Train: 0.9680  Val: 1.0781\n",
      "Epoch 45/200  Train: 0.9810  Val: 0.9093\n",
      "Epoch 46/200  Train: 0.8564  Val: 1.1716\n",
      "Epoch 47/200  Train: 0.9971  Val: 1.0546\n",
      "Epoch 48/200  Train: 1.0005  Val: 0.9162\n",
      "Epoch 49/200  Train: 1.0274  Val: 0.7570\n",
      "Epoch 50/200  Train: 0.9324  Val: 0.8630\n",
      "Epoch 51/200  Train: 0.9248  Val: 0.8103\n",
      "Epoch 52/200  Train: 0.9884  Val: 0.9375\n",
      "Epoch 53/200  Train: 0.9736  Val: 0.9160\n",
      "Epoch 54/200  Train: 0.9165  Val: 1.0626\n",
      "Epoch 55/200  Train: 0.8681  Val: 0.8672\n",
      "Epoch 56/200  Train: 0.9208  Val: 1.0239\n",
      "Epoch 57/200  Train: 0.9372  Val: 0.9145\n",
      "Epoch 58/200  Train: 0.8659  Val: 0.9685\n",
      "Epoch 59/200  Train: 0.9247  Val: 0.9100\n",
      "Epoch 60/200  Train: 0.9299  Val: 0.8973\n",
      "Epoch 61/200  Train: 0.9159  Val: 0.9135\n",
      "Epoch 62/200  Train: 0.9528  Val: 0.9912\n",
      "Epoch 63/200  Train: 0.9380  Val: 0.9677\n",
      "Epoch 64/200  Train: 0.9108  Val: 0.9827\n",
      "Epoch 65/200  Train: 0.8287  Val: 0.9401\n",
      "Epoch 66/200  Train: 0.8879  Val: 0.8782\n",
      "Epoch 67/200  Train: 0.9553  Val: 0.9251\n",
      "Epoch 68/200  Train: 0.9610  Val: 1.3991\n",
      "Epoch 69/200  Train: 0.9679  Val: 1.0203\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:12,850]\u001b[0m Trial 0 finished with value: 0.7570240020751953 and parameters: {'batch_size': 64, 'lr': 1.6779101225057395e-05, 'hidden_dim': 1024, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 665, 'beta_end': 0.011025968074802998, 'dropout': 0.028267862851019305}. Best is trial 0 with value: 0.7570240020751953.\u001b[0m\n",
      "Epoch 1/200  Train: 41.4957  Val: 31.2101\n",
      "Epoch 2/200  Train: 12.8108  Val: 15.7306\n",
      "Epoch 3/200  Train: 11.2425  Val: 1.3020\n",
      "Epoch 4/200  Train: 5.9821  Val: 5.7684\n",
      "Epoch 5/200  Train: 2.9445  Val: 4.8054\n",
      "Epoch 6/200  Train: 3.1665  Val: 1.4388\n",
      "Epoch 7/200  Train: 2.2518  Val: 1.4828\n",
      "Epoch 8/200  Train: 1.4331  Val: 1.8580\n",
      "Epoch 9/200  Train: 1.4156  Val: 1.1674\n",
      "Epoch 10/200  Train: 1.2062  Val: 0.9838\n",
      "Epoch 11/200  Train: 1.1263  Val: 0.8862\n",
      "Epoch 12/200  Train: 0.9568  Val: 0.9814\n",
      "Epoch 13/200  Train: 1.0524  Val: 1.0061\n",
      "Epoch 14/200  Train: 0.8885  Val: 0.9165\n",
      "Epoch 15/200  Train: 1.0104  Val: 1.1050\n",
      "Epoch 16/200  Train: 1.0199  Val: 1.3184\n",
      "Epoch 17/200  Train: 0.9957  Val: 1.1723\n",
      "Epoch 18/200  Train: 1.0961  Val: 0.9757\n",
      "Epoch 19/200  Train: 1.1683  Val: 0.9243\n",
      "Epoch 20/200  Train: 1.0433  Val: 1.0575\n",
      "Epoch 21/200  Train: 1.1106  Val: 0.9794\n",
      "Epoch 22/200  Train: 1.0182  Val: 0.9309\n",
      "Epoch 23/200  Train: 0.9458  Val: 0.9512\n",
      "Epoch 24/200  Train: 1.0681  Val: 1.0152\n",
      "Epoch 25/200  Train: 0.8938  Val: 1.0723\n",
      "Epoch 26/200  Train: 1.0290  Val: 0.9091\n",
      "Epoch 27/200  Train: 1.0589  Val: 0.9902\n",
      "Epoch 28/200  Train: 1.0602  Val: 0.9346\n",
      "Epoch 29/200  Train: 0.9764  Val: 0.9908\n",
      "Epoch 30/200  Train: 1.0092  Val: 0.9459\n",
      "Epoch 31/200  Train: 0.9717  Val: 1.0448\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:14,176]\u001b[0m Trial 1 finished with value: 0.8861582636833191 and parameters: {'batch_size': 128, 'lr': 1.5836929190790218e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 9, 'noise_steps': 837, 'beta_end': 0.013718916129290654, 'dropout': 0.04435707162164262}. Best is trial 0 with value: 0.7570240020751953.\u001b[0m\n",
      "Epoch 1/200  Train: 111.0820  Val: 33.4614\n",
      "Epoch 2/200  Train: 29.2831  Val: 3.8824\n",
      "Epoch 3/200  Train: 5.8778  Val: 7.4847\n",
      "Epoch 4/200  Train: 2.9337  Val: 2.7772\n",
      "Epoch 5/200  Train: 2.2441  Val: 1.0118\n",
      "Epoch 6/200  Train: 1.4226  Val: 1.3016\n",
      "Epoch 7/200  Train: 1.2319  Val: 1.1607\n",
      "Epoch 8/200  Train: 0.9740  Val: 1.2949\n",
      "Epoch 9/200  Train: 0.9490  Val: 0.9861\n",
      "Epoch 10/200  Train: 1.1327  Val: 1.0741\n",
      "Epoch 11/200  Train: 0.9597  Val: 0.9957\n",
      "Epoch 12/200  Train: 1.0755  Val: 0.9409\n",
      "Epoch 13/200  Train: 0.9178  Val: 1.1107\n",
      "Epoch 14/200  Train: 1.1263  Val: 1.1146\n",
      "Epoch 15/200  Train: 0.9877  Val: 1.0063\n",
      "Epoch 16/200  Train: 0.9497  Val: 0.9868\n",
      "Epoch 17/200  Train: 0.9750  Val: 0.9535\n",
      "Epoch 18/200  Train: 1.0478  Val: 0.8030\n",
      "Epoch 19/200  Train: 0.9695  Val: 1.0677\n",
      "Epoch 20/200  Train: 1.0141  Val: 1.0651\n",
      "Epoch 21/200  Train: 0.8831  Val: 0.8382\n",
      "Epoch 22/200  Train: 1.0978  Val: 0.9319\n",
      "Epoch 23/200  Train: 0.9299  Val: 0.9813\n",
      "Epoch 24/200  Train: 0.9522  Val: 0.8400\n",
      "Epoch 25/200  Train: 0.9691  Val: 0.8568\n",
      "Epoch 26/200  Train: 0.8470  Val: 0.8533\n",
      "Epoch 27/200  Train: 0.9734  Val: 0.8929\n",
      "Epoch 28/200  Train: 1.0414  Val: 0.7352\n",
      "Epoch 29/200  Train: 0.8716  Val: 0.9417\n",
      "Epoch 30/200  Train: 0.9581  Val: 0.7611\n",
      "Epoch 31/200  Train: 0.9654  Val: 0.9417\n",
      "Epoch 32/200  Train: 0.9857  Val: 1.1272\n",
      "Epoch 33/200  Train: 0.8920  Val: 1.2095\n",
      "Epoch 34/200  Train: 0.9160  Val: 0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200  Train: 0.8844  Val: 0.9077\n",
      "Epoch 36/200  Train: 0.8896  Val: 0.7398\n",
      "Epoch 37/200  Train: 0.9841  Val: 0.8876\n",
      "Epoch 38/200  Train: 0.8622  Val: 1.0361\n",
      "Epoch 39/200  Train: 0.8483  Val: 0.8817\n",
      "Epoch 40/200  Train: 0.8627  Val: 0.7178\n",
      "Epoch 41/200  Train: 0.8478  Val: 0.8478\n",
      "Epoch 42/200  Train: 0.9050  Val: 0.8912\n",
      "Epoch 43/200  Train: 0.8948  Val: 0.7807\n",
      "Epoch 44/200  Train: 0.8767  Val: 0.8228\n",
      "Epoch 45/200  Train: 0.8477  Val: 1.0462\n",
      "Epoch 46/200  Train: 0.8999  Val: 0.9832\n",
      "Epoch 47/200  Train: 0.8940  Val: 0.9435\n",
      "Epoch 48/200  Train: 0.8382  Val: 0.9614\n",
      "Epoch 49/200  Train: 0.8986  Val: 0.8037\n",
      "Epoch 50/200  Train: 0.9046  Val: 1.1146\n",
      "Epoch 51/200  Train: 0.9533  Val: 0.9204\n",
      "Epoch 52/200  Train: 0.8661  Val: 1.0366\n",
      "Epoch 53/200  Train: 0.8741  Val: 0.8627\n",
      "Epoch 54/200  Train: 0.8823  Val: 1.1052\n",
      "Epoch 55/200  Train: 0.8793  Val: 0.7635\n",
      "Epoch 56/200  Train: 0.9589  Val: 0.7656\n",
      "Epoch 57/200  Train: 0.8609  Val: 0.9221\n",
      "Epoch 58/200  Train: 0.9171  Val: 0.8865\n",
      "Epoch 59/200  Train: 0.8726  Val: 0.9656\n",
      "Epoch 60/200  Train: 0.9579  Val: 0.9071\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:17,245]\u001b[0m Trial 2 finished with value: 0.7177873849868774 and parameters: {'batch_size': 64, 'lr': 4.37002333292519e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 8, 'noise_steps': 731, 'beta_end': 0.018913604140757274, 'dropout': 0.043129501917775905}. Best is trial 2 with value: 0.7177873849868774.\u001b[0m\n",
      "Epoch 1/200  Train: 8.2547  Val: 3.8320\n",
      "Epoch 2/200  Train: 2.7660  Val: 2.0233\n",
      "Epoch 3/200  Train: 1.7852  Val: 0.9941\n",
      "Epoch 4/200  Train: 1.2269  Val: 1.0868\n",
      "Epoch 5/200  Train: 1.0203  Val: 0.9796\n",
      "Epoch 6/200  Train: 1.1783  Val: 1.0012\n",
      "Epoch 7/200  Train: 1.0330  Val: 1.0861\n",
      "Epoch 8/200  Train: 1.1503  Val: 1.0587\n",
      "Epoch 9/200  Train: 1.2308  Val: 1.1819\n",
      "Epoch 10/200  Train: 1.0916  Val: 1.0586\n",
      "Epoch 11/200  Train: 1.0214  Val: 1.0347\n",
      "Epoch 12/200  Train: 0.9733  Val: 1.1304\n",
      "Epoch 13/200  Train: 1.0426  Val: 0.9198\n",
      "Epoch 14/200  Train: 0.9578  Val: 0.9928\n",
      "Epoch 15/200  Train: 1.2267  Val: 1.0317\n",
      "Epoch 16/200  Train: 1.2118  Val: 0.9673\n",
      "Epoch 17/200  Train: 1.0613  Val: 0.9362\n",
      "Epoch 18/200  Train: 1.0090  Val: 1.0076\n",
      "Epoch 19/200  Train: 1.0394  Val: 0.7750\n",
      "Epoch 20/200  Train: 1.1396  Val: 0.9262\n",
      "Epoch 21/200  Train: 0.9401  Val: 0.8800\n",
      "Epoch 22/200  Train: 1.0007  Val: 0.9364\n",
      "Epoch 23/200  Train: 1.1271  Val: 0.9256\n",
      "Epoch 24/200  Train: 1.0692  Val: 1.5655\n",
      "Epoch 25/200  Train: 1.5307  Val: 1.6267\n",
      "Epoch 26/200  Train: 1.1444  Val: 0.8926\n",
      "Epoch 27/200  Train: 1.3737  Val: 2.3491\n",
      "Epoch 28/200  Train: 1.5865  Val: 1.1118\n",
      "Epoch 29/200  Train: 1.0469  Val: 1.1891\n",
      "Epoch 30/200  Train: 1.0598  Val: 0.7905\n",
      "Epoch 31/200  Train: 1.0278  Val: 0.8554\n",
      "Epoch 32/200  Train: 1.0854  Val: 1.0250\n",
      "Epoch 33/200  Train: 1.0285  Val: 0.9139\n",
      "Epoch 34/200  Train: 0.9292  Val: 0.8163\n",
      "Epoch 35/200  Train: 1.0243  Val: 0.9651\n",
      "Epoch 36/200  Train: 1.1010  Val: 1.1491\n",
      "Epoch 37/200  Train: 1.0603  Val: 1.0026\n",
      "Epoch 38/200  Train: 0.9166  Val: 0.8942\n",
      "Epoch 39/200  Train: 0.8599  Val: 0.8927\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:20,208]\u001b[0m Trial 3 finished with value: 0.7749752879142762 and parameters: {'batch_size': 64, 'lr': 2.0562825332871403e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 9, 'noise_steps': 622, 'beta_end': 0.015375164485167663, 'dropout': 0.01805777024932961}. Best is trial 2 with value: 0.7177873849868774.\u001b[0m\n",
      "Epoch 1/200  Train: 9.7646  Val: 2.8871\n",
      "Epoch 2/200  Train: 1.3004  Val: 1.1267\n",
      "Epoch 3/200  Train: 0.9172  Val: 1.1306\n",
      "Epoch 4/200  Train: 1.0240  Val: 0.8725\n",
      "Epoch 5/200  Train: 1.0885  Val: 1.0667\n",
      "Epoch 6/200  Train: 1.2084  Val: 1.1836\n",
      "Epoch 7/200  Train: 1.2332  Val: 0.9550\n",
      "Epoch 8/200  Train: 1.2132  Val: 1.0148\n",
      "Epoch 9/200  Train: 1.0665  Val: 1.1570\n",
      "Epoch 10/200  Train: 1.2165  Val: 1.7566\n",
      "Epoch 11/200  Train: 1.1181  Val: 0.8594\n",
      "Epoch 12/200  Train: 1.0550  Val: 1.3840\n",
      "Epoch 13/200  Train: 1.1291  Val: 0.9969\n",
      "Epoch 14/200  Train: 1.1048  Val: 0.6826\n",
      "Epoch 15/200  Train: 0.9103  Val: 0.8536\n",
      "Epoch 16/200  Train: 0.9441  Val: 0.8858\n",
      "Epoch 17/200  Train: 0.8629  Val: 0.8978\n",
      "Epoch 18/200  Train: 0.9856  Val: 0.9319\n",
      "Epoch 19/200  Train: 0.8815  Val: 0.8057\n",
      "Epoch 20/200  Train: 0.9183  Val: 1.1525\n",
      "Epoch 21/200  Train: 0.9179  Val: 1.0011\n",
      "Epoch 22/200  Train: 0.7827  Val: 0.5915\n",
      "Epoch 23/200  Train: 0.8544  Val: 0.6107\n",
      "Epoch 24/200  Train: 0.8666  Val: 0.8360\n",
      "Epoch 25/200  Train: 0.8903  Val: 0.8759\n",
      "Epoch 26/200  Train: 0.8483  Val: 0.8062\n",
      "Epoch 27/200  Train: 0.7677  Val: 0.7241\n",
      "Epoch 28/200  Train: 0.7860  Val: 0.7648\n",
      "Epoch 29/200  Train: 0.7422  Val: 0.6857\n",
      "Epoch 30/200  Train: 0.8343  Val: 1.3865\n",
      "Epoch 31/200  Train: 0.9511  Val: 0.5827\n",
      "Epoch 32/200  Train: 0.7990  Val: 0.6869\n",
      "Epoch 33/200  Train: 0.9073  Val: 0.7211\n",
      "Epoch 34/200  Train: 0.8740  Val: 0.7986\n",
      "Epoch 35/200  Train: 0.8298  Val: 0.9254\n",
      "Epoch 36/200  Train: 0.7726  Val: 1.0703\n",
      "Epoch 37/200  Train: 1.1291  Val: 1.9861\n",
      "Epoch 38/200  Train: 0.8729  Val: 0.8981\n",
      "Epoch 39/200  Train: 0.9324  Val: 0.8025\n",
      "Epoch 40/200  Train: 0.7550  Val: 0.8267\n",
      "Epoch 41/200  Train: 0.6939  Val: 0.7455\n",
      "Epoch 42/200  Train: 0.6841  Val: 0.9433\n",
      "Epoch 43/200  Train: 0.6756  Val: 0.6693\n",
      "Epoch 44/200  Train: 0.9642  Val: 1.7235\n",
      "Epoch 45/200  Train: 0.8951  Val: 0.6394\n",
      "Epoch 46/200  Train: 0.6050  Val: 0.7548\n",
      "Epoch 47/200  Train: 0.6286  Val: 0.4968\n",
      "Epoch 48/200  Train: 0.5843  Val: 1.1062\n",
      "Epoch 49/200  Train: 0.6006  Val: 0.4875\n",
      "Epoch 50/200  Train: 0.4686  Val: 0.4981\n",
      "Epoch 51/200  Train: 0.5771  Val: 0.5874\n",
      "Epoch 52/200  Train: 0.5051  Val: 0.5954\n",
      "Epoch 53/200  Train: 0.5733  Val: 0.5035\n",
      "Epoch 54/200  Train: 0.5008  Val: 0.6818\n",
      "Epoch 55/200  Train: 0.6264  Val: 0.3949\n",
      "Epoch 56/200  Train: 0.6594  Val: 0.4701\n",
      "Epoch 57/200  Train: 0.5121  Val: 0.6228\n",
      "Epoch 58/200  Train: 0.5003  Val: 0.3912\n",
      "Epoch 59/200  Train: 0.5955  Val: 0.8410\n",
      "Epoch 60/200  Train: 0.5507  Val: 0.5262\n",
      "Epoch 61/200  Train: 0.4509  Val: 0.3261\n",
      "Epoch 62/200  Train: 0.4613  Val: 0.5654\n",
      "Epoch 63/200  Train: 0.5085  Val: 0.4084\n",
      "Epoch 64/200  Train: 0.4641  Val: 0.4610\n",
      "Epoch 65/200  Train: 0.4194  Val: 0.5932\n",
      "Epoch 66/200  Train: 0.5508  Val: 0.5276\n",
      "Epoch 67/200  Train: 0.4257  Val: 0.4518\n",
      "Epoch 68/200  Train: 0.5420  Val: 0.4014\n",
      "Epoch 69/200  Train: 0.5043  Val: 0.3844\n",
      "Epoch 70/200  Train: 0.4080  Val: 0.6383\n",
      "Epoch 71/200  Train: 0.4957  Val: 0.3677\n",
      "Epoch 72/200  Train: 0.4235  Val: 0.2963\n",
      "Epoch 73/200  Train: 0.4162  Val: 0.3488\n",
      "Epoch 74/200  Train: 0.3692  Val: 0.3654\n",
      "Epoch 75/200  Train: 0.4190  Val: 0.5344\n",
      "Epoch 76/200  Train: 0.4422  Val: 0.8015\n",
      "Epoch 77/200  Train: 0.4804  Val: 0.2954\n",
      "Epoch 78/200  Train: 0.2939  Val: 0.3787\n",
      "Epoch 79/200  Train: 0.3882  Val: 0.2882\n",
      "Epoch 80/200  Train: 0.2962  Val: 0.2906\n",
      "Epoch 81/200  Train: 0.6111  Val: 0.3483\n",
      "Epoch 82/200  Train: 0.4326  Val: 0.4023\n",
      "Epoch 83/200  Train: 0.4088  Val: 0.3062\n",
      "Epoch 84/200  Train: 0.3249  Val: 0.2802\n",
      "Epoch 85/200  Train: 0.3253  Val: 0.3403\n",
      "Epoch 86/200  Train: 0.3104  Val: 0.2640\n",
      "Epoch 87/200  Train: 0.2687  Val: 0.3233\n",
      "Epoch 88/200  Train: 0.2583  Val: 0.1828\n",
      "Epoch 89/200  Train: 0.2927  Val: 0.2860\n",
      "Epoch 90/200  Train: 0.2544  Val: 0.1942\n",
      "Epoch 91/200  Train: 0.2282  Val: 0.1402\n",
      "Epoch 92/200  Train: 0.2281  Val: 0.1589\n",
      "Epoch 93/200  Train: 0.2550  Val: 0.1532\n",
      "Epoch 94/200  Train: 0.2680  Val: 0.2456\n",
      "Epoch 95/200  Train: 0.2461  Val: 0.2535\n",
      "Epoch 96/200  Train: 0.2409  Val: 0.2142\n",
      "Epoch 97/200  Train: 0.3359  Val: 0.3750\n",
      "Epoch 98/200  Train: 0.2348  Val: 0.2023\n",
      "Epoch 99/200  Train: 0.2864  Val: 0.2325\n",
      "Epoch 100/200  Train: 0.2191  Val: 0.2492\n",
      "Epoch 101/200  Train: 0.1940  Val: 0.3533\n",
      "Epoch 102/200  Train: 0.2365  Val: 0.3056\n",
      "Epoch 103/200  Train: 0.2477  Val: 0.2756\n",
      "Epoch 104/200  Train: 0.1749  Val: 0.2903\n",
      "Epoch 105/200  Train: 0.1658  Val: 0.1969\n",
      "Epoch 106/200  Train: 0.1716  Val: 0.2980\n",
      "Epoch 107/200  Train: 0.1588  Val: 0.2841\n",
      "Epoch 108/200  Train: 0.1776  Val: 0.1581\n",
      "Epoch 109/200  Train: 0.2320  Val: 0.5013\n",
      "Epoch 110/200  Train: 0.2894  Val: 0.3835\n",
      "Epoch 111/200  Train: 0.3008  Val: 0.4532\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:32,145]\u001b[0m Trial 4 finished with value: 0.1401919186115265 and parameters: {'batch_size': 32, 'lr': 8.569737690316607e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 10, 'noise_steps': 595, 'beta_end': 0.019571063026376893, 'dropout': 0.022120577047787193}. Best is trial 4 with value: 0.1401919186115265.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200  Train: 59.0559  Val: 54.9425\n",
      "Epoch 2/200  Train: 22.8481  Val: 23.6829\n",
      "Epoch 3/200  Train: 10.0761  Val: 13.7059\n",
      "Epoch 4/200  Train: 5.6702  Val: 6.2449\n",
      "Epoch 5/200  Train: 3.2312  Val: 3.6720\n",
      "Epoch 6/200  Train: 2.6004  Val: 2.2229\n",
      "Epoch 7/200  Train: 1.9016  Val: 1.6416\n",
      "Epoch 8/200  Train: 1.4500  Val: 1.6116\n",
      "Epoch 9/200  Train: 1.3301  Val: 0.8818\n",
      "Epoch 10/200  Train: 1.2064  Val: 1.0745\n",
      "Epoch 11/200  Train: 1.0202  Val: 1.0336\n",
      "Epoch 12/200  Train: 1.0588  Val: 1.0751\n",
      "Epoch 13/200  Train: 1.0070  Val: 0.9931\n",
      "Epoch 14/200  Train: 1.0409  Val: 0.8466\n",
      "Epoch 15/200  Train: 0.8435  Val: 0.9739\n",
      "Epoch 16/200  Train: 0.8905  Val: 1.0581\n",
      "Epoch 17/200  Train: 0.9529  Val: 0.9496\n",
      "Epoch 18/200  Train: 0.8142  Val: 0.8958\n",
      "Epoch 19/200  Train: 0.9553  Val: 0.8671\n",
      "Epoch 20/200  Train: 0.8633  Val: 0.8121\n",
      "Epoch 21/200  Train: 1.0126  Val: 0.9307\n",
      "Epoch 22/200  Train: 0.9991  Val: 1.2189\n",
      "Epoch 23/200  Train: 1.1270  Val: 1.1621\n",
      "Epoch 24/200  Train: 1.0940  Val: 0.7607\n",
      "Epoch 25/200  Train: 0.9646  Val: 0.9025\n",
      "Epoch 26/200  Train: 0.9741  Val: 0.9744\n",
      "Epoch 27/200  Train: 0.9107  Val: 0.9990\n",
      "Epoch 28/200  Train: 0.9065  Val: 0.7483\n",
      "Epoch 29/200  Train: 0.9690  Val: 1.0796\n",
      "Epoch 30/200  Train: 0.9598  Val: 1.0302\n",
      "Epoch 31/200  Train: 0.9381  Val: 0.9613\n",
      "Epoch 32/200  Train: 0.9483  Val: 0.9402\n",
      "Epoch 33/200  Train: 0.9407  Val: 0.9301\n",
      "Epoch 34/200  Train: 0.8197  Val: 0.7798\n",
      "Epoch 35/200  Train: 0.8978  Val: 0.8410\n",
      "Epoch 36/200  Train: 0.8676  Val: 1.1256\n",
      "Epoch 37/200  Train: 0.8521  Val: 0.8773\n",
      "Epoch 38/200  Train: 0.9064  Val: 0.8109\n",
      "Epoch 39/200  Train: 0.8984  Val: 0.8362\n",
      "Epoch 40/200  Train: 0.9042  Val: 1.0362\n",
      "Epoch 41/200  Train: 0.8326  Val: 0.7752\n",
      "Epoch 42/200  Train: 0.8425  Val: 0.7729\n",
      "Epoch 43/200  Train: 0.8949  Val: 0.8693\n",
      "Epoch 44/200  Train: 0.8728  Val: 0.8153\n",
      "Epoch 45/200  Train: 0.8805  Val: 0.8972\n",
      "Epoch 46/200  Train: 0.9231  Val: 0.7394\n",
      "Epoch 47/200  Train: 0.9331  Val: 0.8747\n",
      "Epoch 48/200  Train: 0.8696  Val: 0.9370\n",
      "Epoch 49/200  Train: 0.8586  Val: 0.8250\n",
      "Epoch 50/200  Train: 0.8393  Val: 0.8002\n",
      "Epoch 51/200  Train: 0.8602  Val: 0.8104\n",
      "Epoch 52/200  Train: 0.9102  Val: 1.1491\n",
      "Epoch 53/200  Train: 0.9236  Val: 0.9554\n",
      "Epoch 54/200  Train: 0.8683  Val: 0.8223\n",
      "Epoch 55/200  Train: 0.8370  Val: 0.7931\n",
      "Epoch 56/200  Train: 0.8450  Val: 0.8562\n",
      "Epoch 57/200  Train: 0.7897  Val: 0.8119\n",
      "Epoch 58/200  Train: 0.8481  Val: 0.7698\n",
      "Epoch 59/200  Train: 0.8003  Val: 0.5470\n",
      "Epoch 60/200  Train: 0.8366  Val: 0.6367\n",
      "Epoch 61/200  Train: 0.7893  Val: 0.8087\n",
      "Epoch 62/200  Train: 0.7476  Val: 0.8199\n",
      "Epoch 63/200  Train: 0.8366  Val: 0.8500\n",
      "Epoch 64/200  Train: 0.8737  Val: 0.8839\n",
      "Epoch 65/200  Train: 0.8156  Val: 0.9166\n",
      "Epoch 66/200  Train: 0.8023  Val: 0.7135\n",
      "Epoch 67/200  Train: 0.8343  Val: 0.8651\n",
      "Epoch 68/200  Train: 0.8284  Val: 0.8510\n",
      "Epoch 69/200  Train: 0.7369  Val: 0.8236\n",
      "Epoch 70/200  Train: 0.6767  Val: 0.7505\n",
      "Epoch 71/200  Train: 0.7327  Val: 0.7098\n",
      "Epoch 72/200  Train: 0.7645  Val: 0.7619\n",
      "Epoch 73/200  Train: 0.8162  Val: 0.9283\n",
      "Epoch 74/200  Train: 0.7529  Val: 0.8156\n",
      "Epoch 75/200  Train: 0.7473  Val: 0.7575\n",
      "Epoch 76/200  Train: 0.8128  Val: 0.7405\n",
      "Epoch 77/200  Train: 0.7754  Val: 0.6933\n",
      "Epoch 78/200  Train: 0.7574  Val: 0.7361\n",
      "Epoch 79/200  Train: 0.7618  Val: 0.6721\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:35,706]\u001b[0m Trial 5 finished with value: 0.5470124125480652 and parameters: {'batch_size': 128, 'lr': 7.859737564766352e-05, 'hidden_dim': 1024, 'time_embed_dim': 64, 'layers': 10, 'noise_steps': 985, 'beta_end': 0.01298657773880699, 'dropout': 0.04811233163294925}. Best is trial 4 with value: 0.1401919186115265.\u001b[0m\n",
      "Epoch 1/200  Train: 59.1885  Val: 4.2716\n",
      "Epoch 2/200  Train: 9.6341  Val: 7.1882\n",
      "Epoch 3/200  Train: 2.7543  Val: 1.8273\n",
      "Epoch 4/200  Train: 1.2345  Val: 0.9446\n",
      "Epoch 5/200  Train: 1.0755  Val: 0.8667\n",
      "Epoch 6/200  Train: 1.1631  Val: 1.2754\n",
      "Epoch 7/200  Train: 1.1038  Val: 0.8532\n",
      "Epoch 8/200  Train: 1.0752  Val: 1.2068\n",
      "Epoch 9/200  Train: 1.1784  Val: 0.9139\n",
      "Epoch 10/200  Train: 1.0415  Val: 0.9564\n",
      "Epoch 11/200  Train: 0.9720  Val: 1.2367\n",
      "Epoch 12/200  Train: 1.1532  Val: 1.2394\n",
      "Epoch 13/200  Train: 1.2297  Val: 2.0652\n",
      "Epoch 14/200  Train: 1.0655  Val: 1.0203\n",
      "Epoch 15/200  Train: 0.8821  Val: 0.9640\n",
      "Epoch 16/200  Train: 0.9240  Val: 0.9023\n",
      "Epoch 17/200  Train: 0.8795  Val: 0.9280\n",
      "Epoch 18/200  Train: 1.0388  Val: 0.8871\n",
      "Epoch 19/200  Train: 0.8143  Val: 0.7513\n",
      "Epoch 20/200  Train: 0.8575  Val: 0.8810\n",
      "Epoch 21/200  Train: 0.8389  Val: 1.0161\n",
      "Epoch 22/200  Train: 0.8855  Val: 0.6766\n",
      "Epoch 23/200  Train: 0.7794  Val: 0.5993\n",
      "Epoch 24/200  Train: 0.8014  Val: 0.9519\n",
      "Epoch 25/200  Train: 0.8195  Val: 0.6873\n",
      "Epoch 26/200  Train: 0.7711  Val: 0.7575\n",
      "Epoch 27/200  Train: 0.7906  Val: 0.7909\n",
      "Epoch 28/200  Train: 1.0386  Val: 1.0076\n",
      "Epoch 29/200  Train: 0.7800  Val: 0.9196\n",
      "Epoch 30/200  Train: 0.7405  Val: 0.8038\n",
      "Epoch 31/200  Train: 0.9212  Val: 0.9418\n",
      "Epoch 32/200  Train: 0.8074  Val: 1.2232\n",
      "Epoch 33/200  Train: 1.0521  Val: 0.7533\n",
      "Epoch 34/200  Train: 0.7981  Val: 1.4072\n",
      "Epoch 35/200  Train: 1.3491  Val: 1.0634\n",
      "Epoch 36/200  Train: 1.6754  Val: 2.6908\n",
      "Epoch 37/200  Train: 1.0569  Val: 1.0642\n",
      "Epoch 38/200  Train: 0.7737  Val: 0.8196\n",
      "Epoch 39/200  Train: 0.7648  Val: 0.9041\n",
      "Epoch 40/200  Train: 0.7138  Val: 0.5656\n",
      "Epoch 41/200  Train: 0.9259  Val: 1.3691\n",
      "Epoch 42/200  Train: 0.6447  Val: 0.5464\n",
      "Epoch 43/200  Train: 0.5449  Val: 0.6037\n",
      "Epoch 44/200  Train: 0.7178  Val: 1.4453\n",
      "Epoch 45/200  Train: 0.8718  Val: 0.9515\n",
      "Epoch 46/200  Train: 0.9171  Val: 0.7069\n",
      "Epoch 47/200  Train: 0.7925  Val: 0.8934\n",
      "Epoch 48/200  Train: 0.5696  Val: 0.6129\n",
      "Epoch 49/200  Train: 0.6452  Val: 0.5938\n",
      "Epoch 50/200  Train: 0.7045  Val: 0.7083\n",
      "Epoch 51/200  Train: 0.5267  Val: 0.5545\n",
      "Epoch 52/200  Train: 0.6065  Val: 0.6293\n",
      "Epoch 53/200  Train: 0.7018  Val: 0.6093\n",
      "Epoch 54/200  Train: 0.5677  Val: 0.5849\n",
      "Epoch 55/200  Train: 0.5926  Val: 0.7505\n",
      "Epoch 56/200  Train: 0.5113  Val: 0.4988\n",
      "Epoch 57/200  Train: 0.5948  Val: 0.9718\n",
      "Epoch 58/200  Train: 0.6882  Val: 0.6659\n",
      "Epoch 59/200  Train: 0.5932  Val: 0.4267\n",
      "Epoch 60/200  Train: 0.4646  Val: 0.3819\n",
      "Epoch 61/200  Train: 0.8866  Val: 1.2951\n",
      "Epoch 62/200  Train: 1.5386  Val: 1.7587\n",
      "Epoch 63/200  Train: 0.7131  Val: 0.6621\n",
      "Epoch 64/200  Train: 0.4708  Val: 0.3881\n",
      "Epoch 65/200  Train: 0.5210  Val: 0.4315\n",
      "Epoch 66/200  Train: 0.5538  Val: 0.4712\n",
      "Epoch 67/200  Train: 0.9910  Val: 0.4508\n",
      "Epoch 68/200  Train: 0.8784  Val: 0.6859\n",
      "Epoch 69/200  Train: 0.8269  Val: 0.5026\n",
      "Epoch 70/200  Train: 0.5053  Val: 0.3844\n",
      "Epoch 71/200  Train: 0.4255  Val: 0.3989\n",
      "Epoch 72/200  Train: 0.4659  Val: 0.4329\n",
      "Epoch 73/200  Train: 0.5741  Val: 0.3217\n",
      "Epoch 74/200  Train: 0.3979  Val: 0.4253\n",
      "Epoch 75/200  Train: 0.4117  Val: 0.4391\n",
      "Epoch 76/200  Train: 0.4160  Val: 0.4476\n",
      "Epoch 77/200  Train: 0.3656  Val: 0.4065\n",
      "Epoch 78/200  Train: 0.3736  Val: 0.3728\n",
      "Epoch 79/200  Train: 0.3960  Val: 0.3663\n",
      "Epoch 80/200  Train: 0.6468  Val: 2.7318\n",
      "Epoch 81/200  Train: 1.8260  Val: 2.2040\n",
      "Epoch 82/200  Train: 1.0571  Val: 0.3391\n",
      "Epoch 83/200  Train: 0.4849  Val: 0.3497\n",
      "Epoch 84/200  Train: 0.3581  Val: 0.3831\n",
      "Epoch 85/200  Train: 0.4051  Val: 0.3887\n",
      "Epoch 86/200  Train: 0.3803  Val: 0.3946\n",
      "Epoch 87/200  Train: 0.3807  Val: 0.3055\n",
      "Epoch 88/200  Train: 0.4733  Val: 0.3202\n",
      "Epoch 89/200  Train: 0.3542  Val: 0.3215\n",
      "Epoch 90/200  Train: 0.3880  Val: 0.4810\n",
      "Epoch 91/200  Train: 0.4378  Val: 0.6916\n",
      "Epoch 92/200  Train: 0.3804  Val: 0.3535\n",
      "Epoch 93/200  Train: 0.4383  Val: 0.2928\n",
      "Epoch 94/200  Train: 0.3103  Val: 0.3522\n",
      "Epoch 95/200  Train: 0.3853  Val: 0.3405\n",
      "Epoch 96/200  Train: 0.3287  Val: 0.3186\n",
      "Epoch 97/200  Train: 0.3264  Val: 0.2480\n",
      "Epoch 98/200  Train: 0.3027  Val: 0.3637\n",
      "Epoch 99/200  Train: 0.3048  Val: 0.2832\n",
      "Epoch 100/200  Train: 0.3532  Val: 0.3892\n",
      "Epoch 101/200  Train: 0.4464  Val: 0.3783\n",
      "Epoch 102/200  Train: 0.2932  Val: 0.2974\n",
      "Epoch 103/200  Train: 0.3045  Val: 0.3199\n",
      "Epoch 104/200  Train: 0.4280  Val: 0.4128\n",
      "Epoch 105/200  Train: 0.2902  Val: 0.2964\n",
      "Epoch 106/200  Train: 0.3111  Val: 0.2557\n",
      "Epoch 107/200  Train: 0.4725  Val: 0.3414\n",
      "Epoch 108/200  Train: 0.2815  Val: 0.5864\n",
      "Epoch 109/200  Train: 0.4710  Val: 0.8408\n",
      "Epoch 110/200  Train: 0.4424  Val: 0.3859\n",
      "Epoch 111/200  Train: 0.2970  Val: 0.3882\n",
      "Epoch 112/200  Train: 0.3003  Val: 0.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200  Train: 0.2722  Val: 0.2782\n",
      "Epoch 114/200  Train: 0.2196  Val: 0.2854\n",
      "Epoch 115/200  Train: 0.2572  Val: 0.2426\n",
      "Epoch 116/200  Train: 0.2633  Val: 0.2825\n",
      "Epoch 117/200  Train: 0.2153  Val: 0.2359\n",
      "Epoch 118/200  Train: 0.1819  Val: 0.3452\n",
      "Epoch 119/200  Train: 0.3627  Val: 0.2783\n",
      "Epoch 120/200  Train: 0.3036  Val: 0.2840\n",
      "Epoch 121/200  Train: 0.2079  Val: 0.1864\n",
      "Epoch 122/200  Train: 0.2322  Val: 0.2483\n",
      "Epoch 123/200  Train: 0.2295  Val: 0.2167\n",
      "Epoch 124/200  Train: 0.1985  Val: 0.1208\n",
      "Epoch 125/200  Train: 0.2124  Val: 0.2305\n",
      "Epoch 126/200  Train: 0.2041  Val: 0.2723\n",
      "Epoch 127/200  Train: 0.2711  Val: 0.2902\n",
      "Epoch 128/200  Train: 0.2999  Val: 0.2234\n",
      "Epoch 129/200  Train: 0.1966  Val: 0.2337\n",
      "Epoch 130/200  Train: 0.2044  Val: 0.2246\n",
      "Epoch 131/200  Train: 0.1882  Val: 0.2579\n",
      "Epoch 132/200  Train: 0.2162  Val: 0.1754\n",
      "Epoch 133/200  Train: 0.1650  Val: 0.1722\n",
      "Epoch 134/200  Train: 0.1930  Val: 0.1895\n",
      "Epoch 135/200  Train: 0.2004  Val: 0.1792\n",
      "Epoch 136/200  Train: 0.1929  Val: 0.3381\n",
      "Epoch 137/200  Train: 0.1567  Val: 0.1185\n",
      "Epoch 138/200  Train: 0.1950  Val: 0.2686\n",
      "Epoch 139/200  Train: 0.2815  Val: 0.3007\n",
      "Epoch 140/200  Train: 0.2297  Val: 0.4036\n",
      "Epoch 141/200  Train: 0.3058  Val: 0.1958\n",
      "Epoch 142/200  Train: 0.1514  Val: 0.3467\n",
      "Epoch 143/200  Train: 0.2053  Val: 0.2262\n",
      "Epoch 144/200  Train: 0.1838  Val: 0.2925\n",
      "Epoch 145/200  Train: 0.1764  Val: 0.1444\n",
      "Epoch 146/200  Train: 0.1695  Val: 0.1099\n",
      "Epoch 147/200  Train: 0.1638  Val: 0.2556\n",
      "Epoch 148/200  Train: 0.1150  Val: 0.2175\n",
      "Epoch 149/200  Train: 0.1580  Val: 0.1983\n",
      "Epoch 150/200  Train: 0.1949  Val: 0.5029\n",
      "Epoch 151/200  Train: 0.1801  Val: 0.1523\n",
      "Epoch 152/200  Train: 0.1337  Val: 0.2625\n",
      "Epoch 153/200  Train: 0.1343  Val: 0.2218\n",
      "Epoch 154/200  Train: 0.1509  Val: 0.2525\n",
      "Epoch 155/200  Train: 0.1297  Val: 0.1948\n",
      "Epoch 156/200  Train: 0.1391  Val: 0.3022\n",
      "Epoch 157/200  Train: 0.1411  Val: 0.2471\n",
      "Epoch 158/200  Train: 0.1398  Val: 0.5091\n",
      "Epoch 159/200  Train: 0.1961  Val: 0.1742\n",
      "Epoch 160/200  Train: 0.1658  Val: 0.1537\n",
      "Epoch 161/200  Train: 0.1792  Val: 0.4664\n",
      "Epoch 162/200  Train: 0.1714  Val: 0.2779\n",
      "Epoch 163/200  Train: 0.1861  Val: 0.1690\n",
      "Epoch 164/200  Train: 0.1165  Val: 0.1794\n",
      "Epoch 165/200  Train: 0.1737  Val: 0.1255\n",
      "Epoch 166/200  Train: 0.1105  Val: 0.2499\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:45,752]\u001b[0m Trial 6 finished with value: 0.10987674295902253 and parameters: {'batch_size': 32, 'lr': 7.047665023618443e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 724, 'beta_end': 0.018295195375399413, 'dropout': 0.012841175782895937}. Best is trial 6 with value: 0.10987674295902253.\u001b[0m\n",
      "Epoch 1/200  Train: 3.0501  Val: 2.5556\n",
      "Epoch 2/200  Train: 1.8643  Val: 1.8602\n",
      "Epoch 3/200  Train: 1.2473  Val: 1.2746\n",
      "Epoch 4/200  Train: 1.1917  Val: 1.0052\n",
      "Epoch 5/200  Train: 1.1293  Val: 0.9945\n",
      "Epoch 6/200  Train: 1.1163  Val: 1.0020\n",
      "Epoch 7/200  Train: 0.9914  Val: 0.8347\n",
      "Epoch 8/200  Train: 1.0549  Val: 1.0105\n",
      "Epoch 9/200  Train: 0.9745  Val: 0.9146\n",
      "Epoch 10/200  Train: 0.9962  Val: 1.0608\n",
      "Epoch 11/200  Train: 1.0257  Val: 1.0465\n",
      "Epoch 12/200  Train: 1.0449  Val: 1.0161\n",
      "Epoch 13/200  Train: 1.0299  Val: 1.0255\n",
      "Epoch 14/200  Train: 1.0554  Val: 0.8182\n",
      "Epoch 15/200  Train: 1.1560  Val: 1.0882\n",
      "Epoch 16/200  Train: 1.2179  Val: 1.0672\n",
      "Epoch 17/200  Train: 1.0144  Val: 1.1503\n",
      "Epoch 18/200  Train: 1.0991  Val: 0.9541\n",
      "Epoch 19/200  Train: 1.0250  Val: 1.0348\n",
      "Epoch 20/200  Train: 0.9898  Val: 1.1490\n",
      "Epoch 21/200  Train: 0.9851  Val: 0.9885\n",
      "Epoch 22/200  Train: 0.9932  Val: 0.9942\n",
      "Epoch 23/200  Train: 1.0035  Val: 0.9850\n",
      "Epoch 24/200  Train: 1.1264  Val: 1.1885\n",
      "Epoch 25/200  Train: 1.0467  Val: 1.0414\n",
      "Epoch 26/200  Train: 1.0462  Val: 0.9328\n",
      "Epoch 27/200  Train: 1.0172  Val: 1.0199\n",
      "Epoch 28/200  Train: 0.9581  Val: 1.0480\n",
      "Epoch 29/200  Train: 1.0137  Val: 0.8710\n",
      "Epoch 30/200  Train: 1.0438  Val: 1.1117\n",
      "Epoch 31/200  Train: 1.0583  Val: 0.9700\n",
      "Epoch 32/200  Train: 1.0922  Val: 0.9320\n",
      "Epoch 33/200  Train: 0.9508  Val: 1.0627\n",
      "Epoch 34/200  Train: 0.9853  Val: 1.0506\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:46,809]\u001b[0m Trial 7 finished with value: 0.8182249665260315 and parameters: {'batch_size': 128, 'lr': 2.2252290758432033e-05, 'hidden_dim': 1024, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 862, 'beta_end': 0.01736337579745433, 'dropout': 0.020296765899305954}. Best is trial 6 with value: 0.10987674295902253.\u001b[0m\n",
      "Epoch 1/200  Train: 2.2308  Val: 1.7268\n",
      "Epoch 2/200  Train: 1.4829  Val: 1.4490\n",
      "Epoch 3/200  Train: 1.2029  Val: 1.2343\n",
      "Epoch 4/200  Train: 1.1273  Val: 1.1780\n",
      "Epoch 5/200  Train: 1.1465  Val: 0.9627\n",
      "Epoch 6/200  Train: 1.1827  Val: 1.0620\n",
      "Epoch 7/200  Train: 0.9932  Val: 0.8355\n",
      "Epoch 8/200  Train: 1.1026  Val: 1.0415\n",
      "Epoch 9/200  Train: 1.0303  Val: 0.9224\n",
      "Epoch 10/200  Train: 0.9908  Val: 1.0510\n",
      "Epoch 11/200  Train: 0.9744  Val: 0.9558\n",
      "Epoch 12/200  Train: 1.0408  Val: 1.0537\n",
      "Epoch 13/200  Train: 1.0383  Val: 1.0915\n",
      "Epoch 14/200  Train: 1.0737  Val: 0.7606\n",
      "Epoch 15/200  Train: 1.0608  Val: 1.1238\n",
      "Epoch 16/200  Train: 1.0967  Val: 0.9428\n",
      "Epoch 17/200  Train: 0.9758  Val: 1.1804\n",
      "Epoch 18/200  Train: 1.1117  Val: 0.9838\n",
      "Epoch 19/200  Train: 1.0439  Val: 1.0503\n",
      "Epoch 20/200  Train: 1.0211  Val: 1.1393\n",
      "Epoch 21/200  Train: 0.9951  Val: 1.0214\n",
      "Epoch 22/200  Train: 1.0219  Val: 0.9971\n",
      "Epoch 23/200  Train: 1.0060  Val: 1.0194\n",
      "Epoch 24/200  Train: 1.1412  Val: 1.1605\n",
      "Epoch 25/200  Train: 1.0133  Val: 1.0779\n",
      "Epoch 26/200  Train: 1.0295  Val: 0.9639\n",
      "Epoch 27/200  Train: 1.0568  Val: 1.0895\n",
      "Epoch 28/200  Train: 0.9899  Val: 1.1129\n",
      "Epoch 29/200  Train: 1.0441  Val: 0.9566\n",
      "Epoch 30/200  Train: 1.0896  Val: 1.1301\n",
      "Epoch 31/200  Train: 1.1038  Val: 1.0611\n",
      "Epoch 32/200  Train: 1.1810  Val: 0.9041\n",
      "Epoch 33/200  Train: 1.0138  Val: 1.1635\n",
      "Epoch 34/200  Train: 1.0438  Val: 1.1559\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:47,684]\u001b[0m Trial 8 finished with value: 0.7606009244918823 and parameters: {'batch_size': 128, 'lr': 1.271944791901771e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 6, 'noise_steps': 846, 'beta_end': 0.016669328077564563, 'dropout': 0.0019514350472623122}. Best is trial 6 with value: 0.10987674295902253.\u001b[0m\n",
      "Epoch 1/200  Train: 10.6288  Val: 5.3149\n",
      "Epoch 2/200  Train: 3.3893  Val: 5.0396\n",
      "Epoch 3/200  Train: 2.5315  Val: 2.8078\n",
      "Epoch 4/200  Train: 2.2774  Val: 1.0844\n",
      "Epoch 5/200  Train: 1.6911  Val: 1.5144\n",
      "Epoch 6/200  Train: 1.2780  Val: 1.1701\n",
      "Epoch 7/200  Train: 1.1307  Val: 0.9220\n",
      "Epoch 8/200  Train: 1.0617  Val: 1.2336\n",
      "Epoch 9/200  Train: 1.0413  Val: 0.7652\n",
      "Epoch 10/200  Train: 1.0647  Val: 1.0655\n",
      "Epoch 11/200  Train: 0.9735  Val: 1.0186\n",
      "Epoch 12/200  Train: 1.0324  Val: 1.0776\n",
      "Epoch 13/200  Train: 1.0242  Val: 1.0250\n",
      "Epoch 14/200  Train: 1.0809  Val: 0.8905\n",
      "Epoch 15/200  Train: 0.8812  Val: 1.0732\n",
      "Epoch 16/200  Train: 0.9352  Val: 1.1312\n",
      "Epoch 17/200  Train: 1.0211  Val: 1.0650\n",
      "Epoch 18/200  Train: 0.8546  Val: 0.9238\n",
      "Epoch 19/200  Train: 1.0171  Val: 0.9421\n",
      "Epoch 20/200  Train: 0.9186  Val: 0.8936\n",
      "Epoch 21/200  Train: 1.0655  Val: 0.9745\n",
      "Epoch 22/200  Train: 1.0753  Val: 1.1153\n",
      "Epoch 23/200  Train: 1.1212  Val: 1.1501\n",
      "Epoch 24/200  Train: 1.1298  Val: 0.8221\n",
      "Epoch 25/200  Train: 1.0082  Val: 0.9897\n",
      "Epoch 26/200  Train: 1.0434  Val: 1.0960\n",
      "Epoch 27/200  Train: 0.9899  Val: 1.1002\n",
      "Epoch 28/200  Train: 0.9642  Val: 0.7982\n",
      "Epoch 29/200  Train: 1.0642  Val: 1.1376\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:35:49,064]\u001b[0m Trial 9 finished with value: 0.7651851058006287 and parameters: {'batch_size': 128, 'lr': 1.5797917478539486e-05, 'hidden_dim': 1024, 'time_embed_dim': 128, 'layers': 10, 'noise_steps': 623, 'beta_end': 0.012700213637588277, 'dropout': 0.04823931201629669}. Best is trial 6 with value: 0.10987674295902253.\u001b[0m\n",
      "Epoch 1/200  Train: 49.4978  Val: 1.6330\n",
      "Epoch 2/200  Train: 4.2777  Val: 2.0200\n",
      "Epoch 3/200  Train: 1.3028  Val: 0.8929\n",
      "Epoch 4/200  Train: 1.0528  Val: 0.8903\n",
      "Epoch 5/200  Train: 1.0886  Val: 0.8528\n",
      "Epoch 6/200  Train: 1.0737  Val: 1.0253\n",
      "Epoch 7/200  Train: 0.9231  Val: 0.8948\n",
      "Epoch 8/200  Train: 0.9710  Val: 1.0259\n",
      "Epoch 9/200  Train: 1.1340  Val: 0.9584\n",
      "Epoch 10/200  Train: 1.0335  Val: 1.0536\n",
      "Epoch 11/200  Train: 0.9066  Val: 0.9539\n",
      "Epoch 12/200  Train: 0.9790  Val: 0.9364\n",
      "Epoch 13/200  Train: 1.0203  Val: 0.9657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200  Train: 1.0047  Val: 0.9904\n",
      "Epoch 15/200  Train: 0.9560  Val: 1.0110\n",
      "Epoch 16/200  Train: 1.0203  Val: 0.9389\n",
      "Epoch 17/200  Train: 0.9710  Val: 0.8990\n",
      "Epoch 18/200  Train: 1.0000  Val: 0.9257\n",
      "Epoch 19/200  Train: 0.9211  Val: 0.8335\n",
      "Epoch 20/200  Train: 0.9131  Val: 1.2025\n",
      "Epoch 21/200  Train: 0.9082  Val: 1.0427\n",
      "Epoch 22/200  Train: 0.9249  Val: 1.6485\n",
      "Epoch 23/200  Train: 1.1784  Val: 0.7771\n",
      "Epoch 24/200  Train: 0.9118  Val: 1.1034\n",
      "Epoch 25/200  Train: 0.9263  Val: 0.7649\n",
      "Epoch 26/200  Train: 0.8932  Val: 0.8228\n",
      "Epoch 27/200  Train: 0.9662  Val: 0.9860\n",
      "Epoch 28/200  Train: 0.9280  Val: 0.9478\n",
      "Epoch 29/200  Train: 0.9682  Val: 1.1371\n",
      "Epoch 30/200  Train: 0.8662  Val: 1.0895\n",
      "Epoch 31/200  Train: 0.9173  Val: 0.9000\n",
      "Epoch 32/200  Train: 0.9925  Val: 0.8707\n",
      "Epoch 33/200  Train: 0.8398  Val: 0.7326\n",
      "Epoch 34/200  Train: 0.9489  Val: 1.0246\n",
      "Epoch 35/200  Train: 0.8854  Val: 0.9773\n",
      "Epoch 36/200  Train: 0.8266  Val: 0.8884\n",
      "Epoch 37/200  Train: 0.8552  Val: 0.9599\n",
      "Epoch 38/200  Train: 0.8340  Val: 1.0535\n",
      "Epoch 39/200  Train: 0.8167  Val: 0.8848\n",
      "Epoch 40/200  Train: 0.9598  Val: 0.8563\n",
      "Epoch 41/200  Train: 0.9936  Val: 1.7497\n",
      "Epoch 42/200  Train: 1.3223  Val: 1.1347\n",
      "Epoch 43/200  Train: 0.8834  Val: 0.9363\n",
      "Epoch 44/200  Train: 0.7980  Val: 0.8408\n",
      "Epoch 45/200  Train: 0.8462  Val: 0.7695\n",
      "Epoch 46/200  Train: 0.8451  Val: 0.6945\n",
      "Epoch 47/200  Train: 0.8977  Val: 0.8783\n",
      "Epoch 48/200  Train: 0.8034  Val: 0.7769\n",
      "Epoch 49/200  Train: 0.8415  Val: 0.9029\n",
      "Epoch 50/200  Train: 1.0676  Val: 1.7245\n",
      "Epoch 51/200  Train: 0.8425  Val: 0.7799\n",
      "Epoch 52/200  Train: 0.8335  Val: 0.9799\n",
      "Epoch 53/200  Train: 0.9398  Val: 0.9507\n",
      "Epoch 54/200  Train: 0.6896  Val: 0.8270\n",
      "Epoch 55/200  Train: 0.7258  Val: 0.7232\n",
      "Epoch 56/200  Train: 0.7405  Val: 1.0322\n",
      "Epoch 57/200  Train: 1.0708  Val: 0.6860\n",
      "Epoch 58/200  Train: 0.7568  Val: 0.6450\n",
      "Epoch 59/200  Train: 0.7931  Val: 0.8299\n",
      "Epoch 60/200  Train: 0.7721  Val: 0.6607\n",
      "Epoch 61/200  Train: 0.7258  Val: 0.8876\n",
      "Epoch 62/200  Train: 0.7921  Val: 0.8018\n",
      "Epoch 63/200  Train: 1.1472  Val: 1.0011\n",
      "Epoch 64/200  Train: 0.6998  Val: 0.7272\n",
      "Epoch 65/200  Train: 0.9219  Val: 1.0090\n",
      "Epoch 66/200  Train: 0.7103  Val: 0.7498\n",
      "Epoch 67/200  Train: 0.8826  Val: 1.0386\n",
      "Epoch 68/200  Train: 0.6962  Val: 0.6829\n",
      "Epoch 69/200  Train: 0.7081  Val: 0.7286\n",
      "Epoch 70/200  Train: 0.8331  Val: 1.3748\n",
      "Epoch 71/200  Train: 0.9526  Val: 0.7051\n",
      "Epoch 72/200  Train: 0.8107  Val: 0.7281\n",
      "Epoch 73/200  Train: 0.8113  Val: 0.8440\n",
      "Epoch 74/200  Train: 0.6085  Val: 0.7445\n",
      "Epoch 75/200  Train: 0.5956  Val: 0.6853\n",
      "Epoch 76/200  Train: 0.6831  Val: 0.5994\n",
      "Epoch 77/200  Train: 0.6385  Val: 1.2676\n",
      "Epoch 78/200  Train: 0.9225  Val: 0.9063\n",
      "Epoch 79/200  Train: 0.7918  Val: 0.7570\n",
      "Epoch 80/200  Train: 0.7055  Val: 0.8060\n",
      "Epoch 81/200  Train: 0.8686  Val: 0.7213\n",
      "Epoch 82/200  Train: 0.8959  Val: 1.0343\n",
      "Epoch 83/200  Train: 0.6609  Val: 0.5741\n",
      "Epoch 84/200  Train: 0.6915  Val: 0.7485\n",
      "Epoch 85/200  Train: 0.8633  Val: 0.7521\n",
      "Epoch 86/200  Train: 0.7189  Val: 0.8890\n",
      "Epoch 87/200  Train: 0.9716  Val: 0.8119\n",
      "Epoch 88/200  Train: 0.8773  Val: 0.7243\n",
      "Epoch 89/200  Train: 0.6156  Val: 0.5704\n",
      "Epoch 90/200  Train: 0.7608  Val: 1.4529\n",
      "Epoch 91/200  Train: 0.6722  Val: 0.5493\n",
      "Epoch 92/200  Train: 0.6403  Val: 0.5528\n",
      "Epoch 93/200  Train: 0.6202  Val: 0.6856\n",
      "Epoch 94/200  Train: 0.5400  Val: 0.5500\n",
      "Epoch 95/200  Train: 0.6468  Val: 0.5455\n",
      "Epoch 96/200  Train: 0.6000  Val: 0.6821\n",
      "Epoch 97/200  Train: 0.6264  Val: 0.5979\n",
      "Epoch 98/200  Train: 0.6219  Val: 0.6840\n",
      "Epoch 99/200  Train: 0.6568  Val: 0.4820\n",
      "Epoch 100/200  Train: 0.6450  Val: 0.6301\n",
      "Epoch 101/200  Train: 0.6150  Val: 0.5833\n",
      "Epoch 102/200  Train: 0.5620  Val: 0.4788\n",
      "Epoch 103/200  Train: 0.4939  Val: 0.5087\n",
      "Epoch 104/200  Train: 0.6844  Val: 0.5897\n",
      "Epoch 105/200  Train: 0.6625  Val: 0.5060\n",
      "Epoch 106/200  Train: 0.6112  Val: 0.6763\n",
      "Epoch 107/200  Train: 0.6794  Val: 0.7807\n",
      "Epoch 108/200  Train: 0.5396  Val: 0.6076\n",
      "Epoch 109/200  Train: 0.5845  Val: 0.5337\n",
      "Epoch 110/200  Train: 0.6560  Val: 0.8140\n",
      "Epoch 111/200  Train: 0.4791  Val: 0.4850\n",
      "Epoch 112/200  Train: 0.5395  Val: 0.4709\n",
      "Epoch 113/200  Train: 0.5599  Val: 0.6135\n",
      "Epoch 114/200  Train: 0.4652  Val: 0.5439\n",
      "Epoch 115/200  Train: 0.5595  Val: 0.4924\n",
      "Epoch 116/200  Train: 0.5467  Val: 0.4679\n",
      "Epoch 117/200  Train: 0.4523  Val: 0.6257\n",
      "Epoch 118/200  Train: 0.4807  Val: 0.4920\n",
      "Epoch 119/200  Train: 0.6346  Val: 0.6510\n",
      "Epoch 120/200  Train: 0.5039  Val: 0.5115\n",
      "Epoch 121/200  Train: 0.4896  Val: 0.5687\n",
      "Epoch 122/200  Train: 0.5751  Val: 0.4961\n",
      "Epoch 123/200  Train: 0.5183  Val: 0.4245\n",
      "Epoch 124/200  Train: 0.5821  Val: 1.0909\n",
      "Epoch 125/200  Train: 0.8241  Val: 0.5977\n",
      "Epoch 126/200  Train: 0.4979  Val: 0.4248\n",
      "Epoch 127/200  Train: 0.4820  Val: 0.4925\n",
      "Epoch 128/200  Train: 0.4510  Val: 0.4874\n",
      "Epoch 129/200  Train: 0.4619  Val: 0.4444\n",
      "Epoch 130/200  Train: 0.4952  Val: 0.4675\n",
      "Epoch 131/200  Train: 0.4738  Val: 0.3768\n",
      "Epoch 132/200  Train: 0.5852  Val: 0.3853\n",
      "Epoch 133/200  Train: 0.4737  Val: 0.3963\n",
      "Epoch 134/200  Train: 0.4053  Val: 0.4484\n",
      "Epoch 135/200  Train: 0.5205  Val: 0.5264\n",
      "Epoch 136/200  Train: 0.4324  Val: 0.4987\n",
      "Epoch 137/200  Train: 0.3822  Val: 0.3747\n",
      "Epoch 138/200  Train: 0.5175  Val: 0.4390\n",
      "Epoch 139/200  Train: 0.4637  Val: 0.6058\n",
      "Epoch 140/200  Train: 0.4804  Val: 0.5578\n",
      "Epoch 141/200  Train: 0.4615  Val: 0.4467\n",
      "Epoch 142/200  Train: 0.3547  Val: 0.3652\n",
      "Epoch 143/200  Train: 0.4301  Val: 0.4109\n",
      "Epoch 144/200  Train: 0.4902  Val: 0.5996\n",
      "Epoch 145/200  Train: 0.4807  Val: 0.4238\n",
      "Epoch 146/200  Train: 0.5608  Val: 0.5617\n",
      "Epoch 147/200  Train: 0.3578  Val: 0.4188\n",
      "Epoch 148/200  Train: 0.3320  Val: 0.3773\n",
      "Epoch 149/200  Train: 0.3676  Val: 0.4431\n",
      "Epoch 150/200  Train: 0.5010  Val: 0.4674\n",
      "Epoch 151/200  Train: 0.4539  Val: 0.3533\n",
      "Epoch 152/200  Train: 0.3451  Val: 0.3421\n",
      "Epoch 153/200  Train: 0.3786  Val: 0.3164\n",
      "Epoch 154/200  Train: 0.4695  Val: 0.2805\n",
      "Epoch 155/200  Train: 0.3849  Val: 1.2219\n",
      "Epoch 156/200  Train: 0.8274  Val: 0.2801\n",
      "Epoch 157/200  Train: 0.5788  Val: 0.7082\n",
      "Epoch 158/200  Train: 0.3832  Val: 0.5393\n",
      "Epoch 159/200  Train: 0.4672  Val: 0.5083\n",
      "Epoch 160/200  Train: 0.5347  Val: 0.2941\n",
      "Epoch 161/200  Train: 0.4034  Val: 0.4587\n",
      "Epoch 162/200  Train: 0.3619  Val: 0.4017\n",
      "Epoch 163/200  Train: 0.4743  Val: 0.2309\n",
      "Epoch 164/200  Train: 0.3765  Val: 0.2835\n",
      "Epoch 165/200  Train: 0.3347  Val: 0.3680\n",
      "Epoch 166/200  Train: 0.3178  Val: 0.2879\n",
      "Epoch 167/200  Train: 0.3123  Val: 0.4172\n",
      "Epoch 168/200  Train: 0.2930  Val: 0.4350\n",
      "Epoch 169/200  Train: 0.4008  Val: 0.3954\n",
      "Epoch 170/200  Train: 0.3251  Val: 0.3764\n",
      "Epoch 171/200  Train: 0.2995  Val: 0.3148\n",
      "Epoch 172/200  Train: 0.3008  Val: 0.2752\n",
      "Epoch 173/200  Train: 0.2874  Val: 0.3468\n",
      "Epoch 174/200  Train: 0.2598  Val: 0.2557\n",
      "Epoch 175/200  Train: 0.2746  Val: 0.3005\n",
      "Epoch 176/200  Train: 0.5612  Val: 0.5385\n",
      "Epoch 177/200  Train: 0.3761  Val: 0.3419\n",
      "Epoch 178/200  Train: 0.2546  Val: 0.3453\n",
      "Epoch 179/200  Train: 0.2397  Val: 0.3152\n",
      "Epoch 180/200  Train: 0.3854  Val: 0.8204\n",
      "Epoch 181/200  Train: 0.3619  Val: 0.4595\n",
      "Epoch 182/200  Train: 0.2951  Val: 0.3135\n",
      "Epoch 183/200  Train: 0.3136  Val: 0.2009\n",
      "Epoch 184/200  Train: 0.2293  Val: 0.2216\n",
      "Epoch 185/200  Train: 0.1919  Val: 0.2917\n",
      "Epoch 186/200  Train: 0.2475  Val: 0.3680\n",
      "Epoch 187/200  Train: 0.2207  Val: 0.2634\n",
      "Epoch 188/200  Train: 0.1695  Val: 0.2769\n",
      "Epoch 189/200  Train: 0.1804  Val: 0.1893\n",
      "Epoch 190/200  Train: 0.2148  Val: 0.4235\n",
      "Epoch 191/200  Train: 0.2984  Val: 0.3959\n",
      "Epoch 192/200  Train: 0.2334  Val: 0.3570\n",
      "Epoch 193/200  Train: 0.2186  Val: 0.2532\n",
      "Epoch 194/200  Train: 0.2735  Val: 0.2956\n",
      "Epoch 195/200  Train: 0.2884  Val: 0.2413\n",
      "Epoch 196/200  Train: 0.2659  Val: 0.2680\n",
      "Epoch 197/200  Train: 0.4296  Val: 0.4532\n",
      "Epoch 198/200  Train: 0.3429  Val: 0.3193\n",
      "Epoch 199/200  Train: 0.3288  Val: 0.1490\n",
      "Epoch 200/200  Train: 0.2173  Val: 0.3394\n",
      "\u001b[32m[I 2025-06-22 16:35:59,926]\u001b[0m Trial 10 finished with value: 0.1489835910499096 and parameters: {'batch_size': 32, 'lr': 4.7560805787530164e-05, 'hidden_dim': 512, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 501, 'beta_end': 0.017773272327147347, 'dropout': 0.004589719500289529}. Best is trial 6 with value: 0.10987674295902253.\u001b[0m\n",
      "Epoch 1/200  Train: 8.2917  Val: 2.7586\n",
      "Epoch 2/200  Train: 1.8309  Val: 1.0197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200  Train: 1.1599  Val: 1.4252\n",
      "Epoch 4/200  Train: 1.2479  Val: 1.4897\n",
      "Epoch 5/200  Train: 1.1437  Val: 0.8529\n",
      "Epoch 6/200  Train: 1.2095  Val: 1.5956\n",
      "Epoch 7/200  Train: 1.2227  Val: 0.9270\n",
      "Epoch 8/200  Train: 1.1511  Val: 1.0010\n",
      "Epoch 9/200  Train: 1.1929  Val: 0.8611\n",
      "Epoch 10/200  Train: 0.9897  Val: 0.9430\n",
      "Epoch 11/200  Train: 0.9268  Val: 1.5071\n",
      "Epoch 12/200  Train: 1.2477  Val: 0.9280\n",
      "Epoch 13/200  Train: 1.0143  Val: 0.9925\n",
      "Epoch 14/200  Train: 0.9229  Val: 0.9380\n",
      "Epoch 15/200  Train: 0.8582  Val: 0.8802\n",
      "Epoch 16/200  Train: 1.1220  Val: 0.7628\n",
      "Epoch 17/200  Train: 0.8774  Val: 0.9292\n",
      "Epoch 18/200  Train: 0.9352  Val: 0.9090\n",
      "Epoch 19/200  Train: 0.7952  Val: 0.6725\n",
      "Epoch 20/200  Train: 0.8247  Val: 0.9214\n",
      "Epoch 21/200  Train: 0.8287  Val: 0.8906\n",
      "Epoch 22/200  Train: 0.9601  Val: 1.2123\n",
      "Epoch 23/200  Train: 0.8888  Val: 0.6174\n",
      "Epoch 24/200  Train: 0.7491  Val: 0.8481\n",
      "Epoch 25/200  Train: 0.8160  Val: 0.6277\n",
      "Epoch 26/200  Train: 0.9361  Val: 0.9149\n",
      "Epoch 27/200  Train: 0.8161  Val: 0.7218\n",
      "Epoch 28/200  Train: 0.7547  Val: 0.8344\n",
      "Epoch 29/200  Train: 0.8332  Val: 1.3497\n",
      "Epoch 30/200  Train: 0.8641  Val: 0.8692\n",
      "Epoch 31/200  Train: 0.8451  Val: 0.6816\n",
      "Epoch 32/200  Train: 0.8272  Val: 1.4391\n",
      "Epoch 33/200  Train: 1.0600  Val: 0.8995\n",
      "Epoch 34/200  Train: 0.8011  Val: 1.0074\n",
      "Epoch 35/200  Train: 0.7627  Val: 0.7314\n",
      "Epoch 36/200  Train: 0.6401  Val: 0.5736\n",
      "Epoch 37/200  Train: 0.6673  Val: 0.5806\n",
      "Epoch 38/200  Train: 0.6319  Val: 0.7271\n",
      "Epoch 39/200  Train: 0.6446  Val: 0.6939\n",
      "Epoch 40/200  Train: 0.6693  Val: 0.5405\n",
      "Epoch 41/200  Train: 0.7472  Val: 0.8573\n",
      "Epoch 42/200  Train: 0.5868  Val: 0.5165\n",
      "Epoch 43/200  Train: 0.6596  Val: 1.0392\n",
      "Epoch 44/200  Train: 0.7655  Val: 0.6178\n",
      "Epoch 45/200  Train: 0.8079  Val: 0.6027\n",
      "Epoch 46/200  Train: 0.7839  Val: 0.7552\n",
      "Epoch 47/200  Train: 0.6428  Val: 0.5946\n",
      "Epoch 48/200  Train: 0.5712  Val: 0.5508\n",
      "Epoch 49/200  Train: 0.6564  Val: 0.7465\n",
      "Epoch 50/200  Train: 0.7456  Val: 0.3968\n",
      "Epoch 51/200  Train: 0.5382  Val: 0.5405\n",
      "Epoch 52/200  Train: 0.5231  Val: 0.5248\n",
      "Epoch 53/200  Train: 0.7978  Val: 0.6085\n",
      "Epoch 54/200  Train: 0.6464  Val: 0.5163\n",
      "Epoch 55/200  Train: 0.5111  Val: 0.5815\n",
      "Epoch 56/200  Train: 0.4645  Val: 0.5620\n",
      "Epoch 57/200  Train: 0.6074  Val: 0.5447\n",
      "Epoch 58/200  Train: 0.5174  Val: 0.5021\n",
      "Epoch 59/200  Train: 0.5236  Val: 0.6303\n",
      "Epoch 60/200  Train: 0.5491  Val: 0.4240\n",
      "Epoch 61/200  Train: 0.6126  Val: 1.0013\n",
      "Epoch 62/200  Train: 0.6298  Val: 0.5116\n",
      "Epoch 63/200  Train: 0.4348  Val: 0.4609\n",
      "Epoch 64/200  Train: 0.4800  Val: 0.5670\n",
      "Epoch 65/200  Train: 0.5138  Val: 0.4252\n",
      "Epoch 66/200  Train: 0.4256  Val: 0.4592\n",
      "Epoch 67/200  Train: 0.4330  Val: 0.3852\n",
      "Epoch 68/200  Train: 0.3663  Val: 0.3606\n",
      "Epoch 69/200  Train: 0.4151  Val: 0.5364\n",
      "Epoch 70/200  Train: 0.4208  Val: 0.4368\n",
      "Epoch 71/200  Train: 0.4436  Val: 0.4954\n",
      "Epoch 72/200  Train: 0.3717  Val: 0.3163\n",
      "Epoch 73/200  Train: 0.5212  Val: 0.3273\n",
      "Epoch 74/200  Train: 0.4186  Val: 0.5875\n",
      "Epoch 75/200  Train: 0.3162  Val: 0.3973\n",
      "Epoch 76/200  Train: 0.3672  Val: 0.2553\n",
      "Epoch 77/200  Train: 0.3155  Val: 0.5595\n",
      "Epoch 78/200  Train: 0.2911  Val: 0.3569\n",
      "Epoch 79/200  Train: 0.3895  Val: 0.3176\n",
      "Epoch 80/200  Train: 0.3929  Val: 0.2626\n",
      "Epoch 81/200  Train: 0.3317  Val: 0.3104\n",
      "Epoch 82/200  Train: 0.3790  Val: 0.3024\n",
      "Epoch 83/200  Train: 0.2696  Val: 0.2966\n",
      "Epoch 84/200  Train: 0.2960  Val: 0.2756\n",
      "Epoch 85/200  Train: 0.3218  Val: 0.3613\n",
      "Epoch 86/200  Train: 0.2919  Val: 0.5176\n",
      "Epoch 87/200  Train: 0.4609  Val: 0.3637\n",
      "Epoch 88/200  Train: 0.3606  Val: 0.3152\n",
      "Epoch 89/200  Train: 0.2516  Val: 0.2501\n",
      "Epoch 90/200  Train: 0.2681  Val: 0.1960\n",
      "Epoch 91/200  Train: 0.2586  Val: 0.2148\n",
      "Epoch 92/200  Train: 0.2177  Val: 0.2441\n",
      "Epoch 93/200  Train: 0.2165  Val: 0.2616\n",
      "Epoch 94/200  Train: 0.2182  Val: 0.2066\n",
      "Epoch 95/200  Train: 0.2409  Val: 0.3001\n",
      "Epoch 96/200  Train: 0.1934  Val: 0.2387\n",
      "Epoch 97/200  Train: 0.1865  Val: 0.2307\n",
      "Epoch 98/200  Train: 0.1878  Val: 0.3106\n",
      "Epoch 99/200  Train: 0.1575  Val: 0.2546\n",
      "Epoch 100/200  Train: 0.1205  Val: 0.3724\n",
      "Epoch 101/200  Train: 0.1418  Val: 0.3207\n",
      "Epoch 102/200  Train: 0.1168  Val: 0.1968\n",
      "Epoch 103/200  Train: 0.2038  Val: 0.8310\n",
      "Epoch 104/200  Train: 0.3572  Val: 0.2737\n",
      "Epoch 105/200  Train: 0.2090  Val: 0.1683\n",
      "Epoch 106/200  Train: 0.1555  Val: 0.1244\n",
      "Epoch 107/200  Train: 0.1539  Val: 0.3779\n",
      "Epoch 108/200  Train: 0.1461  Val: 0.3017\n",
      "Epoch 109/200  Train: 0.1278  Val: 0.2110\n",
      "Epoch 110/200  Train: 0.1450  Val: 0.5182\n",
      "Epoch 111/200  Train: 0.0749  Val: 0.2599\n",
      "Epoch 112/200  Train: 0.2022  Val: 0.2467\n",
      "Epoch 113/200  Train: 0.1298  Val: 0.2348\n",
      "Epoch 114/200  Train: 0.0702  Val: 0.2123\n",
      "Epoch 115/200  Train: 0.0893  Val: 0.2796\n",
      "Epoch 116/200  Train: 0.0822  Val: 0.2056\n",
      "Epoch 117/200  Train: 0.0737  Val: 0.4136\n",
      "Epoch 118/200  Train: 0.0848  Val: 0.3218\n",
      "Epoch 119/200  Train: 0.1199  Val: 0.2091\n",
      "Epoch 120/200  Train: 0.0833  Val: 0.2361\n",
      "Epoch 121/200  Train: 0.1012  Val: 0.3215\n",
      "Epoch 122/200  Train: 0.0765  Val: 0.2241\n",
      "Epoch 123/200  Train: 0.0778  Val: 0.3085\n",
      "Epoch 124/200  Train: 0.1038  Val: 0.1198\n",
      "Epoch 125/200  Train: 0.0977  Val: 0.3821\n",
      "Epoch 126/200  Train: 0.1045  Val: 0.4233\n",
      "Epoch 127/200  Train: 0.1155  Val: 0.5054\n",
      "Epoch 128/200  Train: 0.0571  Val: 0.1382\n",
      "Epoch 129/200  Train: 0.0687  Val: 0.7357\n",
      "Epoch 130/200  Train: 0.0471  Val: 0.1736\n",
      "Epoch 131/200  Train: 0.0775  Val: 0.2779\n",
      "Epoch 132/200  Train: 0.0539  Val: 0.0987\n",
      "Epoch 133/200  Train: 0.0492  Val: 0.3884\n",
      "Epoch 134/200  Train: 0.1175  Val: 0.3386\n",
      "Epoch 135/200  Train: 0.1050  Val: 0.4283\n",
      "Epoch 136/200  Train: 0.0445  Val: 0.2324\n",
      "Epoch 137/200  Train: 0.1014  Val: 0.1497\n",
      "Epoch 138/200  Train: 0.0678  Val: 0.4862\n",
      "Epoch 139/200  Train: 0.0479  Val: 0.5093\n",
      "Epoch 140/200  Train: 0.0614  Val: 0.2977\n",
      "Epoch 141/200  Train: 0.0509  Val: 0.3786\n",
      "Epoch 142/200  Train: 0.0414  Val: 0.2289\n",
      "Epoch 143/200  Train: 0.0303  Val: 0.3891\n",
      "Epoch 144/200  Train: 0.0469  Val: 0.2855\n",
      "Epoch 145/200  Train: 0.0405  Val: 0.5786\n",
      "Epoch 146/200  Train: 0.0850  Val: 0.4596\n",
      "Epoch 147/200  Train: 0.0400  Val: 0.2801\n",
      "Epoch 148/200  Train: 0.0406  Val: 0.1947\n",
      "Epoch 149/200  Train: 0.0492  Val: 0.1533\n",
      "Epoch 150/200  Train: 0.0658  Val: 0.2716\n",
      "Epoch 151/200  Train: 0.1254  Val: 0.3828\n",
      "Epoch 152/200  Train: 0.1219  Val: 0.1328\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:08,134]\u001b[0m Trial 11 finished with value: 0.09866565316915513 and parameters: {'batch_size': 32, 'lr': 9.673950741218285e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 3, 'noise_steps': 505, 'beta_end': 0.019048350099989945, 'dropout': 0.01306826764328381}. Best is trial 11 with value: 0.09866565316915513.\u001b[0m\n",
      "Epoch 1/200  Train: 72.0436  Val: 10.8285\n",
      "Epoch 2/200  Train: 6.2036  Val: 2.2847\n",
      "Epoch 3/200  Train: 1.3985  Val: 1.3054\n",
      "Epoch 4/200  Train: 1.1739  Val: 0.9381\n",
      "Epoch 5/200  Train: 1.0943  Val: 0.8471\n",
      "Epoch 6/200  Train: 1.1278  Val: 1.0278\n",
      "Epoch 7/200  Train: 0.9249  Val: 0.9126\n",
      "Epoch 8/200  Train: 0.9864  Val: 1.0278\n",
      "Epoch 9/200  Train: 1.0729  Val: 0.8654\n",
      "Epoch 10/200  Train: 1.0967  Val: 0.9927\n",
      "Epoch 11/200  Train: 0.9493  Val: 0.9142\n",
      "Epoch 12/200  Train: 0.9541  Val: 0.9381\n",
      "Epoch 13/200  Train: 1.0347  Val: 0.9156\n",
      "Epoch 14/200  Train: 1.0517  Val: 1.2256\n",
      "Epoch 15/200  Train: 1.0370  Val: 1.1965\n",
      "Epoch 16/200  Train: 1.1332  Val: 0.8435\n",
      "Epoch 17/200  Train: 1.0654  Val: 0.9209\n",
      "Epoch 18/200  Train: 1.0122  Val: 0.9090\n",
      "Epoch 19/200  Train: 0.9374  Val: 0.8799\n",
      "Epoch 20/200  Train: 0.8876  Val: 1.1190\n",
      "Epoch 21/200  Train: 0.8740  Val: 1.0102\n",
      "Epoch 22/200  Train: 0.8757  Val: 1.0543\n",
      "Epoch 23/200  Train: 0.9304  Val: 0.7154\n",
      "Epoch 24/200  Train: 0.8974  Val: 1.1321\n",
      "Epoch 25/200  Train: 0.8925  Val: 0.7517\n",
      "Epoch 26/200  Train: 0.8662  Val: 0.8330\n",
      "Epoch 27/200  Train: 0.9904  Val: 1.0275\n",
      "Epoch 28/200  Train: 0.9460  Val: 0.8682\n",
      "Epoch 29/200  Train: 1.1234  Val: 1.0076\n",
      "Epoch 30/200  Train: 0.8308  Val: 0.9863\n",
      "Epoch 31/200  Train: 0.9998  Val: 0.8571\n",
      "Epoch 32/200  Train: 1.1145  Val: 0.9666\n",
      "Epoch 33/200  Train: 0.8167  Val: 0.6994\n",
      "Epoch 34/200  Train: 0.8790  Val: 0.9975\n",
      "Epoch 35/200  Train: 0.8191  Val: 0.9155\n",
      "Epoch 36/200  Train: 0.8166  Val: 0.7535\n",
      "Epoch 37/200  Train: 0.8764  Val: 1.1421\n",
      "Epoch 38/200  Train: 0.8236  Val: 1.0324\n",
      "Epoch 39/200  Train: 0.8199  Val: 0.8002\n",
      "Epoch 40/200  Train: 1.0020  Val: 0.7980\n",
      "Epoch 41/200  Train: 0.8643  Val: 0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200  Train: 0.9075  Val: 0.8094\n",
      "Epoch 43/200  Train: 0.7063  Val: 0.9404\n",
      "Epoch 44/200  Train: 0.8101  Val: 0.8189\n",
      "Epoch 45/200  Train: 0.8959  Val: 0.6869\n",
      "Epoch 46/200  Train: 0.9221  Val: 0.7067\n",
      "Epoch 47/200  Train: 0.7718  Val: 0.8996\n",
      "Epoch 48/200  Train: 0.7101  Val: 0.7475\n",
      "Epoch 49/200  Train: 0.7970  Val: 0.9498\n",
      "Epoch 50/200  Train: 0.9861  Val: 0.9450\n",
      "Epoch 51/200  Train: 0.7340  Val: 0.8094\n",
      "Epoch 52/200  Train: 0.8047  Val: 0.8793\n",
      "Epoch 53/200  Train: 0.8765  Val: 0.8055\n",
      "Epoch 54/200  Train: 0.6724  Val: 0.7513\n",
      "Epoch 55/200  Train: 0.7324  Val: 0.9273\n",
      "Epoch 56/200  Train: 0.6697  Val: 0.7634\n",
      "Epoch 57/200  Train: 0.9296  Val: 0.8383\n",
      "Epoch 58/200  Train: 0.7622  Val: 0.6141\n",
      "Epoch 59/200  Train: 0.7370  Val: 1.0652\n",
      "Epoch 60/200  Train: 0.7989  Val: 0.5154\n",
      "Epoch 61/200  Train: 0.6991  Val: 1.1388\n",
      "Epoch 62/200  Train: 0.7503  Val: 0.6592\n",
      "Epoch 63/200  Train: 0.8140  Val: 0.7845\n",
      "Epoch 64/200  Train: 0.7169  Val: 0.8194\n",
      "Epoch 65/200  Train: 0.9197  Val: 0.8701\n",
      "Epoch 66/200  Train: 0.7176  Val: 0.6552\n",
      "Epoch 67/200  Train: 0.7887  Val: 0.6512\n",
      "Epoch 68/200  Train: 0.7409  Val: 1.0596\n",
      "Epoch 69/200  Train: 0.7686  Val: 0.7816\n",
      "Epoch 70/200  Train: 0.6855  Val: 0.7263\n",
      "Epoch 71/200  Train: 0.7251  Val: 0.6316\n",
      "Epoch 72/200  Train: 0.6561  Val: 0.7672\n",
      "Epoch 73/200  Train: 0.8264  Val: 0.5246\n",
      "Epoch 74/200  Train: 0.9196  Val: 0.7271\n",
      "Epoch 75/200  Train: 0.7036  Val: 0.6307\n",
      "Epoch 76/200  Train: 0.7134  Val: 0.6454\n",
      "Epoch 77/200  Train: 0.7758  Val: 1.2331\n",
      "Epoch 78/200  Train: 0.8641  Val: 0.7107\n",
      "Epoch 79/200  Train: 0.6616  Val: 0.6774\n",
      "Epoch 80/200  Train: 0.8941  Val: 0.5806\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:12,475]\u001b[0m Trial 12 finished with value: 0.5153787434101105 and parameters: {'batch_size': 32, 'lr': 5.730735076467602e-05, 'hidden_dim': 512, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 512, 'beta_end': 0.019762165184068016, 'dropout': 0.01050978670816129}. Best is trial 11 with value: 0.09866565316915513.\u001b[0m\n",
      "Epoch 1/200  Train: 12.1499  Val: 1.0016\n",
      "Epoch 2/200  Train: 1.6018  Val: 1.2582\n",
      "Epoch 3/200  Train: 1.3493  Val: 0.8223\n",
      "Epoch 4/200  Train: 1.0325  Val: 1.0254\n",
      "Epoch 5/200  Train: 1.0472  Val: 1.1351\n",
      "Epoch 6/200  Train: 1.1205  Val: 0.6807\n",
      "Epoch 7/200  Train: 1.0389  Val: 1.0492\n",
      "Epoch 8/200  Train: 1.0413  Val: 0.7099\n",
      "Epoch 9/200  Train: 0.9489  Val: 0.9176\n",
      "Epoch 10/200  Train: 1.0154  Val: 1.0125\n",
      "Epoch 11/200  Train: 0.9854  Val: 1.1020\n",
      "Epoch 12/200  Train: 0.9657  Val: 1.4515\n",
      "Epoch 13/200  Train: 0.9241  Val: 0.9138\n",
      "Epoch 14/200  Train: 0.9730  Val: 1.3616\n",
      "Epoch 15/200  Train: 1.4625  Val: 1.2491\n",
      "Epoch 16/200  Train: 1.3355  Val: 0.7832\n",
      "Epoch 17/200  Train: 0.7976  Val: 1.0491\n",
      "Epoch 18/200  Train: 0.9847  Val: 0.8986\n",
      "Epoch 19/200  Train: 0.8975  Val: 1.3308\n",
      "Epoch 20/200  Train: 0.8879  Val: 0.8882\n",
      "Epoch 21/200  Train: 0.9215  Val: 0.7087\n",
      "Epoch 22/200  Train: 0.8010  Val: 0.7007\n",
      "Epoch 23/200  Train: 0.8128  Val: 0.8522\n",
      "Epoch 24/200  Train: 0.7182  Val: 0.6116\n",
      "Epoch 25/200  Train: 0.7528  Val: 1.1737\n",
      "Epoch 26/200  Train: 0.9421  Val: 0.8856\n",
      "Epoch 27/200  Train: 1.0698  Val: 2.3684\n",
      "Epoch 28/200  Train: 1.3624  Val: 1.0874\n",
      "Epoch 29/200  Train: 1.6650  Val: 0.7704\n",
      "Epoch 30/200  Train: 0.9031  Val: 0.7591\n",
      "Epoch 31/200  Train: 0.8097  Val: 0.8772\n",
      "Epoch 32/200  Train: 0.9147  Val: 0.7271\n",
      "Epoch 33/200  Train: 0.6697  Val: 0.8539\n",
      "Epoch 34/200  Train: 0.7357  Val: 0.7088\n",
      "Epoch 35/200  Train: 0.7595  Val: 0.5857\n",
      "Epoch 36/200  Train: 0.7719  Val: 0.9185\n",
      "Epoch 37/200  Train: 0.7678  Val: 0.5414\n",
      "Epoch 38/200  Train: 0.6614  Val: 0.6693\n",
      "Epoch 39/200  Train: 0.6685  Val: 0.6217\n",
      "Epoch 40/200  Train: 0.6620  Val: 0.6603\n",
      "Epoch 41/200  Train: 0.6094  Val: 0.6390\n",
      "Epoch 42/200  Train: 0.7545  Val: 0.7076\n",
      "Epoch 43/200  Train: 0.6475  Val: 0.5744\n",
      "Epoch 44/200  Train: 0.6463  Val: 0.7017\n",
      "Epoch 45/200  Train: 0.6021  Val: 0.7089\n",
      "Epoch 46/200  Train: 0.6653  Val: 1.2401\n",
      "Epoch 47/200  Train: 0.6514  Val: 0.6653\n",
      "Epoch 48/200  Train: 0.6307  Val: 0.5103\n",
      "Epoch 49/200  Train: 0.5741  Val: 0.6528\n",
      "Epoch 50/200  Train: 0.6045  Val: 0.3951\n",
      "Epoch 51/200  Train: 0.9228  Val: 2.0123\n",
      "Epoch 52/200  Train: 1.0564  Val: 0.5609\n",
      "Epoch 53/200  Train: 0.5947  Val: 0.5725\n",
      "Epoch 54/200  Train: 0.5989  Val: 0.6069\n",
      "Epoch 55/200  Train: 0.6596  Val: 0.5179\n",
      "Epoch 56/200  Train: 0.5571  Val: 0.5400\n",
      "Epoch 57/200  Train: 0.5279  Val: 0.5637\n",
      "Epoch 58/200  Train: 0.4870  Val: 0.6619\n",
      "Epoch 59/200  Train: 0.5505  Val: 0.5016\n",
      "Epoch 60/200  Train: 0.5976  Val: 0.4256\n",
      "Epoch 61/200  Train: 0.5462  Val: 0.4472\n",
      "Epoch 62/200  Train: 0.5106  Val: 0.4521\n",
      "Epoch 63/200  Train: 0.5135  Val: 0.4730\n",
      "Epoch 64/200  Train: 0.4098  Val: 0.3933\n",
      "Epoch 65/200  Train: 0.4567  Val: 0.6230\n",
      "Epoch 66/200  Train: 0.4875  Val: 0.3650\n",
      "Epoch 67/200  Train: 0.6616  Val: 0.4823\n",
      "Epoch 68/200  Train: 0.6074  Val: 0.6442\n",
      "Epoch 69/200  Train: 0.4883  Val: 0.4728\n",
      "Epoch 70/200  Train: 0.4070  Val: 0.5356\n",
      "Epoch 71/200  Train: 0.5302  Val: 0.4405\n",
      "Epoch 72/200  Train: 0.4478  Val: 0.3946\n",
      "Epoch 73/200  Train: 0.3880  Val: 0.4842\n",
      "Epoch 74/200  Train: 0.4203  Val: 0.4032\n",
      "Epoch 75/200  Train: 0.3686  Val: 0.3840\n",
      "Epoch 76/200  Train: 0.3661  Val: 0.3830\n",
      "Epoch 77/200  Train: 0.3876  Val: 0.3991\n",
      "Epoch 78/200  Train: 0.4410  Val: 0.2663\n",
      "Epoch 79/200  Train: 0.4340  Val: 0.4379\n",
      "Epoch 80/200  Train: 0.3790  Val: 0.4912\n",
      "Epoch 81/200  Train: 0.3422  Val: 0.3278\n",
      "Epoch 82/200  Train: 0.3073  Val: 0.4211\n",
      "Epoch 83/200  Train: 0.3218  Val: 0.4792\n",
      "Epoch 84/200  Train: 0.3980  Val: 0.4925\n",
      "Epoch 85/200  Train: 0.4212  Val: 0.5187\n",
      "Epoch 86/200  Train: 0.3236  Val: 0.4307\n",
      "Epoch 87/200  Train: 0.3173  Val: 0.2362\n",
      "Epoch 88/200  Train: 0.2942  Val: 0.2585\n",
      "Epoch 89/200  Train: 0.3725  Val: 0.2948\n",
      "Epoch 90/200  Train: 0.3190  Val: 0.2585\n",
      "Epoch 91/200  Train: 0.3049  Val: 0.2074\n",
      "Epoch 92/200  Train: 0.2941  Val: 0.2734\n",
      "Epoch 93/200  Train: 0.4005  Val: 1.5605\n",
      "Epoch 94/200  Train: 0.5051  Val: 0.3501\n",
      "Epoch 95/200  Train: 0.2476  Val: 0.2403\n",
      "Epoch 96/200  Train: 0.2822  Val: 0.2332\n",
      "Epoch 97/200  Train: 0.2777  Val: 0.2891\n",
      "Epoch 98/200  Train: 0.2572  Val: 0.2771\n",
      "Epoch 99/200  Train: 0.2340  Val: 0.3048\n",
      "Epoch 100/200  Train: 0.2370  Val: 0.3136\n",
      "Epoch 101/200  Train: 0.3186  Val: 0.2284\n",
      "Epoch 102/200  Train: 0.3056  Val: 0.3063\n",
      "Epoch 103/200  Train: 0.2832  Val: 0.2215\n",
      "Epoch 104/200  Train: 0.2158  Val: 0.3001\n",
      "Epoch 105/200  Train: 0.1540  Val: 0.2204\n",
      "Epoch 106/200  Train: 0.1651  Val: 0.2576\n",
      "Epoch 107/200  Train: 0.1918  Val: 0.3267\n",
      "Epoch 108/200  Train: 0.1845  Val: 0.2182\n",
      "Epoch 109/200  Train: 0.1547  Val: 0.4364\n",
      "Epoch 110/200  Train: 0.2058  Val: 0.3625\n",
      "Epoch 111/200  Train: 0.1962  Val: 0.3543\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:19,273]\u001b[0m Trial 13 finished with value: 0.20741955637931825 and parameters: {'batch_size': 32, 'lr': 9.499211906730125e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 4, 'noise_steps': 745, 'beta_end': 0.015670138997027457, 'dropout': 0.011887056942916897}. Best is trial 11 with value: 0.09866565316915513.\u001b[0m\n",
      "Epoch 1/200  Train: 26.2812  Val: 11.1702\n",
      "Epoch 2/200  Train: 3.1492  Val: 1.8356\n",
      "Epoch 3/200  Train: 1.3066  Val: 0.8591\n",
      "Epoch 4/200  Train: 1.0308  Val: 0.9841\n",
      "Epoch 5/200  Train: 1.1100  Val: 0.9972\n",
      "Epoch 6/200  Train: 1.0438  Val: 0.6988\n",
      "Epoch 7/200  Train: 1.1667  Val: 0.9600\n",
      "Epoch 8/200  Train: 1.1261  Val: 0.7531\n",
      "Epoch 9/200  Train: 0.9749  Val: 0.9355\n",
      "Epoch 10/200  Train: 0.9877  Val: 1.0776\n",
      "Epoch 11/200  Train: 1.0873  Val: 1.1907\n",
      "Epoch 12/200  Train: 0.9416  Val: 1.3185\n",
      "Epoch 13/200  Train: 1.0436  Val: 1.0233\n",
      "Epoch 14/200  Train: 0.9364  Val: 1.3164\n",
      "Epoch 15/200  Train: 1.2373  Val: 1.3735\n",
      "Epoch 16/200  Train: 1.0522  Val: 0.9938\n",
      "Epoch 17/200  Train: 0.8422  Val: 1.4499\n",
      "Epoch 18/200  Train: 1.1046  Val: 1.3219\n",
      "Epoch 19/200  Train: 1.3131  Val: 2.5332\n",
      "Epoch 20/200  Train: 1.0472  Val: 0.9236\n",
      "Epoch 21/200  Train: 0.8578  Val: 0.7475\n",
      "Epoch 22/200  Train: 0.8630  Val: 0.7478\n",
      "Epoch 23/200  Train: 0.9039  Val: 0.8598\n",
      "Epoch 24/200  Train: 0.8402  Val: 0.6282\n",
      "Epoch 25/200  Train: 0.8037  Val: 1.0079\n",
      "Epoch 26/200  Train: 1.3434  Val: 1.6820\n",
      "Epoch 27/200  Train: 1.4893  Val: 1.5950\n",
      "Epoch 28/200  Train: 1.5324  Val: 1.0307\n",
      "Epoch 29/200  Train: 0.8293  Val: 0.8196\n",
      "Epoch 30/200  Train: 0.8384  Val: 1.1212\n",
      "Epoch 31/200  Train: 1.1206  Val: 0.9264\n",
      "Epoch 32/200  Train: 1.3091  Val: 0.6855\n",
      "Epoch 33/200  Train: 1.3168  Val: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200  Train: 0.8355  Val: 0.6943\n",
      "Epoch 35/200  Train: 0.7392  Val: 0.8724\n",
      "Epoch 36/200  Train: 0.8774  Val: 0.7556\n",
      "Epoch 37/200  Train: 0.9300  Val: 0.5315\n",
      "Epoch 38/200  Train: 0.7599  Val: 0.9001\n",
      "Epoch 39/200  Train: 0.8496  Val: 0.6176\n",
      "Epoch 40/200  Train: 0.7726  Val: 0.7546\n",
      "Epoch 41/200  Train: 0.6894  Val: 0.7060\n",
      "Epoch 42/200  Train: 1.0150  Val: 1.0128\n",
      "Epoch 43/200  Train: 0.9696  Val: 0.6588\n",
      "Epoch 44/200  Train: 0.9527  Val: 0.9657\n",
      "Epoch 45/200  Train: 0.7148  Val: 0.7738\n",
      "Epoch 46/200  Train: 0.7364  Val: 0.6833\n",
      "Epoch 47/200  Train: 0.6164  Val: 0.6252\n",
      "Epoch 48/200  Train: 0.6816  Val: 0.6368\n",
      "Epoch 49/200  Train: 0.6586  Val: 0.6770\n",
      "Epoch 50/200  Train: 0.6745  Val: 0.4859\n",
      "Epoch 51/200  Train: 0.8680  Val: 0.6538\n",
      "Epoch 52/200  Train: 0.6575  Val: 0.4872\n",
      "Epoch 53/200  Train: 0.5736  Val: 0.6365\n",
      "Epoch 54/200  Train: 0.8548  Val: 0.6715\n",
      "Epoch 55/200  Train: 0.6382  Val: 0.6456\n",
      "Epoch 56/200  Train: 0.6389  Val: 0.5006\n",
      "Epoch 57/200  Train: 0.6587  Val: 1.0577\n",
      "Epoch 58/200  Train: 0.5984  Val: 0.7439\n",
      "Epoch 59/200  Train: 0.7322  Val: 0.5652\n",
      "Epoch 60/200  Train: 0.5703  Val: 0.6596\n",
      "Epoch 61/200  Train: 0.7407  Val: 0.7149\n",
      "Epoch 62/200  Train: 0.7830  Val: 0.5603\n",
      "Epoch 63/200  Train: 0.8261  Val: 0.8740\n",
      "Epoch 64/200  Train: 0.5604  Val: 0.4632\n",
      "Epoch 65/200  Train: 0.5887  Val: 0.4438\n",
      "Epoch 66/200  Train: 0.6406  Val: 0.7525\n",
      "Epoch 67/200  Train: 0.8317  Val: 1.4137\n",
      "Epoch 68/200  Train: 0.8146  Val: 0.7540\n",
      "Epoch 69/200  Train: 0.6931  Val: 0.5947\n",
      "Epoch 70/200  Train: 0.4565  Val: 0.5127\n",
      "Epoch 71/200  Train: 0.5354  Val: 0.3958\n",
      "Epoch 72/200  Train: 0.4984  Val: 0.6522\n",
      "Epoch 73/200  Train: 0.4719  Val: 0.7662\n",
      "Epoch 74/200  Train: 0.5523  Val: 0.3999\n",
      "Epoch 75/200  Train: 0.4729  Val: 0.4373\n",
      "Epoch 76/200  Train: 0.4348  Val: 0.4059\n",
      "Epoch 77/200  Train: 0.5045  Val: 0.6426\n",
      "Epoch 78/200  Train: 0.5727  Val: 0.5086\n",
      "Epoch 79/200  Train: 0.5681  Val: 0.4621\n",
      "Epoch 80/200  Train: 0.4960  Val: 0.9474\n",
      "Epoch 81/200  Train: 0.7581  Val: 0.6134\n",
      "Epoch 82/200  Train: 0.6648  Val: 0.5787\n",
      "Epoch 83/200  Train: 0.4412  Val: 0.5628\n",
      "Epoch 84/200  Train: 0.4465  Val: 0.5210\n",
      "Epoch 85/200  Train: 0.4391  Val: 0.5103\n",
      "Epoch 86/200  Train: 0.4074  Val: 0.3931\n",
      "Epoch 87/200  Train: 0.4226  Val: 0.3376\n",
      "Epoch 88/200  Train: 0.3650  Val: 0.3057\n",
      "Epoch 89/200  Train: 0.4524  Val: 0.5378\n",
      "Epoch 90/200  Train: 0.4474  Val: 0.3962\n",
      "Epoch 91/200  Train: 0.4115  Val: 0.4135\n",
      "Epoch 92/200  Train: 0.3987  Val: 0.4012\n",
      "Epoch 93/200  Train: 0.4658  Val: 0.8801\n",
      "Epoch 94/200  Train: 0.4679  Val: 0.3388\n",
      "Epoch 95/200  Train: 0.3870  Val: 0.4013\n",
      "Epoch 96/200  Train: 0.4548  Val: 0.3913\n",
      "Epoch 97/200  Train: 0.4449  Val: 0.6958\n",
      "Epoch 98/200  Train: 0.4043  Val: 0.4723\n",
      "Epoch 99/200  Train: 0.3619  Val: 0.2293\n",
      "Epoch 100/200  Train: 0.2826  Val: 0.4866\n",
      "Epoch 101/200  Train: 0.3420  Val: 0.2879\n",
      "Epoch 102/200  Train: 0.3518  Val: 0.4258\n",
      "Epoch 103/200  Train: 0.3380  Val: 0.3285\n",
      "Epoch 104/200  Train: 0.2804  Val: 0.4394\n",
      "Epoch 105/200  Train: 0.3009  Val: 0.2959\n",
      "Epoch 106/200  Train: 0.4757  Val: 0.3417\n",
      "Epoch 107/200  Train: 0.3990  Val: 0.1946\n",
      "Epoch 108/200  Train: 0.3090  Val: 0.3365\n",
      "Epoch 109/200  Train: 0.3046  Val: 0.3175\n",
      "Epoch 110/200  Train: 0.3019  Val: 0.3521\n",
      "Epoch 111/200  Train: 0.3318  Val: 0.3033\n",
      "Epoch 112/200  Train: 0.2944  Val: 0.3148\n",
      "Epoch 113/200  Train: 0.2464  Val: 0.2133\n",
      "Epoch 114/200  Train: 0.2417  Val: 0.2887\n",
      "Epoch 115/200  Train: 0.3583  Val: 0.4110\n",
      "Epoch 116/200  Train: 0.2611  Val: 0.2081\n",
      "Epoch 117/200  Train: 0.2586  Val: 0.3329\n",
      "Epoch 118/200  Train: 0.4176  Val: 0.3415\n",
      "Epoch 119/200  Train: 0.3748  Val: 0.2697\n",
      "Epoch 120/200  Train: 0.3028  Val: 0.6063\n",
      "Epoch 121/200  Train: 0.3821  Val: 0.2952\n",
      "Epoch 122/200  Train: 0.2473  Val: 0.4200\n",
      "Epoch 123/200  Train: 0.2406  Val: 0.2168\n",
      "Epoch 124/200  Train: 0.2668  Val: 0.2790\n",
      "Epoch 125/200  Train: 0.1729  Val: 0.1676\n",
      "Epoch 126/200  Train: 0.1842  Val: 0.2292\n",
      "Epoch 127/200  Train: 0.1938  Val: 0.1986\n",
      "Epoch 128/200  Train: 0.1665  Val: 0.1995\n",
      "Epoch 129/200  Train: 0.2215  Val: 0.2043\n",
      "Epoch 130/200  Train: 0.1742  Val: 0.2515\n",
      "Epoch 131/200  Train: 0.1715  Val: 0.1414\n",
      "Epoch 132/200  Train: 0.1696  Val: 0.3976\n",
      "Epoch 133/200  Train: 0.1582  Val: 0.2306\n",
      "Epoch 134/200  Train: 0.1394  Val: 0.1624\n",
      "Epoch 135/200  Train: 0.1710  Val: 0.3390\n",
      "Epoch 136/200  Train: 0.1739  Val: 0.2316\n",
      "Epoch 137/200  Train: 0.1403  Val: 0.2278\n",
      "Epoch 138/200  Train: 0.1422  Val: 0.2595\n",
      "Epoch 139/200  Train: 0.1348  Val: 0.3186\n",
      "Epoch 140/200  Train: 0.1323  Val: 0.2204\n",
      "Epoch 141/200  Train: 0.1375  Val: 0.2267\n",
      "Epoch 142/200  Train: 0.1235  Val: 0.1112\n",
      "Epoch 143/200  Train: 0.1745  Val: 0.4646\n",
      "Epoch 144/200  Train: 0.0935  Val: 0.4418\n",
      "Epoch 145/200  Train: 0.1046  Val: 0.1610\n",
      "Epoch 146/200  Train: 0.1244  Val: 0.3208\n",
      "Epoch 147/200  Train: 0.1390  Val: 0.1794\n",
      "Epoch 148/200  Train: 0.1051  Val: 0.3791\n",
      "Epoch 149/200  Train: 0.1873  Val: 0.1983\n",
      "Epoch 150/200  Train: 0.1145  Val: 0.3486\n",
      "Epoch 151/200  Train: 0.1107  Val: 0.6354\n",
      "Epoch 152/200  Train: 0.0997  Val: 0.3042\n",
      "Epoch 153/200  Train: 0.0765  Val: 0.2714\n",
      "Epoch 154/200  Train: 0.0902  Val: 0.1485\n",
      "Epoch 155/200  Train: 0.0843  Val: 0.4705\n",
      "Epoch 156/200  Train: 0.1598  Val: 0.2444\n",
      "Epoch 157/200  Train: 0.1270  Val: 0.2921\n",
      "Epoch 158/200  Train: 0.1485  Val: 0.2181\n",
      "Epoch 159/200  Train: 0.1223  Val: 0.1989\n",
      "Epoch 160/200  Train: 0.1169  Val: 0.2651\n",
      "Epoch 161/200  Train: 0.1222  Val: 0.1975\n",
      "Epoch 162/200  Train: 0.1476  Val: 0.2012\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:30,833]\u001b[0m Trial 14 finished with value: 0.11117055416107177 and parameters: {'batch_size': 32, 'lr': 6.101470476139696e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 4, 'noise_steps': 554, 'beta_end': 0.018519431757111238, 'dropout': 0.028320040012959097}. Best is trial 11 with value: 0.09866565316915513.\u001b[0m\n",
      "Epoch 1/200  Train: 4.8437  Val: 0.9847\n",
      "Epoch 2/200  Train: 1.4818  Val: 1.3721\n",
      "Epoch 3/200  Train: 1.2827  Val: 0.8365\n",
      "Epoch 4/200  Train: 1.0314  Val: 0.9179\n",
      "Epoch 5/200  Train: 1.0395  Val: 0.9892\n",
      "Epoch 6/200  Train: 1.0929  Val: 0.6903\n",
      "Epoch 7/200  Train: 1.1315  Val: 0.9667\n",
      "Epoch 8/200  Train: 1.0128  Val: 0.8625\n",
      "Epoch 9/200  Train: 1.0443  Val: 1.0388\n",
      "Epoch 10/200  Train: 1.2158  Val: 1.0465\n",
      "Epoch 11/200  Train: 1.0395  Val: 1.0681\n",
      "Epoch 12/200  Train: 0.9709  Val: 1.2670\n",
      "Epoch 13/200  Train: 1.0904  Val: 1.0737\n",
      "Epoch 14/200  Train: 1.0207  Val: 1.8106\n",
      "Epoch 15/200  Train: 1.5106  Val: 1.1500\n",
      "Epoch 16/200  Train: 1.5597  Val: 2.0057\n",
      "Epoch 17/200  Train: 1.2008  Val: 1.1735\n",
      "Epoch 18/200  Train: 0.9592  Val: 0.8798\n",
      "Epoch 19/200  Train: 0.9666  Val: 1.5605\n",
      "Epoch 20/200  Train: 0.8833  Val: 1.6118\n",
      "Epoch 21/200  Train: 0.9566  Val: 0.8298\n",
      "Epoch 22/200  Train: 0.9133  Val: 0.7943\n",
      "Epoch 23/200  Train: 1.0644  Val: 1.1360\n",
      "Epoch 24/200  Train: 1.0193  Val: 0.7333\n",
      "Epoch 25/200  Train: 0.8710  Val: 0.9749\n",
      "Epoch 26/200  Train: 1.2377  Val: 1.0155\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:32,450]\u001b[0m Trial 15 finished with value: 0.6902732729911805 and parameters: {'batch_size': 32, 'lr': 3.366988109669095e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 4, 'noise_steps': 963, 'beta_end': 0.016595970237544687, 'dropout': 0.011472449597958886}. Best is trial 11 with value: 0.09866565316915513.\u001b[0m\n",
      "Epoch 1/200  Train: 38.1977  Val: 10.2826\n",
      "Epoch 2/200  Train: 3.4465  Val: 1.4088\n",
      "Epoch 3/200  Train: 1.4187  Val: 1.8978\n",
      "Epoch 4/200  Train: 1.2071  Val: 1.3788\n",
      "Epoch 5/200  Train: 1.1193  Val: 1.0818\n",
      "Epoch 6/200  Train: 1.0636  Val: 0.9827\n",
      "Epoch 7/200  Train: 1.1183  Val: 0.9421\n",
      "Epoch 8/200  Train: 0.9800  Val: 1.0009\n",
      "Epoch 9/200  Train: 1.0347  Val: 0.9408\n",
      "Epoch 10/200  Train: 0.9972  Val: 0.8726\n",
      "Epoch 11/200  Train: 1.0208  Val: 1.2519\n",
      "Epoch 12/200  Train: 1.5234  Val: 1.1206\n",
      "Epoch 13/200  Train: 1.0228  Val: 1.0525\n",
      "Epoch 14/200  Train: 0.9722  Val: 0.9013\n",
      "Epoch 15/200  Train: 0.9065  Val: 1.0362\n",
      "Epoch 16/200  Train: 0.9681  Val: 1.5031\n",
      "Epoch 17/200  Train: 1.1651  Val: 0.9850\n",
      "Epoch 18/200  Train: 1.0280  Val: 0.9128\n",
      "Epoch 19/200  Train: 1.0264  Val: 1.5683\n",
      "Epoch 20/200  Train: 0.9014  Val: 1.0291\n",
      "Epoch 21/200  Train: 1.2215  Val: 0.8492\n",
      "Epoch 22/200  Train: 1.1783  Val: 0.8150\n",
      "Epoch 23/200  Train: 1.0519  Val: 1.0311\n",
      "Epoch 24/200  Train: 1.1439  Val: 0.7068\n",
      "Epoch 25/200  Train: 0.8975  Val: 0.8630\n",
      "Epoch 26/200  Train: 0.8375  Val: 1.0701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200  Train: 1.1347  Val: 1.1877\n",
      "Epoch 28/200  Train: 0.9771  Val: 0.8746\n",
      "Epoch 29/200  Train: 0.8766  Val: 0.7694\n",
      "Epoch 30/200  Train: 0.8532  Val: 1.1709\n",
      "Epoch 31/200  Train: 1.1487  Val: 2.3317\n",
      "Epoch 32/200  Train: 1.0703  Val: 0.8157\n",
      "Epoch 33/200  Train: 1.0664  Val: 2.6122\n",
      "Epoch 34/200  Train: 1.0795  Val: 0.5980\n",
      "Epoch 35/200  Train: 0.9612  Val: 0.8791\n",
      "Epoch 36/200  Train: 0.7881  Val: 0.5419\n",
      "Epoch 37/200  Train: 0.7027  Val: 0.7302\n",
      "Epoch 38/200  Train: 0.9646  Val: 1.8793\n",
      "Epoch 39/200  Train: 1.1040  Val: 0.7883\n",
      "Epoch 40/200  Train: 0.8402  Val: 0.6724\n",
      "Epoch 41/200  Train: 0.8532  Val: 0.6701\n",
      "Epoch 42/200  Train: 0.9009  Val: 0.8171\n",
      "Epoch 43/200  Train: 0.8678  Val: 0.7699\n",
      "Epoch 44/200  Train: 0.6064  Val: 0.6072\n",
      "Epoch 45/200  Train: 0.6926  Val: 0.6765\n",
      "Epoch 46/200  Train: 0.6801  Val: 0.9308\n",
      "Epoch 47/200  Train: 0.7266  Val: 0.5495\n",
      "Epoch 48/200  Train: 0.8862  Val: 0.5381\n",
      "Epoch 49/200  Train: 0.6478  Val: 0.6935\n",
      "Epoch 50/200  Train: 0.6937  Val: 0.5550\n",
      "Epoch 51/200  Train: 0.6840  Val: 0.5584\n",
      "Epoch 52/200  Train: 0.5643  Val: 0.5306\n",
      "Epoch 53/200  Train: 0.5837  Val: 0.5032\n",
      "Epoch 54/200  Train: 0.6123  Val: 0.8895\n",
      "Epoch 55/200  Train: 0.7281  Val: 0.7662\n",
      "Epoch 56/200  Train: 0.5592  Val: 0.8384\n",
      "Epoch 57/200  Train: 0.7850  Val: 0.7884\n",
      "Epoch 58/200  Train: 0.6446  Val: 1.1704\n",
      "Epoch 59/200  Train: 0.9497  Val: 0.9791\n",
      "Epoch 60/200  Train: 1.2923  Val: 1.3130\n",
      "Epoch 61/200  Train: 0.6411  Val: 0.3756\n",
      "Epoch 62/200  Train: 0.4828  Val: 0.5175\n",
      "Epoch 63/200  Train: 0.4670  Val: 0.7192\n",
      "Epoch 64/200  Train: 0.5986  Val: 1.1163\n",
      "Epoch 65/200  Train: 0.7662  Val: 0.6941\n",
      "Epoch 66/200  Train: 0.4558  Val: 0.6102\n",
      "Epoch 67/200  Train: 0.8131  Val: 0.7571\n",
      "Epoch 68/200  Train: 0.5339  Val: 0.5434\n",
      "Epoch 69/200  Train: 0.5719  Val: 0.6748\n",
      "Epoch 70/200  Train: 1.0782  Val: 1.3894\n",
      "Epoch 71/200  Train: 0.8418  Val: 0.9132\n",
      "Epoch 72/200  Train: 0.6717  Val: 0.8064\n",
      "Epoch 73/200  Train: 0.5011  Val: 0.4352\n",
      "Epoch 74/200  Train: 0.5170  Val: 0.4662\n",
      "Epoch 75/200  Train: 0.5003  Val: 0.4501\n",
      "Epoch 76/200  Train: 0.4341  Val: 0.5454\n",
      "Epoch 77/200  Train: 0.4146  Val: 0.3457\n",
      "Epoch 78/200  Train: 0.5272  Val: 0.4031\n",
      "Epoch 79/200  Train: 0.6296  Val: 0.4170\n",
      "Epoch 80/200  Train: 0.4830  Val: 0.4749\n",
      "Epoch 81/200  Train: 0.5378  Val: 0.4453\n",
      "Epoch 82/200  Train: 0.3948  Val: 0.5841\n",
      "Epoch 83/200  Train: 0.4288  Val: 0.3600\n",
      "Epoch 84/200  Train: 0.3643  Val: 0.3957\n",
      "Epoch 85/200  Train: 0.4339  Val: 0.3781\n",
      "Epoch 86/200  Train: 0.4693  Val: 0.4246\n",
      "Epoch 87/200  Train: 0.4184  Val: 0.3843\n",
      "Epoch 88/200  Train: 0.3427  Val: 0.2922\n",
      "Epoch 89/200  Train: 0.4416  Val: 0.3392\n",
      "Epoch 90/200  Train: 0.4062  Val: 0.3893\n",
      "Epoch 91/200  Train: 0.4593  Val: 0.2852\n",
      "Epoch 92/200  Train: 0.3421  Val: 0.6095\n",
      "Epoch 93/200  Train: 0.5371  Val: 0.4721\n",
      "Epoch 94/200  Train: 0.5244  Val: 0.5302\n",
      "Epoch 95/200  Train: 0.4155  Val: 0.2100\n",
      "Epoch 96/200  Train: 0.8495  Val: 0.6118\n",
      "Epoch 97/200  Train: 0.4399  Val: 0.5342\n",
      "Epoch 98/200  Train: 0.4348  Val: 0.4254\n",
      "Epoch 99/200  Train: 0.3575  Val: 0.2924\n",
      "Epoch 100/200  Train: 0.3865  Val: 0.2960\n",
      "Epoch 101/200  Train: 0.3239  Val: 0.2901\n",
      "Epoch 102/200  Train: 0.3643  Val: 0.7802\n",
      "Epoch 103/200  Train: 0.3886  Val: 0.5363\n",
      "Epoch 104/200  Train: 0.4557  Val: 0.2760\n",
      "Epoch 105/200  Train: 0.3754  Val: 0.2789\n",
      "Epoch 106/200  Train: 0.3660  Val: 0.4494\n",
      "Epoch 107/200  Train: 0.3275  Val: 0.2615\n",
      "Epoch 108/200  Train: 0.2696  Val: 0.3286\n",
      "Epoch 109/200  Train: 0.2477  Val: 0.1931\n",
      "Epoch 110/200  Train: 0.2593  Val: 0.2944\n",
      "Epoch 111/200  Train: 0.3501  Val: 0.2499\n",
      "Epoch 112/200  Train: 0.2410  Val: 0.2327\n",
      "Epoch 113/200  Train: 0.2004  Val: 0.2446\n",
      "Epoch 114/200  Train: 0.2617  Val: 0.4356\n",
      "Epoch 115/200  Train: 0.2485  Val: 0.2565\n",
      "Epoch 116/200  Train: 0.2466  Val: 0.1995\n",
      "Epoch 117/200  Train: 0.3173  Val: 0.3296\n",
      "Epoch 118/200  Train: 0.2518  Val: 0.2532\n",
      "Epoch 119/200  Train: 0.2501  Val: 0.3076\n",
      "Epoch 120/200  Train: 0.2927  Val: 0.3447\n",
      "Epoch 121/200  Train: 0.3467  Val: 0.4457\n",
      "Epoch 122/200  Train: 0.2646  Val: 0.2343\n",
      "Epoch 123/200  Train: 0.2213  Val: 0.2554\n",
      "Epoch 124/200  Train: 0.2094  Val: 0.2203\n",
      "Epoch 125/200  Train: 0.2565  Val: 0.1740\n",
      "Epoch 126/200  Train: 0.2363  Val: 0.1424\n",
      "Epoch 127/200  Train: 0.2240  Val: 0.2740\n",
      "Epoch 128/200  Train: 0.2035  Val: 0.1470\n",
      "Epoch 129/200  Train: 0.1893  Val: 0.2004\n",
      "Epoch 130/200  Train: 0.1865  Val: 0.2024\n",
      "Epoch 131/200  Train: 0.1653  Val: 0.3540\n",
      "Epoch 132/200  Train: 0.1704  Val: 0.2671\n",
      "Epoch 133/200  Train: 0.1784  Val: 0.2852\n",
      "Epoch 134/200  Train: 0.2302  Val: 0.1916\n",
      "Epoch 135/200  Train: 0.1461  Val: 0.1976\n",
      "Epoch 136/200  Train: 0.1537  Val: 0.1984\n",
      "Epoch 137/200  Train: 0.2261  Val: 0.4665\n",
      "Epoch 138/200  Train: 0.3412  Val: 0.4976\n",
      "Epoch 139/200  Train: 0.2267  Val: 0.2420\n",
      "Epoch 140/200  Train: 0.1278  Val: 0.2068\n",
      "Epoch 141/200  Train: 0.1484  Val: 0.1492\n",
      "Epoch 142/200  Train: 0.2430  Val: 0.0867\n",
      "Epoch 143/200  Train: 0.1209  Val: 0.2248\n",
      "Epoch 144/200  Train: 0.1131  Val: 0.2393\n",
      "Epoch 145/200  Train: 0.1639  Val: 0.1489\n",
      "Epoch 146/200  Train: 0.2318  Val: 0.3528\n",
      "Epoch 147/200  Train: 0.3410  Val: 0.2625\n",
      "Epoch 148/200  Train: 0.1600  Val: 0.1507\n",
      "Epoch 149/200  Train: 0.1656  Val: 0.2670\n",
      "Epoch 150/200  Train: 0.1599  Val: 0.1684\n",
      "Epoch 151/200  Train: 0.1354  Val: 0.1999\n",
      "Epoch 152/200  Train: 0.1408  Val: 0.2731\n",
      "Epoch 153/200  Train: 0.1233  Val: 0.2311\n",
      "Epoch 154/200  Train: 0.0846  Val: 0.2154\n",
      "Epoch 155/200  Train: 0.1002  Val: 0.2314\n",
      "Epoch 156/200  Train: 0.1084  Val: 0.4527\n",
      "Epoch 157/200  Train: 0.1118  Val: 0.1371\n",
      "Epoch 158/200  Train: 0.1760  Val: 0.9511\n",
      "Epoch 159/200  Train: 0.5797  Val: 0.2983\n",
      "Epoch 160/200  Train: 0.3124  Val: 0.2875\n",
      "Epoch 161/200  Train: 0.1562  Val: 0.3235\n",
      "Epoch 162/200  Train: 0.1230  Val: 0.2969\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:45,869]\u001b[0m Trial 16 finished with value: 0.08671222105622292 and parameters: {'batch_size': 32, 'lr': 6.91825418598905e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 5, 'noise_steps': 685, 'beta_end': 0.018081993891564663, 'dropout': 0.03553598821559284}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 4.3410  Val: 1.0928\n",
      "Epoch 2/200  Train: 1.2498  Val: 0.9763\n",
      "Epoch 3/200  Train: 1.0391  Val: 0.9036\n",
      "Epoch 4/200  Train: 1.0026  Val: 1.2389\n",
      "Epoch 5/200  Train: 1.1871  Val: 1.2282\n",
      "Epoch 6/200  Train: 1.1508  Val: 1.0992\n",
      "Epoch 7/200  Train: 1.1284  Val: 0.9418\n",
      "Epoch 8/200  Train: 0.9887  Val: 1.1387\n",
      "Epoch 9/200  Train: 1.0145  Val: 1.0157\n",
      "Epoch 10/200  Train: 1.0225  Val: 0.8397\n",
      "Epoch 11/200  Train: 1.1211  Val: 1.1184\n",
      "Epoch 12/200  Train: 1.2015  Val: 1.0233\n",
      "Epoch 13/200  Train: 1.0475  Val: 1.2222\n",
      "Epoch 14/200  Train: 1.1851  Val: 0.9632\n",
      "Epoch 15/200  Train: 0.9891  Val: 0.9755\n",
      "Epoch 16/200  Train: 0.9956  Val: 1.1849\n",
      "Epoch 17/200  Train: 1.0349  Val: 0.9429\n",
      "Epoch 18/200  Train: 0.9747  Val: 1.0303\n",
      "Epoch 19/200  Train: 0.9593  Val: 1.0019\n",
      "Epoch 20/200  Train: 1.0259  Val: 1.0670\n",
      "Epoch 21/200  Train: 1.1306  Val: 1.6954\n",
      "Epoch 22/200  Train: 1.0635  Val: 1.1028\n",
      "Epoch 23/200  Train: 0.9845  Val: 0.8515\n",
      "Epoch 24/200  Train: 1.0134  Val: 0.8248\n",
      "Epoch 25/200  Train: 0.9329  Val: 0.8551\n",
      "Epoch 26/200  Train: 0.9163  Val: 1.0809\n",
      "Epoch 27/200  Train: 0.9328  Val: 0.9805\n",
      "Epoch 28/200  Train: 0.9993  Val: 0.8655\n",
      "Epoch 29/200  Train: 1.1293  Val: 0.9441\n",
      "Epoch 30/200  Train: 1.0730  Val: 0.9725\n",
      "Epoch 31/200  Train: 0.9905  Val: 1.0152\n",
      "Epoch 32/200  Train: 0.9067  Val: 0.8932\n",
      "Epoch 33/200  Train: 1.0104  Val: 1.0845\n",
      "Epoch 34/200  Train: 0.8809  Val: 0.7870\n",
      "Epoch 35/200  Train: 0.8808  Val: 1.0497\n",
      "Epoch 36/200  Train: 0.8206  Val: 0.6449\n",
      "Epoch 37/200  Train: 0.9280  Val: 0.8897\n",
      "Epoch 38/200  Train: 0.9808  Val: 0.7855\n",
      "Epoch 39/200  Train: 0.9149  Val: 0.9604\n",
      "Epoch 40/200  Train: 1.0185  Val: 0.7846\n",
      "Epoch 41/200  Train: 1.0495  Val: 0.8040\n",
      "Epoch 42/200  Train: 0.9096  Val: 0.8555\n",
      "Epoch 43/200  Train: 0.8621  Val: 1.0117\n",
      "Epoch 44/200  Train: 0.8207  Val: 0.8607\n",
      "Epoch 45/200  Train: 0.8778  Val: 1.1231\n",
      "Epoch 46/200  Train: 0.9283  Val: 0.7456\n",
      "Epoch 47/200  Train: 0.8109  Val: 1.1863\n",
      "Epoch 48/200  Train: 1.0435  Val: 0.7227\n",
      "Epoch 49/200  Train: 0.9850  Val: 0.8658\n",
      "Epoch 50/200  Train: 0.9646  Val: 0.9206\n",
      "Epoch 51/200  Train: 0.9200  Val: 0.8655\n",
      "Epoch 52/200  Train: 0.8889  Val: 1.1490\n",
      "Epoch 53/200  Train: 0.9603  Val: 0.7975\n",
      "Epoch 54/200  Train: 0.8558  Val: 0.7821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200  Train: 0.9814  Val: 0.7852\n",
      "Epoch 56/200  Train: 0.7737  Val: 1.1616\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:49,743]\u001b[0m Trial 17 finished with value: 0.6449318289756775 and parameters: {'batch_size': 32, 'lr': 3.508951850120781e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 5, 'noise_steps': 679, 'beta_end': 0.01449808343758368, 'dropout': 0.03838867380279488}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 94.4071  Val: 4.9398\n",
      "Epoch 2/200  Train: 9.4543  Val: 1.6856\n",
      "Epoch 3/200  Train: 2.3745  Val: 1.1840\n",
      "Epoch 4/200  Train: 1.1168  Val: 1.1566\n",
      "Epoch 5/200  Train: 1.2280  Val: 0.8655\n",
      "Epoch 6/200  Train: 1.0480  Val: 1.0125\n",
      "Epoch 7/200  Train: 1.1270  Val: 0.9345\n",
      "Epoch 8/200  Train: 1.0090  Val: 1.1152\n",
      "Epoch 9/200  Train: 0.9950  Val: 0.9139\n",
      "Epoch 10/200  Train: 0.9934  Val: 0.7711\n",
      "Epoch 11/200  Train: 0.9641  Val: 1.0977\n",
      "Epoch 12/200  Train: 0.9985  Val: 0.9328\n",
      "Epoch 13/200  Train: 0.8922  Val: 0.9167\n",
      "Epoch 14/200  Train: 1.0150  Val: 0.7774\n",
      "Epoch 15/200  Train: 0.8521  Val: 0.9076\n",
      "Epoch 16/200  Train: 1.0301  Val: 1.1457\n",
      "Epoch 17/200  Train: 0.9288  Val: 0.7878\n",
      "Epoch 18/200  Train: 0.8408  Val: 0.8675\n",
      "Epoch 19/200  Train: 0.8329  Val: 0.9045\n",
      "Epoch 20/200  Train: 0.8107  Val: 0.9076\n",
      "Epoch 21/200  Train: 0.8653  Val: 0.8286\n",
      "Epoch 22/200  Train: 0.8246  Val: 0.7682\n",
      "Epoch 23/200  Train: 0.7233  Val: 0.6985\n",
      "Epoch 24/200  Train: 0.8016  Val: 0.7069\n",
      "Epoch 25/200  Train: 0.7488  Val: 0.7023\n",
      "Epoch 26/200  Train: 0.7175  Val: 0.9177\n",
      "Epoch 27/200  Train: 0.7729  Val: 0.7320\n",
      "Epoch 28/200  Train: 0.7504  Val: 0.7012\n",
      "Epoch 29/200  Train: 0.9018  Val: 1.0732\n",
      "Epoch 30/200  Train: 1.2007  Val: 0.7890\n",
      "Epoch 31/200  Train: 0.9304  Val: 0.6770\n",
      "Epoch 32/200  Train: 0.6757  Val: 0.6935\n",
      "Epoch 33/200  Train: 0.7215  Val: 0.6360\n",
      "Epoch 34/200  Train: 0.6666  Val: 0.5826\n",
      "Epoch 35/200  Train: 0.7051  Val: 0.8720\n",
      "Epoch 36/200  Train: 0.5982  Val: 0.4958\n",
      "Epoch 37/200  Train: 0.6578  Val: 0.5630\n",
      "Epoch 38/200  Train: 0.6663  Val: 0.5703\n",
      "Epoch 39/200  Train: 0.6574  Val: 0.6478\n",
      "Epoch 40/200  Train: 0.6651  Val: 0.5862\n",
      "Epoch 41/200  Train: 0.6461  Val: 0.6081\n",
      "Epoch 42/200  Train: 0.5707  Val: 0.5911\n",
      "Epoch 43/200  Train: 0.6619  Val: 0.7110\n",
      "Epoch 44/200  Train: 0.5948  Val: 0.6302\n",
      "Epoch 45/200  Train: 0.5588  Val: 0.5462\n",
      "Epoch 46/200  Train: 0.5308  Val: 0.5072\n",
      "Epoch 47/200  Train: 0.5871  Val: 0.6431\n",
      "Epoch 48/200  Train: 0.7822  Val: 0.6042\n",
      "Epoch 49/200  Train: 0.5582  Val: 0.5107\n",
      "Epoch 50/200  Train: 0.5851  Val: 0.4776\n",
      "Epoch 51/200  Train: 0.6399  Val: 0.4209\n",
      "Epoch 52/200  Train: 0.5527  Val: 0.4513\n",
      "Epoch 53/200  Train: 0.5112  Val: 0.5029\n",
      "Epoch 54/200  Train: 0.5051  Val: 0.7210\n",
      "Epoch 55/200  Train: 0.5333  Val: 0.3959\n",
      "Epoch 56/200  Train: 0.4307  Val: 0.3614\n",
      "Epoch 57/200  Train: 0.4551  Val: 0.5479\n",
      "Epoch 58/200  Train: 0.4974  Val: 0.3720\n",
      "Epoch 59/200  Train: 0.5048  Val: 0.5458\n",
      "Epoch 60/200  Train: 0.5511  Val: 0.4457\n",
      "Epoch 61/200  Train: 0.5163  Val: 0.3253\n",
      "Epoch 62/200  Train: 0.3936  Val: 0.3722\n",
      "Epoch 63/200  Train: 0.3719  Val: 0.4630\n",
      "Epoch 64/200  Train: 0.4806  Val: 0.4705\n",
      "Epoch 65/200  Train: 0.4115  Val: 0.4580\n",
      "Epoch 66/200  Train: 0.3554  Val: 0.3819\n",
      "Epoch 67/200  Train: 0.4535  Val: 0.5776\n",
      "Epoch 68/200  Train: 0.3898  Val: 0.3214\n",
      "Epoch 69/200  Train: 0.3566  Val: 0.7808\n",
      "Epoch 70/200  Train: 0.5570  Val: 0.3346\n",
      "Epoch 71/200  Train: 0.3104  Val: 0.4958\n",
      "Epoch 72/200  Train: 0.3446  Val: 0.5118\n",
      "Epoch 73/200  Train: 0.3936  Val: 0.3886\n",
      "Epoch 74/200  Train: 0.4422  Val: 0.4511\n",
      "Epoch 75/200  Train: 0.4339  Val: 0.4830\n",
      "Epoch 76/200  Train: 0.4003  Val: 0.2443\n",
      "Epoch 77/200  Train: 0.3712  Val: 0.3527\n",
      "Epoch 78/200  Train: 0.4532  Val: 0.2217\n",
      "Epoch 79/200  Train: 0.2854  Val: 0.2987\n",
      "Epoch 80/200  Train: 0.4332  Val: 0.5718\n",
      "Epoch 81/200  Train: 0.4793  Val: 0.3882\n",
      "Epoch 82/200  Train: 0.2978  Val: 0.2164\n",
      "Epoch 83/200  Train: 0.2992  Val: 0.3350\n",
      "Epoch 84/200  Train: 0.2930  Val: 0.2761\n",
      "Epoch 85/200  Train: 0.2441  Val: 0.2151\n",
      "Epoch 86/200  Train: 0.2592  Val: 0.2742\n",
      "Epoch 87/200  Train: 0.2969  Val: 0.2742\n",
      "Epoch 88/200  Train: 0.2570  Val: 0.2079\n",
      "Epoch 89/200  Train: 0.2392  Val: 0.2861\n",
      "Epoch 90/200  Train: 0.2398  Val: 0.2437\n",
      "Epoch 91/200  Train: 0.3275  Val: 0.2401\n",
      "Epoch 92/200  Train: 0.2084  Val: 0.2480\n",
      "Epoch 93/200  Train: 0.2195  Val: 0.3509\n",
      "Epoch 94/200  Train: 0.3321  Val: 0.3264\n",
      "Epoch 95/200  Train: 0.2682  Val: 0.1305\n",
      "Epoch 96/200  Train: 0.2226  Val: 0.2462\n",
      "Epoch 97/200  Train: 0.1788  Val: 0.3170\n",
      "Epoch 98/200  Train: 0.2426  Val: 0.5409\n",
      "Epoch 99/200  Train: 0.2252  Val: 0.1969\n",
      "Epoch 100/200  Train: 0.1879  Val: 0.2148\n",
      "Epoch 101/200  Train: 0.1974  Val: 0.1574\n",
      "Epoch 102/200  Train: 0.2905  Val: 0.2780\n",
      "Epoch 103/200  Train: 0.1772  Val: 0.2642\n",
      "Epoch 104/200  Train: 0.2616  Val: 0.4673\n",
      "Epoch 105/200  Train: 0.2378  Val: 0.2787\n",
      "Epoch 106/200  Train: 0.2103  Val: 0.2877\n",
      "Epoch 107/200  Train: 0.1650  Val: 0.2179\n",
      "Epoch 108/200  Train: 0.1945  Val: 0.2098\n",
      "Epoch 109/200  Train: 0.2940  Val: 0.2400\n",
      "Epoch 110/200  Train: 0.1537  Val: 0.2431\n",
      "Epoch 111/200  Train: 0.1314  Val: 0.1964\n",
      "Epoch 112/200  Train: 0.1470  Val: 0.2698\n",
      "Epoch 113/200  Train: 0.1878  Val: 0.1848\n",
      "Epoch 114/200  Train: 0.1547  Val: 0.1824\n",
      "Epoch 115/200  Train: 0.1330  Val: 0.2807\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:36:59,330]\u001b[0m Trial 18 finished with value: 0.13048603683710097 and parameters: {'batch_size': 32, 'lr': 9.611412363897316e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 5, 'noise_steps': 562, 'beta_end': 0.019993189079146375, 'dropout': 0.03279421359899993}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 35.4385  Val: 11.6460\n",
      "Epoch 2/200  Train: 4.7495  Val: 1.5304\n",
      "Epoch 3/200  Train: 1.4711  Val: 1.2734\n",
      "Epoch 4/200  Train: 1.0197  Val: 0.9856\n",
      "Epoch 5/200  Train: 1.0495  Val: 0.9972\n",
      "Epoch 6/200  Train: 0.9686  Val: 0.9962\n",
      "Epoch 7/200  Train: 1.0063  Val: 0.8838\n",
      "Epoch 8/200  Train: 0.9253  Val: 1.0954\n",
      "Epoch 9/200  Train: 0.9986  Val: 0.9576\n",
      "Epoch 10/200  Train: 0.9934  Val: 1.1301\n",
      "Epoch 11/200  Train: 1.0380  Val: 1.0464\n",
      "Epoch 12/200  Train: 0.9314  Val: 0.9198\n",
      "Epoch 13/200  Train: 0.8749  Val: 1.0544\n",
      "Epoch 14/200  Train: 0.9806  Val: 0.9348\n",
      "Epoch 15/200  Train: 1.0210  Val: 0.8933\n",
      "Epoch 16/200  Train: 0.9560  Val: 0.7819\n",
      "Epoch 17/200  Train: 0.9858  Val: 1.6547\n",
      "Epoch 18/200  Train: 1.2945  Val: 0.7297\n",
      "Epoch 19/200  Train: 1.0973  Val: 1.1580\n",
      "Epoch 20/200  Train: 1.0528  Val: 1.2540\n",
      "Epoch 21/200  Train: 0.9530  Val: 1.0066\n",
      "Epoch 22/200  Train: 0.8565  Val: 1.0447\n",
      "Epoch 23/200  Train: 0.9799  Val: 0.9226\n",
      "Epoch 24/200  Train: 0.9003  Val: 0.8939\n",
      "Epoch 25/200  Train: 1.0150  Val: 0.6954\n",
      "Epoch 26/200  Train: 0.8432  Val: 0.8474\n",
      "Epoch 27/200  Train: 0.8680  Val: 0.9846\n",
      "Epoch 28/200  Train: 0.9602  Val: 0.8908\n",
      "Epoch 29/200  Train: 0.8584  Val: 1.0897\n",
      "Epoch 30/200  Train: 0.9421  Val: 0.7764\n",
      "Epoch 31/200  Train: 0.8602  Val: 1.0774\n",
      "Epoch 32/200  Train: 0.8348  Val: 0.9579\n",
      "Epoch 33/200  Train: 0.8315  Val: 0.6400\n",
      "Epoch 34/200  Train: 0.9121  Val: 0.8111\n",
      "Epoch 35/200  Train: 0.7948  Val: 0.8171\n",
      "Epoch 36/200  Train: 0.9222  Val: 0.8293\n",
      "Epoch 37/200  Train: 0.8365  Val: 0.7374\n",
      "Epoch 38/200  Train: 0.8069  Val: 0.9781\n",
      "Epoch 39/200  Train: 0.8140  Val: 0.8415\n",
      "Epoch 40/200  Train: 0.9440  Val: 0.7613\n",
      "Epoch 41/200  Train: 0.8967  Val: 0.8303\n",
      "Epoch 42/200  Train: 0.9025  Val: 1.0135\n",
      "Epoch 43/200  Train: 0.8104  Val: 1.0397\n",
      "Epoch 44/200  Train: 0.7988  Val: 1.0940\n",
      "Epoch 45/200  Train: 0.9069  Val: 0.8500\n",
      "Epoch 46/200  Train: 0.6549  Val: 0.7081\n",
      "Epoch 47/200  Train: 0.7687  Val: 0.8091\n",
      "Epoch 48/200  Train: 0.7608  Val: 0.6920\n",
      "Epoch 49/200  Train: 1.1225  Val: 0.6658\n",
      "Epoch 50/200  Train: 0.9905  Val: 0.6838\n",
      "Epoch 51/200  Train: 0.7952  Val: 0.9490\n",
      "Epoch 52/200  Train: 0.7685  Val: 0.5396\n",
      "Epoch 53/200  Train: 0.8177  Val: 0.6720\n",
      "Epoch 54/200  Train: 0.7325  Val: 0.5796\n",
      "Epoch 55/200  Train: 0.8018  Val: 0.7398\n",
      "Epoch 56/200  Train: 0.8434  Val: 0.7358\n",
      "Epoch 57/200  Train: 0.7194  Val: 0.7685\n",
      "Epoch 58/200  Train: 0.7866  Val: 0.7072\n",
      "Epoch 59/200  Train: 0.7348  Val: 0.8139\n",
      "Epoch 60/200  Train: 0.8505  Val: 0.7382\n",
      "Epoch 61/200  Train: 0.7319  Val: 0.6986\n",
      "Epoch 62/200  Train: 0.7067  Val: 0.7432\n",
      "Epoch 63/200  Train: 0.8093  Val: 0.6335\n",
      "Epoch 64/200  Train: 0.6414  Val: 0.9623\n",
      "Epoch 65/200  Train: 0.7183  Val: 1.3861\n",
      "Epoch 66/200  Train: 0.7264  Val: 0.6878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200  Train: 0.6830  Val: 0.6115\n",
      "Epoch 68/200  Train: 0.7068  Val: 0.6378\n",
      "Epoch 69/200  Train: 0.7023  Val: 0.9336\n",
      "Epoch 70/200  Train: 0.7503  Val: 0.9066\n",
      "Epoch 71/200  Train: 0.6813  Val: 0.6060\n",
      "Epoch 72/200  Train: 0.6379  Val: 0.6235\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:05,381]\u001b[0m Trial 19 finished with value: 0.5396338820457458 and parameters: {'batch_size': 32, 'lr': 4.725141180066576e-05, 'hidden_dim': 512, 'time_embed_dim': 128, 'layers': 7, 'noise_steps': 827, 'beta_end': 0.01676387307448903, 'dropout': 0.03550807190060893}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 70.3882  Val: 3.0686\n",
      "Epoch 2/200  Train: 16.6509  Val: 3.7125\n",
      "Epoch 3/200  Train: 4.3751  Val: 4.3750\n",
      "Epoch 4/200  Train: 2.2859  Val: 2.2657\n",
      "Epoch 5/200  Train: 1.4293  Val: 1.0278\n",
      "Epoch 6/200  Train: 1.1004  Val: 0.9482\n",
      "Epoch 7/200  Train: 0.9673  Val: 0.9355\n",
      "Epoch 8/200  Train: 1.1185  Val: 0.9314\n",
      "Epoch 9/200  Train: 1.2622  Val: 1.0344\n",
      "Epoch 10/200  Train: 1.1614  Val: 1.2895\n",
      "Epoch 11/200  Train: 1.0685  Val: 0.9133\n",
      "Epoch 12/200  Train: 0.9987  Val: 0.9947\n",
      "Epoch 13/200  Train: 1.0026  Val: 0.8816\n",
      "Epoch 14/200  Train: 0.9302  Val: 0.9531\n",
      "Epoch 15/200  Train: 0.9506  Val: 0.9206\n",
      "Epoch 16/200  Train: 0.9815  Val: 1.1770\n",
      "Epoch 17/200  Train: 0.9241  Val: 0.7445\n",
      "Epoch 18/200  Train: 0.8823  Val: 1.2647\n",
      "Epoch 19/200  Train: 1.0158  Val: 0.8152\n",
      "Epoch 20/200  Train: 0.9443  Val: 0.9498\n",
      "Epoch 21/200  Train: 1.0603  Val: 1.0959\n",
      "Epoch 22/200  Train: 0.9551  Val: 0.9363\n",
      "Epoch 23/200  Train: 0.9245  Val: 1.1594\n",
      "Epoch 24/200  Train: 1.0366  Val: 1.1233\n",
      "Epoch 25/200  Train: 1.0456  Val: 1.2170\n",
      "Epoch 26/200  Train: 0.9794  Val: 1.2871\n",
      "Epoch 27/200  Train: 1.0831  Val: 0.9159\n",
      "Epoch 28/200  Train: 0.8907  Val: 1.2341\n",
      "Epoch 29/200  Train: 0.9454  Val: 0.9235\n",
      "Epoch 30/200  Train: 1.0307  Val: 0.9758\n",
      "Epoch 31/200  Train: 0.9336  Val: 1.0683\n",
      "Epoch 32/200  Train: 0.9144  Val: 0.7246\n",
      "Epoch 33/200  Train: 0.8999  Val: 1.0289\n",
      "Epoch 34/200  Train: 1.0234  Val: 1.2911\n",
      "Epoch 35/200  Train: 0.9991  Val: 0.7224\n",
      "Epoch 36/200  Train: 0.9426  Val: 0.9192\n",
      "Epoch 37/200  Train: 1.0184  Val: 0.8468\n",
      "Epoch 38/200  Train: 0.8030  Val: 0.9127\n",
      "Epoch 39/200  Train: 0.9323  Val: 0.6829\n",
      "Epoch 40/200  Train: 0.8841  Val: 1.0595\n",
      "Epoch 41/200  Train: 0.8915  Val: 0.8253\n",
      "Epoch 42/200  Train: 0.9360  Val: 0.8793\n",
      "Epoch 43/200  Train: 0.9662  Val: 0.9388\n",
      "Epoch 44/200  Train: 0.9623  Val: 0.7596\n",
      "Epoch 45/200  Train: 0.9016  Val: 0.9959\n",
      "Epoch 46/200  Train: 0.8605  Val: 0.9192\n",
      "Epoch 47/200  Train: 0.7785  Val: 0.8236\n",
      "Epoch 48/200  Train: 0.8480  Val: 1.1033\n",
      "Epoch 49/200  Train: 0.8856  Val: 0.6972\n",
      "Epoch 50/200  Train: 0.8411  Val: 0.7340\n",
      "Epoch 51/200  Train: 0.9265  Val: 0.7821\n",
      "Epoch 52/200  Train: 1.2215  Val: 0.8696\n",
      "Epoch 53/200  Train: 0.9590  Val: 0.7900\n",
      "Epoch 54/200  Train: 0.9305  Val: 0.6989\n",
      "Epoch 55/200  Train: 0.8166  Val: 1.0444\n",
      "Epoch 56/200  Train: 0.8276  Val: 1.3182\n",
      "Epoch 57/200  Train: 0.9531  Val: 0.6933\n",
      "Epoch 58/200  Train: 0.9712  Val: 0.6755\n",
      "Epoch 59/200  Train: 0.8894  Val: 0.9125\n",
      "Epoch 60/200  Train: 0.9447  Val: 1.0296\n",
      "Epoch 61/200  Train: 0.8372  Val: 0.7124\n",
      "Epoch 62/200  Train: 0.8060  Val: 1.0417\n",
      "Epoch 63/200  Train: 0.8802  Val: 0.7942\n",
      "Epoch 64/200  Train: 0.7549  Val: 0.6772\n",
      "Epoch 65/200  Train: 0.8559  Val: 1.0933\n",
      "Epoch 66/200  Train: 0.8862  Val: 1.0103\n",
      "Epoch 67/200  Train: 0.7148  Val: 0.7913\n",
      "Epoch 68/200  Train: 0.7851  Val: 0.6986\n",
      "Epoch 69/200  Train: 0.7541  Val: 1.1547\n",
      "Epoch 70/200  Train: 0.9789  Val: 0.5930\n",
      "Epoch 71/200  Train: 0.7847  Val: 0.7711\n",
      "Epoch 72/200  Train: 0.7485  Val: 0.7171\n",
      "Epoch 73/200  Train: 0.7135  Val: 0.8584\n",
      "Epoch 74/200  Train: 0.7025  Val: 0.9634\n",
      "Epoch 75/200  Train: 1.0478  Val: 1.5561\n",
      "Epoch 76/200  Train: 0.9760  Val: 0.6131\n",
      "Epoch 77/200  Train: 0.7625  Val: 1.1625\n",
      "Epoch 78/200  Train: 0.7803  Val: 0.8007\n",
      "Epoch 79/200  Train: 0.7090  Val: 0.6662\n",
      "Epoch 80/200  Train: 0.7693  Val: 1.0088\n",
      "Epoch 81/200  Train: 0.7938  Val: 0.7327\n",
      "Epoch 82/200  Train: 0.8449  Val: 0.7388\n",
      "Epoch 83/200  Train: 0.7323  Val: 0.7276\n",
      "Epoch 84/200  Train: 0.6333  Val: 0.6787\n",
      "Epoch 85/200  Train: 0.7410  Val: 0.8039\n",
      "Epoch 86/200  Train: 0.7161  Val: 0.6732\n",
      "Epoch 87/200  Train: 0.6816  Val: 0.5292\n",
      "Epoch 88/200  Train: 0.5763  Val: 0.9366\n",
      "Epoch 89/200  Train: 0.8461  Val: 0.7511\n",
      "Epoch 90/200  Train: 0.8148  Val: 0.5253\n",
      "Epoch 91/200  Train: 0.6581  Val: 0.5866\n",
      "Epoch 92/200  Train: 0.6722  Val: 0.6859\n",
      "Epoch 93/200  Train: 0.7619  Val: 0.6422\n",
      "Epoch 94/200  Train: 0.8035  Val: 0.6438\n",
      "Epoch 95/200  Train: 0.7948  Val: 0.7400\n",
      "Epoch 96/200  Train: 1.0942  Val: 0.6876\n",
      "Epoch 97/200  Train: 0.6882  Val: 0.6855\n",
      "Epoch 98/200  Train: 0.7145  Val: 0.6328\n",
      "Epoch 99/200  Train: 0.8294  Val: 0.7244\n",
      "Epoch 100/200  Train: 0.5939  Val: 0.7101\n",
      "Epoch 101/200  Train: 0.8370  Val: 1.1275\n",
      "Epoch 102/200  Train: 0.9760  Val: 1.2366\n",
      "Epoch 103/200  Train: 1.1826  Val: 0.8562\n",
      "Epoch 104/200  Train: 1.1858  Val: 0.6458\n",
      "Epoch 105/200  Train: 1.9974  Val: 1.8441\n",
      "Epoch 106/200  Train: 1.8744  Val: 1.0964\n",
      "Epoch 107/200  Train: 1.0022  Val: 0.9766\n",
      "Epoch 108/200  Train: 0.9244  Val: 0.7504\n",
      "Epoch 109/200  Train: 0.8482  Val: 0.5875\n",
      "Epoch 110/200  Train: 0.6503  Val: 0.5869\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:09,662]\u001b[0m Trial 20 finished with value: 0.5253049612045289 and parameters: {'batch_size': 64, 'lr': 6.6855004885132e-05, 'hidden_dim': 512, 'time_embed_dim': 256, 'layers': 5, 'noise_steps': 918, 'beta_end': 0.010448133053440748, 'dropout': 0.017113224703569418}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 67.5974  Val: 12.0701\n",
      "Epoch 2/200  Train: 7.8825  Val: 0.8859\n",
      "Epoch 3/200  Train: 1.7215  Val: 1.2583\n",
      "Epoch 4/200  Train: 1.3018  Val: 0.9078\n",
      "Epoch 5/200  Train: 1.1603  Val: 0.8912\n",
      "Epoch 6/200  Train: 1.1737  Val: 1.4883\n",
      "Epoch 7/200  Train: 1.3600  Val: 0.8673\n",
      "Epoch 8/200  Train: 1.3348  Val: 1.8552\n",
      "Epoch 9/200  Train: 1.3379  Val: 0.9546\n",
      "Epoch 10/200  Train: 0.9622  Val: 1.0133\n",
      "Epoch 11/200  Train: 0.8966  Val: 1.2172\n",
      "Epoch 12/200  Train: 0.9463  Val: 0.8634\n",
      "Epoch 13/200  Train: 1.0109  Val: 0.8228\n",
      "Epoch 14/200  Train: 0.9323  Val: 1.1281\n",
      "Epoch 15/200  Train: 0.9202  Val: 0.8840\n",
      "Epoch 16/200  Train: 0.9557  Val: 0.9829\n",
      "Epoch 17/200  Train: 0.9619  Val: 1.0814\n",
      "Epoch 18/200  Train: 0.9928  Val: 0.8289\n",
      "Epoch 19/200  Train: 0.9139  Val: 1.1251\n",
      "Epoch 20/200  Train: 1.0183  Val: 0.9545\n",
      "Epoch 21/200  Train: 0.9192  Val: 0.8597\n",
      "Epoch 22/200  Train: 0.8913  Val: 0.7507\n",
      "Epoch 23/200  Train: 0.9162  Val: 0.7530\n",
      "Epoch 24/200  Train: 0.9153  Val: 0.8917\n",
      "Epoch 25/200  Train: 0.9017  Val: 0.7798\n",
      "Epoch 26/200  Train: 0.9129  Val: 0.8061\n",
      "Epoch 27/200  Train: 0.8812  Val: 0.7456\n",
      "Epoch 28/200  Train: 0.7594  Val: 1.0030\n",
      "Epoch 29/200  Train: 0.8038  Val: 0.8568\n",
      "Epoch 30/200  Train: 0.7325  Val: 0.7917\n",
      "Epoch 31/200  Train: 0.7804  Val: 0.9014\n",
      "Epoch 32/200  Train: 0.7698  Val: 0.7888\n",
      "Epoch 33/200  Train: 0.8912  Val: 0.6726\n",
      "Epoch 34/200  Train: 0.8268  Val: 0.8176\n",
      "Epoch 35/200  Train: 0.8426  Val: 1.0967\n",
      "Epoch 36/200  Train: 0.8320  Val: 0.6369\n",
      "Epoch 37/200  Train: 0.6616  Val: 0.5800\n",
      "Epoch 38/200  Train: 0.6802  Val: 0.8332\n",
      "Epoch 39/200  Train: 0.7226  Val: 0.7955\n",
      "Epoch 40/200  Train: 0.6874  Val: 0.5527\n",
      "Epoch 41/200  Train: 0.9701  Val: 0.8837\n",
      "Epoch 42/200  Train: 0.7186  Val: 0.6970\n",
      "Epoch 43/200  Train: 0.6390  Val: 0.6470\n",
      "Epoch 44/200  Train: 0.6969  Val: 1.5664\n",
      "Epoch 45/200  Train: 1.0222  Val: 0.5316\n",
      "Epoch 46/200  Train: 0.5876  Val: 0.4774\n",
      "Epoch 47/200  Train: 0.6230  Val: 1.1494\n",
      "Epoch 48/200  Train: 0.8910  Val: 0.8210\n",
      "Epoch 49/200  Train: 0.6012  Val: 0.9720\n",
      "Epoch 50/200  Train: 0.7723  Val: 0.7522\n",
      "Epoch 51/200  Train: 0.8786  Val: 1.3092\n",
      "Epoch 52/200  Train: 0.5980  Val: 0.5474\n",
      "Epoch 53/200  Train: 0.8580  Val: 1.1170\n",
      "Epoch 54/200  Train: 4.2825  Val: 4.4585\n",
      "Epoch 55/200  Train: 5.7806  Val: 1.5608\n",
      "Epoch 56/200  Train: 1.1619  Val: 0.6219\n",
      "Epoch 57/200  Train: 0.7077  Val: 0.4718\n",
      "Epoch 58/200  Train: 0.7800  Val: 0.4463\n",
      "Epoch 59/200  Train: 0.6001  Val: 0.5198\n",
      "Epoch 60/200  Train: 0.5114  Val: 0.4769\n",
      "Epoch 61/200  Train: 0.5211  Val: 0.5018\n",
      "Epoch 62/200  Train: 0.5003  Val: 0.7793\n",
      "Epoch 63/200  Train: 0.5358  Val: 0.4387\n",
      "Epoch 64/200  Train: 0.4847  Val: 0.5627\n",
      "Epoch 65/200  Train: 0.5355  Val: 0.3925\n",
      "Epoch 66/200  Train: 0.4879  Val: 0.3775\n",
      "Epoch 67/200  Train: 0.4245  Val: 0.3612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200  Train: 0.4187  Val: 0.6379\n",
      "Epoch 69/200  Train: 0.5399  Val: 0.8233\n",
      "Epoch 70/200  Train: 0.4886  Val: 0.3708\n",
      "Epoch 71/200  Train: 0.4430  Val: 0.4028\n",
      "Epoch 72/200  Train: 0.4468  Val: 0.5374\n",
      "Epoch 73/200  Train: 0.7054  Val: 0.3131\n",
      "Epoch 74/200  Train: 0.4181  Val: 0.3462\n",
      "Epoch 75/200  Train: 0.3575  Val: 0.4120\n",
      "Epoch 76/200  Train: 0.3666  Val: 0.3179\n",
      "Epoch 77/200  Train: 0.3391  Val: 0.3612\n",
      "Epoch 78/200  Train: 0.4258  Val: 0.3378\n",
      "Epoch 79/200  Train: 0.5034  Val: 0.3418\n",
      "Epoch 80/200  Train: 0.9810  Val: 0.6646\n",
      "Epoch 81/200  Train: 0.6354  Val: 0.3489\n",
      "Epoch 82/200  Train: 0.4990  Val: 0.3580\n",
      "Epoch 83/200  Train: 0.4531  Val: 0.5395\n",
      "Epoch 84/200  Train: 0.3968  Val: 0.2768\n",
      "Epoch 85/200  Train: 0.3220  Val: 0.3191\n",
      "Epoch 86/200  Train: 0.3167  Val: 0.6338\n",
      "Epoch 87/200  Train: 0.4942  Val: 0.5262\n",
      "Epoch 88/200  Train: 0.3901  Val: 0.3573\n",
      "Epoch 89/200  Train: 0.3785  Val: 0.2528\n",
      "Epoch 90/200  Train: 0.4054  Val: 0.2557\n",
      "Epoch 91/200  Train: 0.3443  Val: 0.4549\n",
      "Epoch 92/200  Train: 0.5614  Val: 0.6016\n",
      "Epoch 93/200  Train: 0.4205  Val: 0.2676\n",
      "Epoch 94/200  Train: 0.3157  Val: 0.3174\n",
      "Epoch 95/200  Train: 0.3607  Val: 0.2698\n",
      "Epoch 96/200  Train: 0.3385  Val: 0.4094\n",
      "Epoch 97/200  Train: 0.3548  Val: 0.4831\n",
      "Epoch 98/200  Train: 0.3298  Val: 0.2772\n",
      "Epoch 99/200  Train: 0.2832  Val: 0.2754\n",
      "Epoch 100/200  Train: 0.2742  Val: 0.3151\n",
      "Epoch 101/200  Train: 0.3444  Val: 0.2235\n",
      "Epoch 102/200  Train: 0.2841  Val: 0.2275\n",
      "Epoch 103/200  Train: 0.3218  Val: 0.2862\n",
      "Epoch 104/200  Train: 0.2937  Val: 0.3092\n",
      "Epoch 105/200  Train: 0.2566  Val: 0.3135\n",
      "Epoch 106/200  Train: 0.3389  Val: 0.3461\n",
      "Epoch 107/200  Train: 0.3056  Val: 0.3066\n",
      "Epoch 108/200  Train: 0.2381  Val: 0.2303\n",
      "Epoch 109/200  Train: 0.2108  Val: 0.2025\n",
      "Epoch 110/200  Train: 0.2131  Val: 0.2814\n",
      "Epoch 111/200  Train: 0.2242  Val: 0.2435\n",
      "Epoch 112/200  Train: 0.2208  Val: 0.2537\n",
      "Epoch 113/200  Train: 0.2155  Val: 0.2410\n",
      "Epoch 114/200  Train: 0.2241  Val: 0.1486\n",
      "Epoch 115/200  Train: 0.2801  Val: 0.2274\n",
      "Epoch 116/200  Train: 0.3458  Val: 0.2344\n",
      "Epoch 117/200  Train: 0.2644  Val: 0.3235\n",
      "Epoch 118/200  Train: 0.3152  Val: 0.1453\n",
      "Epoch 119/200  Train: 0.3688  Val: 0.1430\n",
      "Epoch 120/200  Train: 0.2527  Val: 0.2625\n",
      "Epoch 121/200  Train: 0.1927  Val: 0.1892\n",
      "Epoch 122/200  Train: 0.2286  Val: 0.3589\n",
      "Epoch 123/200  Train: 0.2466  Val: 0.1794\n",
      "Epoch 124/200  Train: 0.2050  Val: 0.3507\n",
      "Epoch 125/200  Train: 0.2524  Val: 0.1613\n",
      "Epoch 126/200  Train: 0.1997  Val: 0.1725\n",
      "Epoch 127/200  Train: 0.2021  Val: 0.2448\n",
      "Epoch 128/200  Train: 0.4027  Val: 0.2474\n",
      "Epoch 129/200  Train: 0.1780  Val: 0.2056\n",
      "Epoch 130/200  Train: 0.2234  Val: 0.1387\n",
      "Epoch 131/200  Train: 0.2225  Val: 0.2744\n",
      "Epoch 132/200  Train: 0.3705  Val: 0.2925\n",
      "Epoch 133/200  Train: 0.2055  Val: 0.1694\n",
      "Epoch 134/200  Train: 0.1734  Val: 0.1640\n",
      "Epoch 135/200  Train: 0.1322  Val: 0.1380\n",
      "Epoch 136/200  Train: 0.2069  Val: 0.3754\n",
      "Epoch 137/200  Train: 0.1916  Val: 0.1559\n",
      "Epoch 138/200  Train: 0.1531  Val: 0.2322\n",
      "Epoch 139/200  Train: 0.2078  Val: 0.1898\n",
      "Epoch 140/200  Train: 0.1934  Val: 0.3128\n",
      "Epoch 141/200  Train: 0.1775  Val: 0.1568\n",
      "Epoch 142/200  Train: 0.2003  Val: 0.1642\n",
      "Epoch 143/200  Train: 0.1759  Val: 0.1558\n",
      "Epoch 144/200  Train: 0.1819  Val: 0.2953\n",
      "Epoch 145/200  Train: 0.3531  Val: 0.2145\n",
      "Epoch 146/200  Train: 0.3287  Val: 0.6287\n",
      "Epoch 147/200  Train: 0.4061  Val: 0.3191\n",
      "Epoch 148/200  Train: 0.1566  Val: 0.2666\n",
      "Epoch 149/200  Train: 0.1251  Val: 0.1768\n",
      "Epoch 150/200  Train: 0.1911  Val: 0.1715\n",
      "Epoch 151/200  Train: 0.2900  Val: 0.2189\n",
      "Epoch 152/200  Train: 0.1490  Val: 0.1789\n",
      "Epoch 153/200  Train: 0.1242  Val: 0.2673\n",
      "Epoch 154/200  Train: 0.1734  Val: 0.2081\n",
      "Epoch 155/200  Train: 0.1189  Val: 0.1916\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:19,055]\u001b[0m Trial 21 finished with value: 0.13798387497663497 and parameters: {'batch_size': 32, 'lr': 7.21631196252835e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 790, 'beta_end': 0.018162875293060356, 'dropout': 0.007176420672306877}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 59.4728  Val: 13.2115\n",
      "Epoch 2/200  Train: 5.9041  Val: 4.0073\n",
      "Epoch 3/200  Train: 1.5131  Val: 1.0487\n",
      "Epoch 4/200  Train: 1.0968  Val: 0.8705\n",
      "Epoch 5/200  Train: 1.0336  Val: 0.9894\n",
      "Epoch 6/200  Train: 1.1300  Val: 0.6857\n",
      "Epoch 7/200  Train: 0.9738  Val: 0.9768\n",
      "Epoch 8/200  Train: 1.0006  Val: 0.7255\n",
      "Epoch 9/200  Train: 1.1094  Val: 1.1095\n",
      "Epoch 10/200  Train: 1.1615  Val: 1.0461\n",
      "Epoch 11/200  Train: 1.0300  Val: 1.0284\n",
      "Epoch 12/200  Train: 0.8701  Val: 1.1319\n",
      "Epoch 13/200  Train: 1.0088  Val: 1.0803\n",
      "Epoch 14/200  Train: 1.1797  Val: 1.6002\n",
      "Epoch 15/200  Train: 1.1829  Val: 1.2079\n",
      "Epoch 16/200  Train: 1.3660  Val: 1.8877\n",
      "Epoch 17/200  Train: 1.0513  Val: 0.9327\n",
      "Epoch 18/200  Train: 0.8915  Val: 0.9242\n",
      "Epoch 19/200  Train: 0.8808  Val: 1.4255\n",
      "Epoch 20/200  Train: 0.9529  Val: 1.3004\n",
      "Epoch 21/200  Train: 1.1853  Val: 0.9567\n",
      "Epoch 22/200  Train: 0.9658  Val: 0.8001\n",
      "Epoch 23/200  Train: 1.0643  Val: 1.4773\n",
      "Epoch 24/200  Train: 0.8658  Val: 0.7264\n",
      "Epoch 25/200  Train: 0.8232  Val: 1.2193\n",
      "Epoch 26/200  Train: 1.1988  Val: 0.9201\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:20,955]\u001b[0m Trial 22 finished with value: 0.6856868505477905 and parameters: {'batch_size': 32, 'lr': 5.9266736263585125e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 4, 'noise_steps': 708, 'beta_end': 0.01908122519673869, 'dropout': 0.02568745240426188}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 136.3511  Val: 2.1197\n",
      "Epoch 2/200  Train: 8.3137  Val: 2.1227\n",
      "Epoch 3/200  Train: 1.6933  Val: 1.1608\n",
      "Epoch 4/200  Train: 1.3373  Val: 0.9221\n",
      "Epoch 5/200  Train: 1.1606  Val: 0.8480\n",
      "Epoch 6/200  Train: 1.2384  Val: 1.0225\n",
      "Epoch 7/200  Train: 0.9595  Val: 0.8938\n",
      "Epoch 8/200  Train: 1.0634  Val: 1.1733\n",
      "Epoch 9/200  Train: 1.1289  Val: 0.8398\n",
      "Epoch 10/200  Train: 0.9796  Val: 0.9844\n",
      "Epoch 11/200  Train: 1.1035  Val: 0.9159\n",
      "Epoch 12/200  Train: 1.0131  Val: 0.8724\n",
      "Epoch 13/200  Train: 1.0837  Val: 1.1435\n",
      "Epoch 14/200  Train: 1.0850  Val: 0.9713\n",
      "Epoch 15/200  Train: 0.9217  Val: 0.9525\n",
      "Epoch 16/200  Train: 1.0239  Val: 1.2197\n",
      "Epoch 17/200  Train: 1.0354  Val: 0.9719\n",
      "Epoch 18/200  Train: 0.9925  Val: 0.8770\n",
      "Epoch 19/200  Train: 0.8336  Val: 0.7545\n",
      "Epoch 20/200  Train: 0.8347  Val: 0.9067\n",
      "Epoch 21/200  Train: 0.8343  Val: 0.9811\n",
      "Epoch 22/200  Train: 0.8256  Val: 1.0827\n",
      "Epoch 23/200  Train: 1.0513  Val: 0.7675\n",
      "Epoch 24/200  Train: 1.0065  Val: 1.4870\n",
      "Epoch 25/200  Train: 0.8699  Val: 0.7916\n",
      "Epoch 26/200  Train: 0.8607  Val: 0.7361\n",
      "Epoch 27/200  Train: 0.8278  Val: 0.8442\n",
      "Epoch 28/200  Train: 0.8646  Val: 1.1619\n",
      "Epoch 29/200  Train: 0.9353  Val: 1.1190\n",
      "Epoch 30/200  Train: 0.8649  Val: 1.1485\n",
      "Epoch 31/200  Train: 0.8071  Val: 0.8742\n",
      "Epoch 32/200  Train: 0.8052  Val: 1.0048\n",
      "Epoch 33/200  Train: 0.8124  Val: 0.6157\n",
      "Epoch 34/200  Train: 0.8223  Val: 0.9430\n",
      "Epoch 35/200  Train: 1.1990  Val: 0.8204\n",
      "Epoch 36/200  Train: 0.7985  Val: 0.6308\n",
      "Epoch 37/200  Train: 0.8973  Val: 0.7137\n",
      "Epoch 38/200  Train: 0.7937  Val: 0.7933\n",
      "Epoch 39/200  Train: 0.7212  Val: 0.8221\n",
      "Epoch 40/200  Train: 0.7495  Val: 0.5956\n",
      "Epoch 41/200  Train: 0.7503  Val: 0.9943\n",
      "Epoch 42/200  Train: 0.6277  Val: 0.5848\n",
      "Epoch 43/200  Train: 0.5513  Val: 0.7435\n",
      "Epoch 44/200  Train: 0.7137  Val: 0.6930\n",
      "Epoch 45/200  Train: 1.2281  Val: 0.5934\n",
      "Epoch 46/200  Train: 0.9638  Val: 0.7435\n",
      "Epoch 47/200  Train: 0.6918  Val: 0.7324\n",
      "Epoch 48/200  Train: 0.6152  Val: 0.8538\n",
      "Epoch 49/200  Train: 0.6527  Val: 0.6697\n",
      "Epoch 50/200  Train: 0.6639  Val: 0.3909\n",
      "Epoch 51/200  Train: 0.5502  Val: 0.6390\n",
      "Epoch 52/200  Train: 0.6163  Val: 0.5330\n",
      "Epoch 53/200  Train: 0.6395  Val: 0.7124\n",
      "Epoch 54/200  Train: 0.5382  Val: 0.5589\n",
      "Epoch 55/200  Train: 0.6245  Val: 0.5425\n",
      "Epoch 56/200  Train: 0.6117  Val: 0.5262\n",
      "Epoch 57/200  Train: 0.7045  Val: 0.4756\n",
      "Epoch 58/200  Train: 0.6480  Val: 0.4964\n",
      "Epoch 59/200  Train: 0.5383  Val: 0.7650\n",
      "Epoch 60/200  Train: 0.6582  Val: 0.5580\n",
      "Epoch 61/200  Train: 0.5700  Val: 0.4309\n",
      "Epoch 62/200  Train: 0.5121  Val: 0.5412\n",
      "Epoch 63/200  Train: 0.6027  Val: 0.9486\n",
      "Epoch 64/200  Train: 0.4809  Val: 0.4703\n",
      "Epoch 65/200  Train: 0.4962  Val: 0.5235\n",
      "Epoch 66/200  Train: 0.5533  Val: 1.2003\n",
      "Epoch 67/200  Train: 0.6607  Val: 0.5276\n",
      "Epoch 68/200  Train: 0.6182  Val: 0.4691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200  Train: 0.4556  Val: 0.4705\n",
      "Epoch 70/200  Train: 0.4455  Val: 0.3497\n",
      "Epoch 71/200  Train: 0.4532  Val: 0.4135\n",
      "Epoch 72/200  Train: 0.4374  Val: 0.3827\n",
      "Epoch 73/200  Train: 0.4482  Val: 0.3326\n",
      "Epoch 74/200  Train: 0.3846  Val: 0.3540\n",
      "Epoch 75/200  Train: 0.4554  Val: 0.4970\n",
      "Epoch 76/200  Train: 0.4984  Val: 0.6471\n",
      "Epoch 77/200  Train: 0.3668  Val: 0.5218\n",
      "Epoch 78/200  Train: 0.4720  Val: 0.3885\n",
      "Epoch 79/200  Train: 0.5776  Val: 0.6721\n",
      "Epoch 80/200  Train: 0.7077  Val: 1.2904\n",
      "Epoch 81/200  Train: 0.7700  Val: 0.4260\n",
      "Epoch 82/200  Train: 0.4115  Val: 0.3429\n",
      "Epoch 83/200  Train: 0.3803  Val: 0.4504\n",
      "Epoch 84/200  Train: 0.5463  Val: 0.6776\n",
      "Epoch 85/200  Train: 0.4075  Val: 0.4183\n",
      "Epoch 86/200  Train: 0.3290  Val: 0.4849\n",
      "Epoch 87/200  Train: 0.4756  Val: 0.4143\n",
      "Epoch 88/200  Train: 0.3480  Val: 0.5425\n",
      "Epoch 89/200  Train: 0.3798  Val: 0.3739\n",
      "Epoch 90/200  Train: 0.3762  Val: 0.3332\n",
      "Epoch 91/200  Train: 0.4765  Val: 0.7526\n",
      "Epoch 92/200  Train: 0.5365  Val: 0.6008\n",
      "Epoch 93/200  Train: 0.7240  Val: 0.3561\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:26,610]\u001b[0m Trial 23 finished with value: 0.33259875178337095 and parameters: {'batch_size': 32, 'lr': 8.186991796497888e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 774, 'beta_end': 0.01753066621644961, 'dropout': 0.013754203943561446}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 89.5721  Val: 20.4392\n",
      "Epoch 2/200  Train: 6.8106  Val: 4.0851\n",
      "Epoch 3/200  Train: 2.6642  Val: 2.0438\n",
      "Epoch 4/200  Train: 1.7006  Val: 1.1016\n",
      "Epoch 5/200  Train: 1.3965  Val: 1.2160\n",
      "Epoch 6/200  Train: 1.3612  Val: 0.7814\n",
      "Epoch 7/200  Train: 1.1294  Val: 0.9668\n",
      "Epoch 8/200  Train: 0.9428  Val: 0.7058\n",
      "Epoch 9/200  Train: 0.9925  Val: 1.2812\n",
      "Epoch 10/200  Train: 1.0740  Val: 1.0081\n",
      "Epoch 11/200  Train: 0.9872  Val: 1.0239\n",
      "Epoch 12/200  Train: 0.8514  Val: 1.1887\n",
      "Epoch 13/200  Train: 0.8700  Val: 0.8852\n",
      "Epoch 14/200  Train: 0.8485  Val: 1.4047\n",
      "Epoch 15/200  Train: 1.2281  Val: 1.5598\n",
      "Epoch 16/200  Train: 1.1635  Val: 0.8294\n",
      "Epoch 17/200  Train: 1.1076  Val: 0.8789\n",
      "Epoch 18/200  Train: 1.0347  Val: 0.7104\n",
      "Epoch 19/200  Train: 0.7886  Val: 1.1060\n",
      "Epoch 20/200  Train: 0.7428  Val: 0.9574\n",
      "Epoch 21/200  Train: 0.9230  Val: 0.9091\n",
      "Epoch 22/200  Train: 0.7620  Val: 0.6423\n",
      "Epoch 23/200  Train: 0.7715  Val: 0.9195\n",
      "Epoch 24/200  Train: 0.7232  Val: 0.6693\n",
      "Epoch 25/200  Train: 0.6724  Val: 0.7414\n",
      "Epoch 26/200  Train: 0.7903  Val: 0.7399\n",
      "Epoch 27/200  Train: 0.7275  Val: 1.0464\n",
      "Epoch 28/200  Train: 0.7918  Val: 0.5930\n",
      "Epoch 29/200  Train: 0.7423  Val: 0.6976\n",
      "Epoch 30/200  Train: 0.7198  Val: 0.7854\n",
      "Epoch 31/200  Train: 0.6393  Val: 0.7069\n",
      "Epoch 32/200  Train: 0.7646  Val: 0.5385\n",
      "Epoch 33/200  Train: 0.6417  Val: 0.6959\n",
      "Epoch 34/200  Train: 0.6200  Val: 0.6038\n",
      "Epoch 35/200  Train: 0.7104  Val: 0.5446\n",
      "Epoch 36/200  Train: 0.8658  Val: 0.5748\n",
      "Epoch 37/200  Train: 0.9015  Val: 0.6460\n",
      "Epoch 38/200  Train: 0.8441  Val: 0.9166\n",
      "Epoch 39/200  Train: 1.0215  Val: 0.5455\n",
      "Epoch 40/200  Train: 0.6638  Val: 0.5679\n",
      "Epoch 41/200  Train: 0.5265  Val: 0.4858\n",
      "Epoch 42/200  Train: 0.7137  Val: 1.1996\n",
      "Epoch 43/200  Train: 0.8488  Val: 0.6445\n",
      "Epoch 44/200  Train: 0.8966  Val: 0.9703\n",
      "Epoch 45/200  Train: 0.7222  Val: 0.4968\n",
      "Epoch 46/200  Train: 0.5178  Val: 0.5722\n",
      "Epoch 47/200  Train: 0.3897  Val: 0.4392\n",
      "Epoch 48/200  Train: 0.5559  Val: 0.5643\n",
      "Epoch 49/200  Train: 0.5137  Val: 0.4825\n",
      "Epoch 50/200  Train: 0.4810  Val: 0.3190\n",
      "Epoch 51/200  Train: 0.6936  Val: 0.4499\n",
      "Epoch 52/200  Train: 0.4211  Val: 0.3166\n",
      "Epoch 53/200  Train: 0.4761  Val: 0.3856\n",
      "Epoch 54/200  Train: 0.5278  Val: 0.4982\n",
      "Epoch 55/200  Train: 0.4689  Val: 0.3782\n",
      "Epoch 56/200  Train: 0.4039  Val: 0.3598\n",
      "Epoch 57/200  Train: 0.4687  Val: 0.7457\n",
      "Epoch 58/200  Train: 0.4090  Val: 0.4948\n",
      "Epoch 59/200  Train: 0.4539  Val: 0.3557\n",
      "Epoch 60/200  Train: 0.4008  Val: 0.3230\n",
      "Epoch 61/200  Train: 0.3797  Val: 0.6489\n",
      "Epoch 62/200  Train: 0.5353  Val: 0.3713\n",
      "Epoch 63/200  Train: 0.3978  Val: 0.3287\n",
      "Epoch 64/200  Train: 0.3145  Val: 0.2936\n",
      "Epoch 65/200  Train: 0.3974  Val: 0.4526\n",
      "Epoch 66/200  Train: 0.4065  Val: 0.3725\n",
      "Epoch 67/200  Train: 0.3514  Val: 0.3261\n",
      "Epoch 68/200  Train: 0.3719  Val: 0.3187\n",
      "Epoch 69/200  Train: 0.3794  Val: 0.4776\n",
      "Epoch 70/200  Train: 0.3810  Val: 0.2997\n",
      "Epoch 71/200  Train: 0.4158  Val: 0.2994\n",
      "Epoch 72/200  Train: 0.4936  Val: 0.7073\n",
      "Epoch 73/200  Train: 0.3602  Val: 0.3103\n",
      "Epoch 74/200  Train: 0.3239  Val: 0.2525\n",
      "Epoch 75/200  Train: 0.3170  Val: 0.2406\n",
      "Epoch 76/200  Train: 0.2717  Val: 0.4028\n",
      "Epoch 77/200  Train: 0.3764  Val: 0.3830\n",
      "Epoch 78/200  Train: 0.3362  Val: 0.3302\n",
      "Epoch 79/200  Train: 0.2578  Val: 0.3452\n",
      "Epoch 80/200  Train: 0.2391  Val: 0.3399\n",
      "Epoch 81/200  Train: 0.2371  Val: 0.2325\n",
      "Epoch 82/200  Train: 0.2829  Val: 0.2528\n",
      "Epoch 83/200  Train: 0.2650  Val: 0.2530\n",
      "Epoch 84/200  Train: 0.2858  Val: 0.2610\n",
      "Epoch 85/200  Train: 0.2230  Val: 0.2358\n",
      "Epoch 86/200  Train: 0.2807  Val: 0.3214\n",
      "Epoch 87/200  Train: 0.2606  Val: 0.2991\n",
      "Epoch 88/200  Train: 0.2176  Val: 0.1781\n",
      "Epoch 89/200  Train: 0.2062  Val: 0.3954\n",
      "Epoch 90/200  Train: 0.2298  Val: 0.2113\n",
      "Epoch 91/200  Train: 0.2057  Val: 0.2569\n",
      "Epoch 92/200  Train: 0.2485  Val: 0.3314\n",
      "Epoch 93/200  Train: 0.2063  Val: 0.3493\n",
      "Epoch 94/200  Train: 0.2593  Val: 0.1895\n",
      "Epoch 95/200  Train: 0.2398  Val: 0.1397\n",
      "Epoch 96/200  Train: 0.2486  Val: 0.2405\n",
      "Epoch 97/200  Train: 0.2778  Val: 0.2621\n",
      "Epoch 98/200  Train: 0.1877  Val: 0.2334\n",
      "Epoch 99/200  Train: 0.1948  Val: 0.1746\n",
      "Epoch 100/200  Train: 0.1751  Val: 0.2810\n",
      "Epoch 101/200  Train: 0.2772  Val: 0.2153\n",
      "Epoch 102/200  Train: 0.1797  Val: 0.3119\n",
      "Epoch 103/200  Train: 0.2011  Val: 0.2402\n",
      "Epoch 104/200  Train: 0.2211  Val: 0.3451\n",
      "Epoch 105/200  Train: 0.2460  Val: 0.2643\n",
      "Epoch 106/200  Train: 0.4659  Val: 0.9429\n",
      "Epoch 107/200  Train: 0.4858  Val: 0.2468\n",
      "Epoch 108/200  Train: 0.2047  Val: 0.1691\n",
      "Epoch 109/200  Train: 0.1795  Val: 0.2577\n",
      "Epoch 110/200  Train: 0.2226  Val: 0.1799\n",
      "Epoch 111/200  Train: 0.1499  Val: 0.1469\n",
      "Epoch 112/200  Train: 0.1632  Val: 0.1745\n",
      "Epoch 113/200  Train: 0.1791  Val: 0.2063\n",
      "Epoch 114/200  Train: 0.1400  Val: 0.3731\n",
      "Epoch 115/200  Train: 0.2370  Val: 0.1778\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:34,818]\u001b[0m Trial 24 finished with value: 0.13971254378557205 and parameters: {'batch_size': 32, 'lr': 9.99489724502712e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 4, 'noise_steps': 672, 'beta_end': 0.018618843906682638, 'dropout': 0.00016327937759082027}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 18.8303  Val: 1.9270\n",
      "Epoch 2/200  Train: 2.2175  Val: 1.3743\n",
      "Epoch 3/200  Train: 1.0982  Val: 0.9212\n",
      "Epoch 4/200  Train: 1.0319  Val: 1.1278\n",
      "Epoch 5/200  Train: 1.1184  Val: 0.9098\n",
      "Epoch 6/200  Train: 1.0317  Val: 1.0394\n",
      "Epoch 7/200  Train: 1.1494  Val: 1.0431\n",
      "Epoch 8/200  Train: 1.0054  Val: 1.1194\n",
      "Epoch 9/200  Train: 1.0846  Val: 1.1674\n",
      "Epoch 10/200  Train: 1.0048  Val: 0.8082\n",
      "Epoch 11/200  Train: 0.9725  Val: 1.1558\n",
      "Epoch 12/200  Train: 1.0791  Val: 1.0350\n",
      "Epoch 13/200  Train: 1.0107  Val: 1.0693\n",
      "Epoch 14/200  Train: 1.1201  Val: 0.8773\n",
      "Epoch 15/200  Train: 0.9575  Val: 0.9875\n",
      "Epoch 16/200  Train: 0.9676  Val: 0.9895\n",
      "Epoch 17/200  Train: 0.9638  Val: 0.8782\n",
      "Epoch 18/200  Train: 0.9790  Val: 1.0241\n",
      "Epoch 19/200  Train: 1.0374  Val: 1.0377\n",
      "Epoch 20/200  Train: 1.0340  Val: 1.1754\n",
      "Epoch 21/200  Train: 1.0087  Val: 0.9904\n",
      "Epoch 22/200  Train: 1.0490  Val: 0.8994\n",
      "Epoch 23/200  Train: 0.9100  Val: 0.8351\n",
      "Epoch 24/200  Train: 1.0103  Val: 0.8324\n",
      "Epoch 25/200  Train: 0.9233  Val: 0.8485\n",
      "Epoch 26/200  Train: 0.9371  Val: 1.0888\n",
      "Epoch 27/200  Train: 1.0228  Val: 1.0192\n",
      "Epoch 28/200  Train: 1.0237  Val: 0.9762\n",
      "Epoch 29/200  Train: 1.0609  Val: 0.9410\n",
      "Epoch 30/200  Train: 0.9681  Val: 0.8771\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:37,346]\u001b[0m Trial 25 finished with value: 0.8082218289375305 and parameters: {'batch_size': 32, 'lr': 2.8016263821501013e-05, 'hidden_dim': 1024, 'time_embed_dim': 128, 'layers': 5, 'noise_steps': 642, 'beta_end': 0.016066345403276575, 'dropout': 0.007207446023351074}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 30.3053  Val: 7.1028\n",
      "Epoch 2/200  Train: 3.1300  Val: 1.5994\n",
      "Epoch 3/200  Train: 1.1506  Val: 1.3952\n",
      "Epoch 4/200  Train: 1.2875  Val: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200  Train: 1.1645  Val: 1.1056\n",
      "Epoch 6/200  Train: 1.4852  Val: 1.1165\n",
      "Epoch 7/200  Train: 1.2297  Val: 1.0057\n",
      "Epoch 8/200  Train: 1.0664  Val: 1.3421\n",
      "Epoch 9/200  Train: 1.0984  Val: 0.8648\n",
      "Epoch 10/200  Train: 1.0160  Val: 1.0579\n",
      "Epoch 11/200  Train: 1.1458  Val: 1.2658\n",
      "Epoch 12/200  Train: 1.1577  Val: 0.8975\n",
      "Epoch 13/200  Train: 1.0674  Val: 1.2306\n",
      "Epoch 14/200  Train: 1.0061  Val: 1.0694\n",
      "Epoch 15/200  Train: 0.9469  Val: 0.9594\n",
      "Epoch 16/200  Train: 1.0295  Val: 1.5624\n",
      "Epoch 17/200  Train: 1.0133  Val: 0.8930\n",
      "Epoch 18/200  Train: 0.9746  Val: 0.8664\n",
      "Epoch 19/200  Train: 0.8594  Val: 0.8913\n",
      "Epoch 20/200  Train: 0.8730  Val: 0.9928\n",
      "Epoch 21/200  Train: 0.8629  Val: 1.0389\n",
      "Epoch 22/200  Train: 0.9670  Val: 0.9118\n",
      "Epoch 23/200  Train: 0.9302  Val: 0.6794\n",
      "Epoch 24/200  Train: 0.9722  Val: 0.9825\n",
      "Epoch 25/200  Train: 0.8930  Val: 0.7257\n",
      "Epoch 26/200  Train: 0.9686  Val: 0.7645\n",
      "Epoch 27/200  Train: 0.9865  Val: 1.0613\n",
      "Epoch 28/200  Train: 0.9038  Val: 0.9179\n",
      "Epoch 29/200  Train: 0.9643  Val: 1.8454\n",
      "Epoch 30/200  Train: 1.5549  Val: 3.6727\n",
      "Epoch 31/200  Train: 1.2366  Val: 1.1526\n",
      "Epoch 32/200  Train: 0.8618  Val: 0.8209\n",
      "Epoch 33/200  Train: 0.7807  Val: 0.6279\n",
      "Epoch 34/200  Train: 0.9089  Val: 1.0772\n",
      "Epoch 35/200  Train: 1.2885  Val: 0.7645\n",
      "Epoch 36/200  Train: 0.8671  Val: 0.7240\n",
      "Epoch 37/200  Train: 0.8174  Val: 0.7400\n",
      "Epoch 38/200  Train: 0.7602  Val: 0.8948\n",
      "Epoch 39/200  Train: 0.9151  Val: 0.7807\n",
      "Epoch 40/200  Train: 0.9141  Val: 1.2267\n",
      "Epoch 41/200  Train: 0.9758  Val: 0.8991\n",
      "Epoch 42/200  Train: 0.7703  Val: 0.6578\n",
      "Epoch 43/200  Train: 0.6321  Val: 0.7765\n",
      "Epoch 44/200  Train: 0.7255  Val: 0.8372\n",
      "Epoch 45/200  Train: 0.9440  Val: 0.6474\n",
      "Epoch 46/200  Train: 0.7752  Val: 0.6523\n",
      "Epoch 47/200  Train: 0.7396  Val: 0.8107\n",
      "Epoch 48/200  Train: 0.6382  Val: 0.6868\n",
      "Epoch 49/200  Train: 0.8050  Val: 0.7173\n",
      "Epoch 50/200  Train: 0.8874  Val: 0.5961\n",
      "Epoch 51/200  Train: 0.7061  Val: 0.6932\n",
      "Epoch 52/200  Train: 0.6940  Val: 0.5771\n",
      "Epoch 53/200  Train: 0.6842  Val: 0.7355\n",
      "Epoch 54/200  Train: 0.6042  Val: 0.6985\n",
      "Epoch 55/200  Train: 0.8856  Val: 0.6050\n",
      "Epoch 56/200  Train: 0.7093  Val: 0.7310\n",
      "Epoch 57/200  Train: 0.8399  Val: 0.8879\n",
      "Epoch 58/200  Train: 0.7281  Val: 0.5462\n",
      "Epoch 59/200  Train: 0.6535  Val: 0.5659\n",
      "Epoch 60/200  Train: 0.6132  Val: 0.5832\n",
      "Epoch 61/200  Train: 0.6016  Val: 0.5714\n",
      "Epoch 62/200  Train: 0.5938  Val: 0.6389\n",
      "Epoch 63/200  Train: 0.7780  Val: 0.6025\n",
      "Epoch 64/200  Train: 0.6177  Val: 0.6067\n",
      "Epoch 65/200  Train: 0.6475  Val: 0.6165\n",
      "Epoch 66/200  Train: 0.5574  Val: 0.5348\n",
      "Epoch 67/200  Train: 0.5718  Val: 0.6686\n",
      "Epoch 68/200  Train: 0.5322  Val: 0.5356\n",
      "Epoch 69/200  Train: 0.7126  Val: 1.1892\n",
      "Epoch 70/200  Train: 0.7673  Val: 0.4764\n",
      "Epoch 71/200  Train: 0.5358  Val: 0.5038\n",
      "Epoch 72/200  Train: 0.6969  Val: 0.5150\n",
      "Epoch 73/200  Train: 0.9215  Val: 0.3777\n",
      "Epoch 74/200  Train: 0.5780  Val: 0.5353\n",
      "Epoch 75/200  Train: 0.5130  Val: 0.5927\n",
      "Epoch 76/200  Train: 0.5124  Val: 0.3999\n",
      "Epoch 77/200  Train: 0.5196  Val: 0.6317\n",
      "Epoch 78/200  Train: 0.5807  Val: 0.4617\n",
      "Epoch 79/200  Train: 0.5465  Val: 1.0196\n",
      "Epoch 80/200  Train: 0.6933  Val: 0.6301\n",
      "Epoch 81/200  Train: 0.5267  Val: 0.4784\n",
      "Epoch 82/200  Train: 0.5416  Val: 0.4299\n",
      "Epoch 83/200  Train: 0.4334  Val: 0.4858\n",
      "Epoch 84/200  Train: 0.5132  Val: 0.4895\n",
      "Epoch 85/200  Train: 0.5271  Val: 0.7294\n",
      "Epoch 86/200  Train: 0.4810  Val: 0.5290\n",
      "Epoch 87/200  Train: 0.5605  Val: 0.5176\n",
      "Epoch 88/200  Train: 0.5122  Val: 0.5242\n",
      "Epoch 89/200  Train: 0.4231  Val: 0.4049\n",
      "Epoch 90/200  Train: 0.5644  Val: 0.4028\n",
      "Epoch 91/200  Train: 0.5582  Val: 0.3552\n",
      "Epoch 92/200  Train: 0.4642  Val: 0.6069\n",
      "Epoch 93/200  Train: 0.4855  Val: 0.4785\n",
      "Epoch 94/200  Train: 0.4688  Val: 0.4676\n",
      "Epoch 95/200  Train: 0.5950  Val: 0.4909\n",
      "Epoch 96/200  Train: 0.4156  Val: 0.5997\n",
      "Epoch 97/200  Train: 0.4347  Val: 0.5193\n",
      "Epoch 98/200  Train: 0.4582  Val: 0.4687\n",
      "Epoch 99/200  Train: 0.4296  Val: 0.3074\n",
      "Epoch 100/200  Train: 0.4258  Val: 0.6891\n",
      "Epoch 101/200  Train: 0.5234  Val: 0.4638\n",
      "Epoch 102/200  Train: 0.3972  Val: 0.2608\n",
      "Epoch 103/200  Train: 0.3920  Val: 0.3564\n",
      "Epoch 104/200  Train: 0.4062  Val: 0.4084\n",
      "Epoch 105/200  Train: 0.3835  Val: 0.3119\n",
      "Epoch 106/200  Train: 0.5118  Val: 0.7469\n",
      "Epoch 107/200  Train: 0.4580  Val: 0.3017\n",
      "Epoch 108/200  Train: 0.3012  Val: 0.4464\n",
      "Epoch 109/200  Train: 0.4276  Val: 0.3093\n",
      "Epoch 110/200  Train: 0.5205  Val: 0.5450\n",
      "Epoch 111/200  Train: 0.3442  Val: 0.4163\n",
      "Epoch 112/200  Train: 0.3654  Val: 0.2468\n",
      "Epoch 113/200  Train: 0.4736  Val: 0.5151\n",
      "Epoch 114/200  Train: 0.3382  Val: 0.3390\n",
      "Epoch 115/200  Train: 0.3938  Val: 0.2842\n",
      "Epoch 116/200  Train: 0.3281  Val: 0.4225\n",
      "Epoch 117/200  Train: 0.3060  Val: 0.3082\n",
      "Epoch 118/200  Train: 0.2719  Val: 0.4559\n",
      "Epoch 119/200  Train: 0.3732  Val: 0.3399\n",
      "Epoch 120/200  Train: 0.2611  Val: 0.4511\n",
      "Epoch 121/200  Train: 0.3008  Val: 0.2890\n",
      "Epoch 122/200  Train: 0.3098  Val: 0.4172\n",
      "Epoch 123/200  Train: 0.3307  Val: 0.4693\n",
      "Epoch 124/200  Train: 0.2534  Val: 0.3752\n",
      "Epoch 125/200  Train: 0.3771  Val: 0.4473\n",
      "Epoch 126/200  Train: 0.4600  Val: 0.3502\n",
      "Epoch 127/200  Train: 0.5804  Val: 0.6143\n",
      "Epoch 128/200  Train: 0.4363  Val: 0.4024\n",
      "Epoch 129/200  Train: 0.3242  Val: 0.3561\n",
      "Epoch 130/200  Train: 0.2990  Val: 0.3372\n",
      "Epoch 131/200  Train: 0.3425  Val: 0.3555\n",
      "Epoch 132/200  Train: 0.3047  Val: 0.2662\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:45,343]\u001b[0m Trial 26 finished with value: 0.24681580662727357 and parameters: {'batch_size': 32, 'lr': 5.1937546288918135e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 570, 'beta_end': 0.017334871029175025, 'dropout': 0.015316322726160509}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 50.4300  Val: 2.9003\n",
      "Epoch 2/200  Train: 5.1788  Val: 2.2148\n",
      "Epoch 3/200  Train: 1.4031  Val: 1.0274\n",
      "Epoch 4/200  Train: 1.0243  Val: 1.0242\n",
      "Epoch 5/200  Train: 1.0498  Val: 0.9706\n",
      "Epoch 6/200  Train: 1.0564  Val: 1.0356\n",
      "Epoch 7/200  Train: 1.1156  Val: 0.8877\n",
      "Epoch 8/200  Train: 1.0260  Val: 1.2092\n",
      "Epoch 9/200  Train: 1.0867  Val: 0.8096\n",
      "Epoch 10/200  Train: 1.0014  Val: 1.2361\n",
      "Epoch 11/200  Train: 1.1084  Val: 1.4135\n",
      "Epoch 12/200  Train: 0.9744  Val: 1.0154\n",
      "Epoch 13/200  Train: 0.9745  Val: 1.2455\n",
      "Epoch 14/200  Train: 1.2012  Val: 1.2651\n",
      "Epoch 15/200  Train: 1.0983  Val: 0.9462\n",
      "Epoch 16/200  Train: 1.2558  Val: 1.1023\n",
      "Epoch 17/200  Train: 0.9868  Val: 0.9325\n",
      "Epoch 18/200  Train: 0.9997  Val: 0.7373\n",
      "Epoch 19/200  Train: 1.0201  Val: 0.9121\n",
      "Epoch 20/200  Train: 0.9932  Val: 0.8781\n",
      "Epoch 21/200  Train: 0.8955  Val: 1.5999\n",
      "Epoch 22/200  Train: 1.1186  Val: 1.0764\n",
      "Epoch 23/200  Train: 0.9718  Val: 1.2485\n",
      "Epoch 24/200  Train: 1.2206  Val: 1.1522\n",
      "Epoch 25/200  Train: 1.1672  Val: 1.1172\n",
      "Epoch 26/200  Train: 0.9416  Val: 1.0280\n",
      "Epoch 27/200  Train: 1.0373  Val: 1.0453\n",
      "Epoch 28/200  Train: 1.0446  Val: 0.8935\n",
      "Epoch 29/200  Train: 1.0143  Val: 1.0926\n",
      "Epoch 30/200  Train: 1.3970  Val: 1.2345\n",
      "Epoch 31/200  Train: 1.2262  Val: 1.1362\n",
      "Epoch 32/200  Train: 0.9187  Val: 1.0280\n",
      "Epoch 33/200  Train: 0.8864  Val: 0.7354\n",
      "Epoch 34/200  Train: 1.0404  Val: 0.8631\n",
      "Epoch 35/200  Train: 0.8010  Val: 0.7698\n",
      "Epoch 36/200  Train: 0.8693  Val: 1.2479\n",
      "Epoch 37/200  Train: 1.0915  Val: 1.3124\n",
      "Epoch 38/200  Train: 0.9351  Val: 0.8528\n",
      "Epoch 39/200  Train: 0.8143  Val: 1.4972\n",
      "Epoch 40/200  Train: 1.1064  Val: 0.7685\n",
      "Epoch 41/200  Train: 0.8230  Val: 0.9768\n",
      "Epoch 42/200  Train: 1.0661  Val: 1.2226\n",
      "Epoch 43/200  Train: 1.0477  Val: 1.0684\n",
      "Epoch 44/200  Train: 0.9164  Val: 0.9414\n",
      "Epoch 45/200  Train: 0.9645  Val: 0.9874\n",
      "Epoch 46/200  Train: 0.8423  Val: 0.5960\n",
      "Epoch 47/200  Train: 0.9102  Val: 1.0240\n",
      "Epoch 48/200  Train: 0.8129  Val: 0.7788\n",
      "Epoch 49/200  Train: 0.9376  Val: 1.2939\n",
      "Epoch 50/200  Train: 1.0539  Val: 0.7496\n",
      "Epoch 51/200  Train: 0.9534  Val: 1.1828\n",
      "Epoch 52/200  Train: 1.1368  Val: 1.5906\n",
      "Epoch 53/200  Train: 1.6223  Val: 0.7252\n",
      "Epoch 54/200  Train: 0.8687  Val: 0.5690\n",
      "Epoch 55/200  Train: 0.8030  Val: 0.6814\n",
      "Epoch 56/200  Train: 1.0533  Val: 1.1669\n",
      "Epoch 57/200  Train: 0.9294  Val: 0.7619\n",
      "Epoch 58/200  Train: 1.3244  Val: 0.9665\n",
      "Epoch 59/200  Train: 1.5939  Val: 1.2370\n",
      "Epoch 60/200  Train: 0.9076  Val: 0.7202\n",
      "Epoch 61/200  Train: 0.7856  Val: 0.7784\n",
      "Epoch 62/200  Train: 0.7502  Val: 0.6581\n",
      "Epoch 63/200  Train: 1.2041  Val: 1.4734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200  Train: 1.1289  Val: 1.4497\n",
      "Epoch 65/200  Train: 1.0529  Val: 3.8891\n",
      "Epoch 66/200  Train: 1.3633  Val: 0.7466\n",
      "Epoch 67/200  Train: 0.7010  Val: 0.6796\n",
      "Epoch 68/200  Train: 0.9517  Val: 0.8323\n",
      "Epoch 69/200  Train: 0.8195  Val: 0.8186\n",
      "Epoch 70/200  Train: 0.7752  Val: 1.0663\n",
      "Epoch 71/200  Train: 0.6981  Val: 0.8709\n",
      "Epoch 72/200  Train: 0.7547  Val: 1.1099\n",
      "Epoch 73/200  Train: 1.0225  Val: 0.8800\n",
      "Epoch 74/200  Train: 0.7234  Val: 0.6428\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:53,423]\u001b[0m Trial 27 finished with value: 0.568966680765152 and parameters: {'batch_size': 32, 'lr': 3.985804942900072e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 7, 'noise_steps': 710, 'beta_end': 0.014544384226803816, 'dropout': 0.03381151597912439}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 15.7376  Val: 3.0785\n",
      "Epoch 2/200  Train: 2.0322  Val: 1.5014\n",
      "Epoch 3/200  Train: 1.2357  Val: 0.8630\n",
      "Epoch 4/200  Train: 1.0062  Val: 0.8631\n",
      "Epoch 5/200  Train: 1.0114  Val: 0.9306\n",
      "Epoch 6/200  Train: 0.9780  Val: 0.6791\n",
      "Epoch 7/200  Train: 0.9371  Val: 0.8825\n",
      "Epoch 8/200  Train: 0.9679  Val: 0.7411\n",
      "Epoch 9/200  Train: 0.8949  Val: 0.9551\n",
      "Epoch 10/200  Train: 0.9481  Val: 1.0409\n",
      "Epoch 11/200  Train: 0.9990  Val: 1.0228\n",
      "Epoch 12/200  Train: 0.8662  Val: 1.0516\n",
      "Epoch 13/200  Train: 0.9435  Val: 1.0197\n",
      "Epoch 14/200  Train: 0.9800  Val: 1.0345\n",
      "Epoch 15/200  Train: 0.8732  Val: 1.0969\n",
      "Epoch 16/200  Train: 1.0139  Val: 0.7877\n",
      "Epoch 17/200  Train: 0.7926  Val: 0.8962\n",
      "Epoch 18/200  Train: 0.8016  Val: 0.7852\n",
      "Epoch 19/200  Train: 0.8363  Val: 1.0142\n",
      "Epoch 20/200  Train: 0.8025  Val: 0.9994\n",
      "Epoch 21/200  Train: 0.8389  Val: 0.7632\n",
      "Epoch 22/200  Train: 0.8979  Val: 1.1891\n",
      "Epoch 23/200  Train: 0.9772  Val: 0.8516\n",
      "Epoch 24/200  Train: 0.7937  Val: 0.6816\n",
      "Epoch 25/200  Train: 0.7979  Val: 0.8545\n",
      "Epoch 26/200  Train: 0.8765  Val: 0.8541\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:37:55,047]\u001b[0m Trial 28 finished with value: 0.6790977120399475 and parameters: {'batch_size': 32, 'lr': 6.809159974106459e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 4, 'noise_steps': 787, 'beta_end': 0.019084501796963985, 'dropout': 0.02373325253181132}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 27.3314  Val: 8.1634\n",
      "Epoch 2/200  Train: 5.8771  Val: 0.9736\n",
      "Epoch 3/200  Train: 2.2363  Val: 0.8362\n",
      "Epoch 4/200  Train: 1.2077  Val: 1.1042\n",
      "Epoch 5/200  Train: 1.1562  Val: 1.2037\n",
      "Epoch 6/200  Train: 1.3045  Val: 1.0209\n",
      "Epoch 7/200  Train: 1.0173  Val: 0.9041\n",
      "Epoch 8/200  Train: 1.0572  Val: 0.8305\n",
      "Epoch 9/200  Train: 1.1952  Val: 1.0340\n",
      "Epoch 10/200  Train: 1.0680  Val: 1.0614\n",
      "Epoch 11/200  Train: 0.9405  Val: 0.8590\n",
      "Epoch 12/200  Train: 0.9446  Val: 0.9798\n",
      "Epoch 13/200  Train: 1.0257  Val: 0.9388\n",
      "Epoch 14/200  Train: 0.9383  Val: 0.8911\n",
      "Epoch 15/200  Train: 0.9651  Val: 0.9386\n",
      "Epoch 16/200  Train: 0.9402  Val: 1.0505\n",
      "Epoch 17/200  Train: 0.8796  Val: 0.7043\n",
      "Epoch 18/200  Train: 0.8331  Val: 1.1521\n",
      "Epoch 19/200  Train: 0.9490  Val: 0.7599\n",
      "Epoch 20/200  Train: 0.8594  Val: 0.9646\n",
      "Epoch 21/200  Train: 0.9990  Val: 1.1579\n",
      "Epoch 22/200  Train: 1.0098  Val: 1.1757\n",
      "Epoch 23/200  Train: 0.9234  Val: 1.3949\n",
      "Epoch 24/200  Train: 1.0742  Val: 0.8554\n",
      "Epoch 25/200  Train: 1.0374  Val: 0.9514\n",
      "Epoch 26/200  Train: 0.8906  Val: 1.0054\n",
      "Epoch 27/200  Train: 0.9451  Val: 0.8914\n",
      "Epoch 28/200  Train: 0.7698  Val: 1.0567\n",
      "Epoch 29/200  Train: 0.8274  Val: 0.7794\n",
      "Epoch 30/200  Train: 0.8648  Val: 0.9060\n",
      "Epoch 31/200  Train: 0.8938  Val: 1.1589\n",
      "Epoch 32/200  Train: 0.9001  Val: 0.6666\n",
      "Epoch 33/200  Train: 0.8988  Val: 0.9616\n",
      "Epoch 34/200  Train: 0.9099  Val: 1.2802\n",
      "Epoch 35/200  Train: 1.0155  Val: 0.6197\n",
      "Epoch 36/200  Train: 0.8717  Val: 0.7657\n",
      "Epoch 37/200  Train: 0.8791  Val: 0.7887\n",
      "Epoch 38/200  Train: 0.7058  Val: 0.7582\n",
      "Epoch 39/200  Train: 0.8363  Val: 0.6383\n",
      "Epoch 40/200  Train: 0.7720  Val: 1.1131\n",
      "Epoch 41/200  Train: 0.8377  Val: 0.7209\n",
      "Epoch 42/200  Train: 0.8195  Val: 0.8047\n",
      "Epoch 43/200  Train: 0.7836  Val: 0.7239\n",
      "Epoch 44/200  Train: 0.7826  Val: 0.6101\n",
      "Epoch 45/200  Train: 0.7560  Val: 0.8210\n",
      "Epoch 46/200  Train: 0.7395  Val: 0.8461\n",
      "Epoch 47/200  Train: 0.6674  Val: 0.6204\n",
      "Epoch 48/200  Train: 0.8655  Val: 0.9182\n",
      "Epoch 49/200  Train: 0.9218  Val: 0.8432\n",
      "Epoch 50/200  Train: 0.8381  Val: 0.6289\n",
      "Epoch 51/200  Train: 0.8540  Val: 0.9376\n",
      "Epoch 52/200  Train: 0.8387  Val: 0.6747\n",
      "Epoch 53/200  Train: 0.7218  Val: 0.6402\n",
      "Epoch 54/200  Train: 0.7427  Val: 0.5590\n",
      "Epoch 55/200  Train: 0.6127  Val: 0.7524\n",
      "Epoch 56/200  Train: 0.5814  Val: 0.8625\n",
      "Epoch 57/200  Train: 0.8627  Val: 0.5590\n",
      "Epoch 58/200  Train: 0.9741  Val: 0.8783\n",
      "Epoch 59/200  Train: 0.8009  Val: 0.6750\n",
      "Epoch 60/200  Train: 0.7882  Val: 0.6965\n",
      "Epoch 61/200  Train: 0.7254  Val: 0.6335\n",
      "Epoch 62/200  Train: 0.6439  Val: 0.8127\n",
      "Epoch 63/200  Train: 0.6546  Val: 0.5985\n",
      "Epoch 64/200  Train: 0.5768  Val: 0.5203\n",
      "Epoch 65/200  Train: 0.7457  Val: 0.9560\n",
      "Epoch 66/200  Train: 0.7310  Val: 0.6367\n",
      "Epoch 67/200  Train: 0.6179  Val: 0.6207\n",
      "Epoch 68/200  Train: 0.7023  Val: 0.6671\n",
      "Epoch 69/200  Train: 0.8196  Val: 0.6380\n",
      "Epoch 70/200  Train: 0.8540  Val: 0.5195\n",
      "Epoch 71/200  Train: 0.8216  Val: 0.6173\n",
      "Epoch 72/200  Train: 0.6165  Val: 0.5864\n",
      "Epoch 73/200  Train: 0.5950  Val: 0.6193\n",
      "Epoch 74/200  Train: 0.5448  Val: 0.7566\n",
      "Epoch 75/200  Train: 0.5790  Val: 0.9053\n",
      "Epoch 76/200  Train: 0.7272  Val: 0.4718\n",
      "Epoch 77/200  Train: 0.5362  Val: 0.8000\n",
      "Epoch 78/200  Train: 0.5687  Val: 0.5882\n",
      "Epoch 79/200  Train: 0.5436  Val: 0.4434\n",
      "Epoch 80/200  Train: 0.5443  Val: 0.8021\n",
      "Epoch 81/200  Train: 0.5489  Val: 0.5004\n",
      "Epoch 82/200  Train: 0.7038  Val: 1.0933\n",
      "Epoch 83/200  Train: 0.6120  Val: 0.5854\n",
      "Epoch 84/200  Train: 0.5023  Val: 0.4196\n",
      "Epoch 85/200  Train: 0.5413  Val: 0.5746\n",
      "Epoch 86/200  Train: 0.5493  Val: 0.5207\n",
      "Epoch 87/200  Train: 0.4940  Val: 0.4081\n",
      "Epoch 88/200  Train: 0.4648  Val: 0.4977\n",
      "Epoch 89/200  Train: 0.7434  Val: 0.9512\n",
      "Epoch 90/200  Train: 0.7618  Val: 0.5546\n",
      "Epoch 91/200  Train: 0.4709  Val: 0.4058\n",
      "Epoch 92/200  Train: 0.4651  Val: 0.4249\n",
      "Epoch 93/200  Train: 0.4888  Val: 0.5145\n",
      "Epoch 94/200  Train: 0.4921  Val: 0.4584\n",
      "Epoch 95/200  Train: 0.4067  Val: 0.4145\n",
      "Epoch 96/200  Train: 0.4919  Val: 0.3960\n",
      "Epoch 97/200  Train: 0.5088  Val: 0.5701\n",
      "Epoch 98/200  Train: 0.4833  Val: 0.4003\n",
      "Epoch 99/200  Train: 0.4751  Val: 0.5807\n",
      "Epoch 100/200  Train: 0.4238  Val: 0.4220\n",
      "Epoch 101/200  Train: 0.4266  Val: 0.5841\n",
      "Epoch 102/200  Train: 0.4593  Val: 0.4408\n",
      "Epoch 103/200  Train: 0.4925  Val: 0.4439\n",
      "Epoch 104/200  Train: 0.5728  Val: 0.6225\n",
      "Epoch 105/200  Train: 0.6735  Val: 0.4851\n",
      "Epoch 106/200  Train: 0.6125  Val: 0.5380\n",
      "Epoch 107/200  Train: 0.5222  Val: 0.4878\n",
      "Epoch 108/200  Train: 0.4483  Val: 0.3759\n",
      "Epoch 109/200  Train: 0.5159  Val: 0.3690\n",
      "Epoch 110/200  Train: 0.4269  Val: 0.4454\n",
      "Epoch 111/200  Train: 0.5612  Val: 0.3750\n",
      "Epoch 112/200  Train: 0.6694  Val: 0.8857\n",
      "Epoch 113/200  Train: 0.4758  Val: 0.3916\n",
      "Epoch 114/200  Train: 0.5298  Val: 0.5180\n",
      "Epoch 115/200  Train: 0.3898  Val: 0.4118\n",
      "Epoch 116/200  Train: 0.3459  Val: 0.4604\n",
      "Epoch 117/200  Train: 0.3862  Val: 0.6495\n",
      "Epoch 118/200  Train: 0.4940  Val: 0.4700\n",
      "Epoch 119/200  Train: 0.4476  Val: 0.6498\n",
      "Epoch 120/200  Train: 0.4193  Val: 0.3167\n",
      "Epoch 121/200  Train: 0.3317  Val: 0.3276\n",
      "Epoch 122/200  Train: 0.3081  Val: 0.2696\n",
      "Epoch 123/200  Train: 0.3787  Val: 0.3266\n",
      "Epoch 124/200  Train: 0.3125  Val: 0.3335\n",
      "Epoch 125/200  Train: 0.3256  Val: 0.3075\n",
      "Epoch 126/200  Train: 0.3706  Val: 0.4606\n",
      "Epoch 127/200  Train: 0.3591  Val: 0.3675\n",
      "Epoch 128/200  Train: 0.3177  Val: 0.2849\n",
      "Epoch 129/200  Train: 0.3507  Val: 0.4141\n",
      "Epoch 130/200  Train: 0.3846  Val: 0.3361\n",
      "Epoch 131/200  Train: 0.3581  Val: 0.3186\n",
      "Epoch 132/200  Train: 0.2875  Val: 0.3025\n",
      "Epoch 133/200  Train: 0.2669  Val: 0.2909\n",
      "Epoch 134/200  Train: 0.2720  Val: 0.4046\n",
      "Epoch 135/200  Train: 0.2932  Val: 0.2845\n",
      "Epoch 136/200  Train: 0.3092  Val: 0.3091\n",
      "Epoch 137/200  Train: 0.2819  Val: 0.3416\n",
      "Epoch 138/200  Train: 0.2558  Val: 0.2533\n",
      "Epoch 139/200  Train: 0.2578  Val: 0.2218\n",
      "Epoch 140/200  Train: 0.2046  Val: 0.2696\n",
      "Epoch 141/200  Train: 0.3069  Val: 0.4099\n",
      "Epoch 142/200  Train: 0.2985  Val: 0.2171\n",
      "Epoch 143/200  Train: 0.2873  Val: 0.3325\n",
      "Epoch 144/200  Train: 0.2493  Val: 0.3016\n",
      "Epoch 145/200  Train: 0.2635  Val: 0.2900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200  Train: 0.3006  Val: 0.3434\n",
      "Epoch 147/200  Train: 0.2352  Val: 0.2636\n",
      "Epoch 148/200  Train: 0.2156  Val: 0.2750\n",
      "Epoch 149/200  Train: 0.2183  Val: 0.1389\n",
      "Epoch 150/200  Train: 0.1840  Val: 0.1925\n",
      "Epoch 151/200  Train: 0.2037  Val: 0.1940\n",
      "Epoch 152/200  Train: 0.2329  Val: 0.4603\n",
      "Epoch 153/200  Train: 0.2945  Val: 0.2520\n",
      "Epoch 154/200  Train: 0.2504  Val: 0.1517\n",
      "Epoch 155/200  Train: 0.2459  Val: 0.1994\n",
      "Epoch 156/200  Train: 0.2843  Val: 0.3998\n",
      "Epoch 157/200  Train: 0.2618  Val: 0.1926\n",
      "Epoch 158/200  Train: 0.2748  Val: 0.2510\n",
      "Epoch 159/200  Train: 0.2775  Val: 0.2662\n",
      "Epoch 160/200  Train: 0.2490  Val: 0.3330\n",
      "Epoch 161/200  Train: 0.1853  Val: 0.2971\n",
      "Epoch 162/200  Train: 0.1579  Val: 0.2768\n",
      "Epoch 163/200  Train: 0.1698  Val: 0.2903\n",
      "Epoch 164/200  Train: 0.1788  Val: 0.4825\n",
      "Epoch 165/200  Train: 0.2360  Val: 0.2424\n",
      "Epoch 166/200  Train: 0.1707  Val: 0.3675\n",
      "Epoch 167/200  Train: 0.1359  Val: 0.2650\n",
      "Epoch 168/200  Train: 0.1537  Val: 0.3212\n",
      "Epoch 169/200  Train: 0.1756  Val: 0.2749\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:02,708]\u001b[0m Trial 29 finished with value: 0.13894178420305253 and parameters: {'batch_size': 64, 'lr': 7.824745006399626e-05, 'hidden_dim': 1024, 'time_embed_dim': 128, 'layers': 5, 'noise_steps': 696, 'beta_end': 0.018030667735514604, 'dropout': 0.030697030471226353}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 3.1537  Val: 1.5173\n",
      "Epoch 2/200  Train: 1.2689  Val: 1.4238\n",
      "Epoch 3/200  Train: 1.1868  Val: 1.0061\n",
      "Epoch 4/200  Train: 0.9819  Val: 0.9758\n",
      "Epoch 5/200  Train: 1.1230  Val: 1.0646\n",
      "Epoch 6/200  Train: 0.9491  Val: 1.0301\n",
      "Epoch 7/200  Train: 1.0216  Val: 1.1339\n",
      "Epoch 8/200  Train: 0.9446  Val: 0.7940\n",
      "Epoch 9/200  Train: 0.9791  Val: 1.0290\n",
      "Epoch 10/200  Train: 1.0102  Val: 0.9217\n",
      "Epoch 11/200  Train: 1.1416  Val: 1.1493\n",
      "Epoch 12/200  Train: 1.0700  Val: 1.1331\n",
      "Epoch 13/200  Train: 1.0445  Val: 1.1162\n",
      "Epoch 14/200  Train: 0.9456  Val: 1.1468\n",
      "Epoch 15/200  Train: 1.0484  Val: 1.0816\n",
      "Epoch 16/200  Train: 1.0154  Val: 1.0417\n",
      "Epoch 17/200  Train: 1.0108  Val: 0.8866\n",
      "Epoch 18/200  Train: 1.1492  Val: 0.9693\n",
      "Epoch 19/200  Train: 0.9387  Val: 1.1098\n",
      "Epoch 20/200  Train: 0.9951  Val: 0.9595\n",
      "Epoch 21/200  Train: 0.9806  Val: 1.0106\n",
      "Epoch 22/200  Train: 1.0096  Val: 0.9379\n",
      "Epoch 23/200  Train: 0.9892  Val: 1.0051\n",
      "Epoch 24/200  Train: 1.0296  Val: 0.9496\n",
      "Epoch 25/200  Train: 1.0292  Val: 1.1213\n",
      "Epoch 26/200  Train: 1.0238  Val: 0.8658\n",
      "Epoch 27/200  Train: 1.0651  Val: 1.3057\n",
      "Epoch 28/200  Train: 1.1159  Val: 1.0136\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:03,708]\u001b[0m Trial 30 finished with value: 0.7939610838890075 and parameters: {'batch_size': 64, 'lr': 1.020171455373152e-05, 'hidden_dim': 1024, 'time_embed_dim': 64, 'layers': 3, 'noise_steps': 532, 'beta_end': 0.019368364317103825, 'dropout': 0.03932849240418815}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 15.0041  Val: 0.9644\n",
      "Epoch 2/200  Train: 1.6182  Val: 1.2471\n",
      "Epoch 3/200  Train: 1.2285  Val: 0.8523\n",
      "Epoch 4/200  Train: 1.0817  Val: 0.8815\n",
      "Epoch 5/200  Train: 1.1627  Val: 0.9541\n",
      "Epoch 6/200  Train: 1.1595  Val: 0.6798\n",
      "Epoch 7/200  Train: 1.1681  Val: 0.9845\n",
      "Epoch 8/200  Train: 1.0471  Val: 0.7224\n",
      "Epoch 9/200  Train: 0.9058  Val: 1.6804\n",
      "Epoch 10/200  Train: 1.0932  Val: 1.2162\n",
      "Epoch 11/200  Train: 1.0888  Val: 0.9709\n",
      "Epoch 12/200  Train: 1.0400  Val: 2.1723\n",
      "Epoch 13/200  Train: 1.3480  Val: 1.2288\n",
      "Epoch 14/200  Train: 1.0602  Val: 1.1355\n",
      "Epoch 15/200  Train: 1.0787  Val: 0.9985\n",
      "Epoch 16/200  Train: 0.9826  Val: 1.1290\n",
      "Epoch 17/200  Train: 0.8761  Val: 0.8407\n",
      "Epoch 18/200  Train: 0.9063  Val: 0.7474\n",
      "Epoch 19/200  Train: 1.3941  Val: 0.7781\n",
      "Epoch 20/200  Train: 0.9902  Val: 1.0860\n",
      "Epoch 21/200  Train: 1.2649  Val: 1.0707\n",
      "Epoch 22/200  Train: 1.1589  Val: 1.0340\n",
      "Epoch 23/200  Train: 1.1648  Val: 0.7917\n",
      "Epoch 24/200  Train: 0.8903  Val: 0.7023\n",
      "Epoch 25/200  Train: 0.7861  Val: 0.8144\n",
      "Epoch 26/200  Train: 0.8523  Val: 0.8780\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:05,611]\u001b[0m Trial 31 finished with value: 0.6798443138599396 and parameters: {'batch_size': 32, 'lr': 6.339751481100882e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 4, 'noise_steps': 559, 'beta_end': 0.018445706027764734, 'dropout': 0.029440558005166526}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 20.7080  Val: 2.4312\n",
      "Epoch 2/200  Train: 2.5209  Val: 2.4993\n",
      "Epoch 3/200  Train: 1.3844  Val: 1.0710\n",
      "Epoch 4/200  Train: 1.1677  Val: 0.9416\n",
      "Epoch 5/200  Train: 1.1734  Val: 1.0999\n",
      "Epoch 6/200  Train: 1.0884  Val: 0.7681\n",
      "Epoch 7/200  Train: 1.1423  Val: 0.9844\n",
      "Epoch 8/200  Train: 1.0846  Val: 0.7386\n",
      "Epoch 9/200  Train: 1.0602  Val: 0.9160\n",
      "Epoch 10/200  Train: 1.1019  Val: 1.0583\n",
      "Epoch 11/200  Train: 1.1160  Val: 1.1824\n",
      "Epoch 12/200  Train: 0.9722  Val: 1.8533\n",
      "Epoch 13/200  Train: 1.0176  Val: 0.9244\n",
      "Epoch 14/200  Train: 0.9204  Val: 1.4905\n",
      "Epoch 15/200  Train: 1.3156  Val: 1.1897\n",
      "Epoch 16/200  Train: 1.3647  Val: 1.4257\n",
      "Epoch 17/200  Train: 1.2090  Val: 1.1053\n",
      "Epoch 18/200  Train: 0.9947  Val: 0.8280\n",
      "Epoch 19/200  Train: 0.8536  Val: 1.0459\n",
      "Epoch 20/200  Train: 0.7811  Val: 1.1463\n",
      "Epoch 21/200  Train: 0.9092  Val: 0.7799\n",
      "Epoch 22/200  Train: 0.8601  Val: 0.7402\n",
      "Epoch 23/200  Train: 0.8915  Val: 1.0258\n",
      "Epoch 24/200  Train: 0.7848  Val: 0.6491\n",
      "Epoch 25/200  Train: 0.8052  Val: 1.1619\n",
      "Epoch 26/200  Train: 1.0145  Val: 1.0100\n",
      "Epoch 27/200  Train: 0.9744  Val: 1.5824\n",
      "Epoch 28/200  Train: 1.0451  Val: 0.8132\n",
      "Epoch 29/200  Train: 0.8970  Val: 1.0015\n",
      "Epoch 30/200  Train: 0.8767  Val: 0.8034\n",
      "Epoch 31/200  Train: 0.8400  Val: 0.7230\n",
      "Epoch 32/200  Train: 0.8454  Val: 0.7431\n",
      "Epoch 33/200  Train: 0.7455  Val: 0.7502\n",
      "Epoch 34/200  Train: 0.7359  Val: 0.7639\n",
      "Epoch 35/200  Train: 0.8158  Val: 0.7290\n",
      "Epoch 36/200  Train: 0.9333  Val: 1.0095\n",
      "Epoch 37/200  Train: 0.8139  Val: 0.6434\n",
      "Epoch 38/200  Train: 0.7257  Val: 0.7145\n",
      "Epoch 39/200  Train: 0.7351  Val: 0.8137\n",
      "Epoch 40/200  Train: 0.9735  Val: 0.7420\n",
      "Epoch 41/200  Train: 0.7863  Val: 0.6849\n",
      "Epoch 42/200  Train: 0.9578  Val: 0.8524\n",
      "Epoch 43/200  Train: 0.8931  Val: 0.5980\n",
      "Epoch 44/200  Train: 1.0924  Val: 1.2232\n",
      "Epoch 45/200  Train: 0.7679  Val: 0.9544\n",
      "Epoch 46/200  Train: 0.7667  Val: 0.9662\n",
      "Epoch 47/200  Train: 0.7409  Val: 0.5651\n",
      "Epoch 48/200  Train: 0.7354  Val: 0.6858\n",
      "Epoch 49/200  Train: 0.6554  Val: 0.6121\n",
      "Epoch 50/200  Train: 0.6874  Val: 0.6407\n",
      "Epoch 51/200  Train: 0.9081  Val: 0.8362\n",
      "Epoch 52/200  Train: 0.7514  Val: 0.6528\n",
      "Epoch 53/200  Train: 0.6797  Val: 0.6908\n",
      "Epoch 54/200  Train: 0.7470  Val: 0.8070\n",
      "Epoch 55/200  Train: 0.6201  Val: 0.6830\n",
      "Epoch 56/200  Train: 0.7008  Val: 0.6652\n",
      "Epoch 57/200  Train: 0.6103  Val: 0.7335\n",
      "Epoch 58/200  Train: 0.6029  Val: 0.8182\n",
      "Epoch 59/200  Train: 0.6773  Val: 0.6278\n",
      "Epoch 60/200  Train: 0.8704  Val: 1.1288\n",
      "Epoch 61/200  Train: 0.9766  Val: 0.4815\n",
      "Epoch 62/200  Train: 0.6081  Val: 0.5386\n",
      "Epoch 63/200  Train: 0.5527  Val: 0.4989\n",
      "Epoch 64/200  Train: 0.5512  Val: 0.5252\n",
      "Epoch 65/200  Train: 0.5292  Val: 0.5784\n",
      "Epoch 66/200  Train: 0.6454  Val: 0.5062\n",
      "Epoch 67/200  Train: 0.5994  Val: 0.4898\n",
      "Epoch 68/200  Train: 0.7063  Val: 0.7216\n",
      "Epoch 69/200  Train: 0.6352  Val: 0.6038\n",
      "Epoch 70/200  Train: 0.5624  Val: 0.4675\n",
      "Epoch 71/200  Train: 0.6228  Val: 0.5069\n",
      "Epoch 72/200  Train: 0.5226  Val: 0.6000\n",
      "Epoch 73/200  Train: 0.5670  Val: 0.9163\n",
      "Epoch 74/200  Train: 0.6952  Val: 0.5221\n",
      "Epoch 75/200  Train: 0.4708  Val: 0.4141\n",
      "Epoch 76/200  Train: 0.4671  Val: 0.4513\n",
      "Epoch 77/200  Train: 0.4684  Val: 0.4083\n",
      "Epoch 78/200  Train: 0.4665  Val: 0.4670\n",
      "Epoch 79/200  Train: 0.5526  Val: 0.3874\n",
      "Epoch 80/200  Train: 0.4669  Val: 0.4958\n",
      "Epoch 81/200  Train: 0.4466  Val: 0.5798\n",
      "Epoch 82/200  Train: 0.5651  Val: 0.4714\n",
      "Epoch 83/200  Train: 0.4151  Val: 0.6244\n",
      "Epoch 84/200  Train: 0.5052  Val: 0.5905\n",
      "Epoch 85/200  Train: 0.5139  Val: 0.3806\n",
      "Epoch 86/200  Train: 0.4039  Val: 0.4785\n",
      "Epoch 87/200  Train: 0.5075  Val: 0.5418\n",
      "Epoch 88/200  Train: 0.4255  Val: 0.3193\n",
      "Epoch 89/200  Train: 0.4583  Val: 0.3954\n",
      "Epoch 90/200  Train: 0.4613  Val: 0.6107\n",
      "Epoch 91/200  Train: 0.6346  Val: 0.5051\n",
      "Epoch 92/200  Train: 0.3897  Val: 0.5219\n",
      "Epoch 93/200  Train: 0.4585  Val: 0.4417\n",
      "Epoch 94/200  Train: 0.4255  Val: 0.3561\n",
      "Epoch 95/200  Train: 0.3306  Val: 0.3777\n",
      "Epoch 96/200  Train: 0.5052  Val: 0.5617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200  Train: 0.4274  Val: 0.3784\n",
      "Epoch 98/200  Train: 0.3644  Val: 0.3308\n",
      "Epoch 99/200  Train: 0.3839  Val: 0.5582\n",
      "Epoch 100/200  Train: 0.3707  Val: 0.3198\n",
      "Epoch 101/200  Train: 0.4409  Val: 0.2411\n",
      "Epoch 102/200  Train: 0.4173  Val: 0.3491\n",
      "Epoch 103/200  Train: 0.4339  Val: 0.3366\n",
      "Epoch 104/200  Train: 0.3076  Val: 0.4020\n",
      "Epoch 105/200  Train: 0.3327  Val: 0.3754\n",
      "Epoch 106/200  Train: 0.4423  Val: 0.3959\n",
      "Epoch 107/200  Train: 0.3217  Val: 0.4850\n",
      "Epoch 108/200  Train: 0.3018  Val: 0.2935\n",
      "Epoch 109/200  Train: 0.3302  Val: 0.3054\n",
      "Epoch 110/200  Train: 0.4124  Val: 0.4387\n",
      "Epoch 111/200  Train: 0.3543  Val: 0.3140\n",
      "Epoch 112/200  Train: 0.3001  Val: 0.3634\n",
      "Epoch 113/200  Train: 0.3254  Val: 0.4551\n",
      "Epoch 114/200  Train: 0.2562  Val: 0.3141\n",
      "Epoch 115/200  Train: 0.3506  Val: 0.4926\n",
      "Epoch 116/200  Train: 0.2753  Val: 0.1611\n",
      "Epoch 117/200  Train: 0.2692  Val: 0.3442\n",
      "Epoch 118/200  Train: 0.4722  Val: 1.0572\n",
      "Epoch 119/200  Train: 0.5809  Val: 0.3168\n",
      "Epoch 120/200  Train: 0.3742  Val: 0.6037\n",
      "Epoch 121/200  Train: 0.3661  Val: 0.2262\n",
      "Epoch 122/200  Train: 0.2377  Val: 0.2948\n",
      "Epoch 123/200  Train: 0.4238  Val: 0.2848\n",
      "Epoch 124/200  Train: 0.3666  Val: 0.3160\n",
      "Epoch 125/200  Train: 0.2174  Val: 0.1943\n",
      "Epoch 126/200  Train: 0.1983  Val: 0.1875\n",
      "Epoch 127/200  Train: 0.2423  Val: 0.2823\n",
      "Epoch 128/200  Train: 0.1970  Val: 0.2485\n",
      "Epoch 129/200  Train: 0.1486  Val: 0.2675\n",
      "Epoch 130/200  Train: 0.1590  Val: 0.1481\n",
      "Epoch 131/200  Train: 0.1834  Val: 0.1626\n",
      "Epoch 132/200  Train: 0.1916  Val: 0.2996\n",
      "Epoch 133/200  Train: 0.2079  Val: 0.2853\n",
      "Epoch 134/200  Train: 0.1348  Val: 0.2058\n",
      "Epoch 135/200  Train: 0.2197  Val: 0.4940\n",
      "Epoch 136/200  Train: 0.2177  Val: 0.3095\n",
      "Epoch 137/200  Train: 0.1617  Val: 0.3558\n",
      "Epoch 138/200  Train: 0.1548  Val: 0.2379\n",
      "Epoch 139/200  Train: 0.1865  Val: 0.3490\n",
      "Epoch 140/200  Train: 0.1370  Val: 0.3590\n",
      "Epoch 141/200  Train: 0.2019  Val: 0.4364\n",
      "Epoch 142/200  Train: 0.1306  Val: 0.3317\n",
      "Epoch 143/200  Train: 0.1409  Val: 0.2987\n",
      "Epoch 144/200  Train: 0.1081  Val: 0.3003\n",
      "Epoch 145/200  Train: 0.1077  Val: 0.6144\n",
      "Epoch 146/200  Train: 0.1462  Val: 0.4338\n",
      "Epoch 147/200  Train: 0.1067  Val: 0.2485\n",
      "Epoch 148/200  Train: 0.1503  Val: 0.4363\n",
      "Epoch 149/200  Train: 0.1508  Val: 0.2026\n",
      "Epoch 150/200  Train: 0.1121  Val: 0.4252\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:16,313]\u001b[0m Trial 32 finished with value: 0.14810508191585542 and parameters: {'batch_size': 32, 'lr': 5.5166265263361176e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 4, 'noise_steps': 528, 'beta_end': 0.01854609830108094, 'dropout': 0.027297424916089663}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 35.9188  Val: 2.5927\n",
      "Epoch 2/200  Train: 2.8732  Val: 1.0877\n",
      "Epoch 3/200  Train: 1.1350  Val: 0.9943\n",
      "Epoch 4/200  Train: 1.0832  Val: 1.1678\n",
      "Epoch 5/200  Train: 0.9733  Val: 1.2793\n",
      "Epoch 6/200  Train: 1.2930  Val: 1.1274\n",
      "Epoch 7/200  Train: 1.2362  Val: 0.9701\n",
      "Epoch 8/200  Train: 1.0562  Val: 0.8820\n",
      "Epoch 9/200  Train: 0.9972  Val: 0.9713\n",
      "Epoch 10/200  Train: 1.0560  Val: 1.5178\n",
      "Epoch 11/200  Train: 1.3130  Val: 0.7988\n",
      "Epoch 12/200  Train: 1.0953  Val: 0.9920\n",
      "Epoch 13/200  Train: 0.9610  Val: 0.7889\n",
      "Epoch 14/200  Train: 1.0261  Val: 1.1132\n",
      "Epoch 15/200  Train: 0.9404  Val: 0.9468\n",
      "Epoch 16/200  Train: 1.0165  Val: 0.9438\n",
      "Epoch 17/200  Train: 0.9852  Val: 0.9375\n",
      "Epoch 18/200  Train: 0.9505  Val: 1.5469\n",
      "Epoch 19/200  Train: 1.2384  Val: 0.8159\n",
      "Epoch 20/200  Train: 1.0546  Val: 0.9069\n",
      "Epoch 21/200  Train: 0.9658  Val: 0.7584\n",
      "Epoch 22/200  Train: 1.1816  Val: 0.7333\n",
      "Epoch 23/200  Train: 1.3840  Val: 0.9896\n",
      "Epoch 24/200  Train: 0.9464  Val: 0.7070\n",
      "Epoch 25/200  Train: 0.9434  Val: 0.6870\n",
      "Epoch 26/200  Train: 0.8121  Val: 0.9795\n",
      "Epoch 27/200  Train: 0.8290  Val: 1.2157\n",
      "Epoch 28/200  Train: 0.9464  Val: 0.8238\n",
      "Epoch 29/200  Train: 0.8258  Val: 0.9040\n",
      "Epoch 30/200  Train: 1.1470  Val: 0.8049\n",
      "Epoch 31/200  Train: 0.8573  Val: 0.8107\n",
      "Epoch 32/200  Train: 0.7455  Val: 0.8041\n",
      "Epoch 33/200  Train: 0.8759  Val: 0.7877\n",
      "Epoch 34/200  Train: 0.7778  Val: 0.8055\n",
      "Epoch 35/200  Train: 0.7915  Val: 0.7513\n",
      "Epoch 36/200  Train: 0.8370  Val: 0.8021\n",
      "Epoch 37/200  Train: 0.9195  Val: 0.6269\n",
      "Epoch 38/200  Train: 0.6485  Val: 0.6065\n",
      "Epoch 39/200  Train: 0.7430  Val: 0.7340\n",
      "Epoch 40/200  Train: 0.9875  Val: 1.0481\n",
      "Epoch 41/200  Train: 0.8075  Val: 0.7617\n",
      "Epoch 42/200  Train: 1.0993  Val: 0.6763\n",
      "Epoch 43/200  Train: 0.8445  Val: 0.6658\n",
      "Epoch 44/200  Train: 0.6333  Val: 0.8166\n",
      "Epoch 45/200  Train: 0.6239  Val: 0.6999\n",
      "Epoch 46/200  Train: 0.7312  Val: 0.7945\n",
      "Epoch 47/200  Train: 0.7745  Val: 0.7551\n",
      "Epoch 48/200  Train: 0.6816  Val: 0.5994\n",
      "Epoch 49/200  Train: 0.7365  Val: 0.9639\n",
      "Epoch 50/200  Train: 0.7932  Val: 0.6268\n",
      "Epoch 51/200  Train: 0.5652  Val: 0.5894\n",
      "Epoch 52/200  Train: 0.6521  Val: 0.5068\n",
      "Epoch 53/200  Train: 0.6507  Val: 0.5335\n",
      "Epoch 54/200  Train: 0.7364  Val: 0.6010\n",
      "Epoch 55/200  Train: 0.7062  Val: 0.5844\n",
      "Epoch 56/200  Train: 0.5992  Val: 0.5554\n",
      "Epoch 57/200  Train: 0.5314  Val: 0.4761\n",
      "Epoch 58/200  Train: 0.7422  Val: 0.5401\n",
      "Epoch 59/200  Train: 0.6068  Val: 1.1020\n",
      "Epoch 60/200  Train: 0.7680  Val: 0.7802\n",
      "Epoch 61/200  Train: 0.6346  Val: 1.0138\n",
      "Epoch 62/200  Train: 0.8611  Val: 0.5332\n",
      "Epoch 63/200  Train: 0.8167  Val: 0.8429\n",
      "Epoch 64/200  Train: 0.4965  Val: 0.5698\n",
      "Epoch 65/200  Train: 0.5411  Val: 1.0378\n",
      "Epoch 66/200  Train: 0.6815  Val: 0.6012\n",
      "Epoch 67/200  Train: 0.5817  Val: 0.4190\n",
      "Epoch 68/200  Train: 0.5097  Val: 0.5521\n",
      "Epoch 69/200  Train: 0.5300  Val: 0.4440\n",
      "Epoch 70/200  Train: 0.5439  Val: 0.4923\n",
      "Epoch 71/200  Train: 0.4845  Val: 0.4511\n",
      "Epoch 72/200  Train: 0.5129  Val: 0.4211\n",
      "Epoch 73/200  Train: 0.4495  Val: 0.6709\n",
      "Epoch 74/200  Train: 0.4685  Val: 0.6638\n",
      "Epoch 75/200  Train: 0.4633  Val: 0.2926\n",
      "Epoch 76/200  Train: 0.4761  Val: 1.1613\n",
      "Epoch 77/200  Train: 0.9155  Val: 0.5856\n",
      "Epoch 78/200  Train: 0.5269  Val: 0.5178\n",
      "Epoch 79/200  Train: 0.4728  Val: 0.3807\n",
      "Epoch 80/200  Train: 0.4355  Val: 0.3269\n",
      "Epoch 81/200  Train: 0.5363  Val: 0.4359\n",
      "Epoch 82/200  Train: 0.7188  Val: 0.6991\n",
      "Epoch 83/200  Train: 0.7036  Val: 0.5769\n",
      "Epoch 84/200  Train: 0.5762  Val: 0.6956\n",
      "Epoch 85/200  Train: 0.6271  Val: 0.3977\n",
      "Epoch 86/200  Train: 0.4792  Val: 0.3127\n",
      "Epoch 87/200  Train: 0.4369  Val: 0.4387\n",
      "Epoch 88/200  Train: 0.4138  Val: 0.3679\n",
      "Epoch 89/200  Train: 0.3803  Val: 0.3144\n",
      "Epoch 90/200  Train: 0.3872  Val: 0.3201\n",
      "Epoch 91/200  Train: 0.3709  Val: 0.5001\n",
      "Epoch 92/200  Train: 0.3486  Val: 0.4328\n",
      "Epoch 93/200  Train: 0.2958  Val: 0.3195\n",
      "Epoch 94/200  Train: 0.3938  Val: 0.3298\n",
      "Epoch 95/200  Train: 0.4021  Val: 0.3753\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:25,388]\u001b[0m Trial 33 finished with value: 0.2925976037979126 and parameters: {'batch_size': 32, 'lr': 7.210474267130972e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 6, 'noise_steps': 594, 'beta_end': 0.017042189258591325, 'dropout': 0.04161644697990041}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 58.1973  Val: 9.9165\n",
      "Epoch 2/200  Train: 5.4696  Val: 2.8420\n",
      "Epoch 3/200  Train: 1.3568  Val: 1.3175\n",
      "Epoch 4/200  Train: 1.1640  Val: 0.9109\n",
      "Epoch 5/200  Train: 1.0667  Val: 0.8513\n",
      "Epoch 6/200  Train: 1.1054  Val: 1.0196\n",
      "Epoch 7/200  Train: 0.9400  Val: 0.9384\n",
      "Epoch 8/200  Train: 0.9824  Val: 1.1168\n",
      "Epoch 9/200  Train: 1.1133  Val: 1.0278\n",
      "Epoch 10/200  Train: 0.9798  Val: 0.9729\n",
      "Epoch 11/200  Train: 0.9373  Val: 0.9141\n",
      "Epoch 12/200  Train: 0.9892  Val: 0.8799\n",
      "Epoch 13/200  Train: 1.0726  Val: 0.9436\n",
      "Epoch 14/200  Train: 1.0615  Val: 1.4050\n",
      "Epoch 15/200  Train: 0.9840  Val: 0.9462\n",
      "Epoch 16/200  Train: 1.0170  Val: 0.9772\n",
      "Epoch 17/200  Train: 0.9771  Val: 1.1968\n",
      "Epoch 18/200  Train: 1.0576  Val: 0.9485\n",
      "Epoch 19/200  Train: 0.8758  Val: 0.7538\n",
      "Epoch 20/200  Train: 0.8889  Val: 1.0137\n",
      "Epoch 21/200  Train: 0.8426  Val: 1.0000\n",
      "Epoch 22/200  Train: 0.8735  Val: 0.8073\n",
      "Epoch 23/200  Train: 0.8855  Val: 0.7323\n",
      "Epoch 24/200  Train: 0.9342  Val: 1.2773\n",
      "Epoch 25/200  Train: 0.9095  Val: 0.7614\n",
      "Epoch 26/200  Train: 0.8628  Val: 0.8768\n",
      "Epoch 27/200  Train: 0.9749  Val: 0.8789\n",
      "Epoch 28/200  Train: 1.1094  Val: 0.8956\n",
      "Epoch 29/200  Train: 1.1742  Val: 1.3669\n",
      "Epoch 30/200  Train: 0.9435  Val: 0.9436\n",
      "Epoch 31/200  Train: 0.8706  Val: 0.9742\n",
      "Epoch 32/200  Train: 0.9674  Val: 0.9545\n",
      "Epoch 33/200  Train: 0.8342  Val: 0.7296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200  Train: 0.8429  Val: 1.2230\n",
      "Epoch 35/200  Train: 0.9257  Val: 0.7889\n",
      "Epoch 36/200  Train: 0.9165  Val: 0.7501\n",
      "Epoch 37/200  Train: 0.8218  Val: 0.7984\n",
      "Epoch 38/200  Train: 0.9509  Val: 0.9143\n",
      "Epoch 39/200  Train: 0.8732  Val: 0.8646\n",
      "Epoch 40/200  Train: 0.8684  Val: 0.6962\n",
      "Epoch 41/200  Train: 0.9753  Val: 0.8664\n",
      "Epoch 42/200  Train: 0.9620  Val: 0.7427\n",
      "Epoch 43/200  Train: 0.7030  Val: 0.9464\n",
      "Epoch 44/200  Train: 0.8683  Val: 0.9550\n",
      "Epoch 45/200  Train: 0.8965  Val: 0.7118\n",
      "Epoch 46/200  Train: 0.7865  Val: 0.7699\n",
      "Epoch 47/200  Train: 0.8730  Val: 0.9604\n",
      "Epoch 48/200  Train: 0.8616  Val: 0.7885\n",
      "Epoch 49/200  Train: 0.9705  Val: 1.3155\n",
      "Epoch 50/200  Train: 1.1470  Val: 0.5422\n",
      "Epoch 51/200  Train: 0.6803  Val: 0.9125\n",
      "Epoch 52/200  Train: 0.7575  Val: 0.6782\n",
      "Epoch 53/200  Train: 0.7766  Val: 0.7782\n",
      "Epoch 54/200  Train: 0.6871  Val: 0.7757\n",
      "Epoch 55/200  Train: 0.8483  Val: 0.8565\n",
      "Epoch 56/200  Train: 0.7403  Val: 1.0842\n",
      "Epoch 57/200  Train: 1.0100  Val: 0.6371\n",
      "Epoch 58/200  Train: 0.7583  Val: 0.5978\n",
      "Epoch 59/200  Train: 0.7749  Val: 0.6540\n",
      "Epoch 60/200  Train: 0.6154  Val: 0.5393\n",
      "Epoch 61/200  Train: 0.7368  Val: 0.6796\n",
      "Epoch 62/200  Train: 0.7042  Val: 0.6332\n",
      "Epoch 63/200  Train: 0.8254  Val: 1.3347\n",
      "Epoch 64/200  Train: 0.7038  Val: 0.9150\n",
      "Epoch 65/200  Train: 0.7716  Val: 0.7730\n",
      "Epoch 66/200  Train: 0.6655  Val: 0.6926\n",
      "Epoch 67/200  Train: 0.6852  Val: 0.6026\n",
      "Epoch 68/200  Train: 0.6732  Val: 0.8038\n",
      "Epoch 69/200  Train: 0.8374  Val: 1.0535\n",
      "Epoch 70/200  Train: 0.7891  Val: 0.7671\n",
      "Epoch 71/200  Train: 0.6870  Val: 0.6378\n",
      "Epoch 72/200  Train: 0.6190  Val: 0.5551\n",
      "Epoch 73/200  Train: 0.9720  Val: 0.7286\n",
      "Epoch 74/200  Train: 0.7742  Val: 0.5554\n",
      "Epoch 75/200  Train: 0.8667  Val: 0.5900\n",
      "Epoch 76/200  Train: 0.6644  Val: 0.5314\n",
      "Epoch 77/200  Train: 0.6650  Val: 0.9190\n",
      "Epoch 78/200  Train: 0.6998  Val: 0.6045\n",
      "Epoch 79/200  Train: 0.7285  Val: 1.9243\n",
      "Epoch 80/200  Train: 0.7926  Val: 0.6745\n",
      "Epoch 81/200  Train: 0.6701  Val: 0.9132\n",
      "Epoch 82/200  Train: 0.8311  Val: 1.0420\n",
      "Epoch 83/200  Train: 0.6572  Val: 0.5559\n",
      "Epoch 84/200  Train: 0.5885  Val: 0.4963\n",
      "Epoch 85/200  Train: 0.6421  Val: 0.6167\n",
      "Epoch 86/200  Train: 0.5788  Val: 0.8790\n",
      "Epoch 87/200  Train: 0.7652  Val: 0.5123\n",
      "Epoch 88/200  Train: 0.6215  Val: 0.6595\n",
      "Epoch 89/200  Train: 0.6373  Val: 0.9676\n",
      "Epoch 90/200  Train: 0.7552  Val: 0.4716\n",
      "Epoch 91/200  Train: 0.7320  Val: 0.7820\n",
      "Epoch 92/200  Train: 0.6704  Val: 0.5117\n",
      "Epoch 93/200  Train: 0.4660  Val: 0.5270\n",
      "Epoch 94/200  Train: 0.5045  Val: 0.5279\n",
      "Epoch 95/200  Train: 0.7721  Val: 0.5073\n",
      "Epoch 96/200  Train: 0.5845  Val: 0.8493\n",
      "Epoch 97/200  Train: 0.6088  Val: 0.6320\n",
      "Epoch 98/200  Train: 0.6411  Val: 0.4707\n",
      "Epoch 99/200  Train: 0.5092  Val: 0.5516\n",
      "Epoch 100/200  Train: 0.5422  Val: 0.5672\n",
      "Epoch 101/200  Train: 0.6055  Val: 0.5981\n",
      "Epoch 102/200  Train: 0.5166  Val: 0.4067\n",
      "Epoch 103/200  Train: 0.6436  Val: 0.6307\n",
      "Epoch 104/200  Train: 0.9210  Val: 1.3376\n",
      "Epoch 105/200  Train: 1.2613  Val: 0.5405\n",
      "Epoch 106/200  Train: 0.7432  Val: 0.8520\n",
      "Epoch 107/200  Train: 0.5346  Val: 0.3683\n",
      "Epoch 108/200  Train: 0.4344  Val: 0.5712\n",
      "Epoch 109/200  Train: 0.7023  Val: 0.4567\n",
      "Epoch 110/200  Train: 0.5081  Val: 0.6427\n",
      "Epoch 111/200  Train: 0.5136  Val: 0.4012\n",
      "Epoch 112/200  Train: 0.4583  Val: 0.3234\n",
      "Epoch 113/200  Train: 0.4612  Val: 0.5078\n",
      "Epoch 114/200  Train: 0.4771  Val: 0.4726\n",
      "Epoch 115/200  Train: 0.4527  Val: 0.4370\n",
      "Epoch 116/200  Train: 0.5094  Val: 0.5310\n",
      "Epoch 117/200  Train: 0.4292  Val: 0.6645\n",
      "Epoch 118/200  Train: 0.4445  Val: 0.5105\n",
      "Epoch 119/200  Train: 0.6631  Val: 0.3690\n",
      "Epoch 120/200  Train: 0.4601  Val: 0.4800\n",
      "Epoch 121/200  Train: 0.4488  Val: 0.4488\n",
      "Epoch 122/200  Train: 0.5681  Val: 0.6038\n",
      "Epoch 123/200  Train: 0.4803  Val: 0.4636\n",
      "Epoch 124/200  Train: 0.4542  Val: 0.4261\n",
      "Epoch 125/200  Train: 0.7329  Val: 0.6955\n",
      "Epoch 126/200  Train: 0.9772  Val: 1.9469\n",
      "Epoch 127/200  Train: 0.9101  Val: 0.9714\n",
      "Epoch 128/200  Train: 0.9783  Val: 0.5628\n",
      "Epoch 129/200  Train: 0.5233  Val: 0.5103\n",
      "Epoch 130/200  Train: 0.5963  Val: 1.0638\n",
      "Epoch 131/200  Train: 0.5331  Val: 0.5821\n",
      "Epoch 132/200  Train: 0.5324  Val: 0.4358\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:33,397]\u001b[0m Trial 34 finished with value: 0.32339991331100465 and parameters: {'batch_size': 32, 'lr': 4.11129579758145e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 3, 'noise_steps': 640, 'beta_end': 0.011631578083534615, 'dropout': 0.02257893290069253}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 66.7863  Val: 28.6954\n",
      "Epoch 2/200  Train: 7.5234  Val: 0.9115\n",
      "Epoch 3/200  Train: 1.4138  Val: 1.4771\n",
      "Epoch 4/200  Train: 1.0271  Val: 1.2661\n",
      "Epoch 5/200  Train: 1.1497  Val: 1.0541\n",
      "Epoch 6/200  Train: 1.1719  Val: 0.9670\n",
      "Epoch 7/200  Train: 1.1506  Val: 1.0351\n",
      "Epoch 8/200  Train: 1.0043  Val: 1.5275\n",
      "Epoch 9/200  Train: 1.2904  Val: 1.0942\n",
      "Epoch 10/200  Train: 1.0300  Val: 0.7788\n",
      "Epoch 11/200  Train: 0.9670  Val: 1.0980\n",
      "Epoch 12/200  Train: 1.0522  Val: 0.9404\n",
      "Epoch 13/200  Train: 0.9179  Val: 0.9615\n",
      "Epoch 14/200  Train: 0.9081  Val: 0.7482\n",
      "Epoch 15/200  Train: 0.8882  Val: 0.9407\n",
      "Epoch 16/200  Train: 0.9132  Val: 1.0528\n",
      "Epoch 17/200  Train: 0.9548  Val: 0.8596\n",
      "Epoch 18/200  Train: 0.8741  Val: 1.0711\n",
      "Epoch 19/200  Train: 1.0054  Val: 0.8846\n",
      "Epoch 20/200  Train: 0.9746  Val: 0.9085\n",
      "Epoch 21/200  Train: 0.9030  Val: 1.1435\n",
      "Epoch 22/200  Train: 1.1027  Val: 1.5834\n",
      "Epoch 23/200  Train: 1.1946  Val: 0.9532\n",
      "Epoch 24/200  Train: 1.0109  Val: 0.7125\n",
      "Epoch 25/200  Train: 0.7887  Val: 0.7424\n",
      "Epoch 26/200  Train: 0.7640  Val: 0.9341\n",
      "Epoch 27/200  Train: 0.8583  Val: 0.7384\n",
      "Epoch 28/200  Train: 0.7941  Val: 0.7286\n",
      "Epoch 29/200  Train: 0.9281  Val: 1.0884\n",
      "Epoch 30/200  Train: 0.9063  Val: 0.7041\n",
      "Epoch 31/200  Train: 0.8037  Val: 0.7607\n",
      "Epoch 32/200  Train: 0.7212  Val: 0.7343\n",
      "Epoch 33/200  Train: 0.6928  Val: 0.6236\n",
      "Epoch 34/200  Train: 0.7215  Val: 0.5895\n",
      "Epoch 35/200  Train: 0.6451  Val: 0.8042\n",
      "Epoch 36/200  Train: 0.6510  Val: 0.5300\n",
      "Epoch 37/200  Train: 0.6543  Val: 0.7197\n",
      "Epoch 38/200  Train: 0.7560  Val: 0.5831\n",
      "Epoch 39/200  Train: 0.7615  Val: 0.7387\n",
      "Epoch 40/200  Train: 0.8060  Val: 0.5928\n",
      "Epoch 41/200  Train: 0.8346  Val: 0.5560\n",
      "Epoch 42/200  Train: 0.6591  Val: 0.6545\n",
      "Epoch 43/200  Train: 0.6739  Val: 0.7209\n",
      "Epoch 44/200  Train: 0.5550  Val: 0.6408\n",
      "Epoch 45/200  Train: 0.6161  Val: 0.5664\n",
      "Epoch 46/200  Train: 0.6262  Val: 0.9727\n",
      "Epoch 47/200  Train: 0.7103  Val: 0.8061\n",
      "Epoch 48/200  Train: 0.9946  Val: 0.4397\n",
      "Epoch 49/200  Train: 0.6363  Val: 0.5965\n",
      "Epoch 50/200  Train: 0.6366  Val: 0.4800\n",
      "Epoch 51/200  Train: 0.6285  Val: 0.5349\n",
      "Epoch 52/200  Train: 0.5197  Val: 0.7642\n",
      "Epoch 53/200  Train: 0.5874  Val: 0.5289\n",
      "Epoch 54/200  Train: 0.5406  Val: 0.4470\n",
      "Epoch 55/200  Train: 0.5451  Val: 0.4402\n",
      "Epoch 56/200  Train: 0.4538  Val: 0.5993\n",
      "Epoch 57/200  Train: 0.4817  Val: 0.6086\n",
      "Epoch 58/200  Train: 0.5304  Val: 0.7536\n",
      "Epoch 59/200  Train: 0.7850  Val: 0.9689\n",
      "Epoch 60/200  Train: 1.0757  Val: 0.5603\n",
      "Epoch 61/200  Train: 0.5580  Val: 0.3946\n",
      "Epoch 62/200  Train: 0.5052  Val: 0.5769\n",
      "Epoch 63/200  Train: 0.3721  Val: 0.5969\n",
      "Epoch 64/200  Train: 0.4447  Val: 0.5762\n",
      "Epoch 65/200  Train: 0.4426  Val: 0.4239\n",
      "Epoch 66/200  Train: 0.3887  Val: 0.4023\n",
      "Epoch 67/200  Train: 0.4276  Val: 0.5264\n",
      "Epoch 68/200  Train: 0.4942  Val: 0.3656\n",
      "Epoch 69/200  Train: 0.4687  Val: 0.5244\n",
      "Epoch 70/200  Train: 0.5798  Val: 0.5396\n",
      "Epoch 71/200  Train: 0.3983  Val: 0.3923\n",
      "Epoch 72/200  Train: 0.3350  Val: 0.4609\n",
      "Epoch 73/200  Train: 0.3995  Val: 0.4236\n",
      "Epoch 74/200  Train: 0.5138  Val: 0.3418\n",
      "Epoch 75/200  Train: 0.4559  Val: 0.4398\n",
      "Epoch 76/200  Train: 0.3922  Val: 0.3837\n",
      "Epoch 77/200  Train: 0.3393  Val: 0.3658\n",
      "Epoch 78/200  Train: 0.4244  Val: 0.2517\n",
      "Epoch 79/200  Train: 0.4024  Val: 0.4350\n",
      "Epoch 80/200  Train: 0.4584  Val: 0.4114\n",
      "Epoch 81/200  Train: 0.3406  Val: 0.3774\n",
      "Epoch 82/200  Train: 0.3247  Val: 0.3580\n",
      "Epoch 83/200  Train: 0.3867  Val: 0.3968\n",
      "Epoch 84/200  Train: 0.3902  Val: 0.6948\n",
      "Epoch 85/200  Train: 0.4222  Val: 0.3902\n",
      "Epoch 86/200  Train: 0.4266  Val: 0.2876\n",
      "Epoch 87/200  Train: 0.2983  Val: 0.3121\n",
      "Epoch 88/200  Train: 0.3138  Val: 0.2302\n",
      "Epoch 89/200  Train: 0.3351  Val: 0.4024\n",
      "Epoch 90/200  Train: 0.2469  Val: 0.4009\n",
      "Epoch 91/200  Train: 0.3963  Val: 0.3117\n",
      "Epoch 92/200  Train: 0.2610  Val: 0.2960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200  Train: 0.3116  Val: 0.3293\n",
      "Epoch 94/200  Train: 0.3401  Val: 0.2961\n",
      "Epoch 95/200  Train: 0.3277  Val: 0.3133\n",
      "Epoch 96/200  Train: 0.2983  Val: 0.2816\n",
      "Epoch 97/200  Train: 0.2820  Val: 0.3262\n",
      "Epoch 98/200  Train: 0.2267  Val: 0.3861\n",
      "Epoch 99/200  Train: 0.2689  Val: 0.2354\n",
      "Epoch 100/200  Train: 0.2566  Val: 0.2703\n",
      "Epoch 101/200  Train: 0.1975  Val: 0.2433\n",
      "Epoch 102/200  Train: 0.3502  Val: 0.2304\n",
      "Epoch 103/200  Train: 0.2391  Val: 0.1779\n",
      "Epoch 104/200  Train: 0.2120  Val: 0.2286\n",
      "Epoch 105/200  Train: 0.1833  Val: 0.1980\n",
      "Epoch 106/200  Train: 0.3114  Val: 0.3864\n",
      "Epoch 107/200  Train: 0.2564  Val: 0.2151\n",
      "Epoch 108/200  Train: 0.2806  Val: 0.3444\n",
      "Epoch 109/200  Train: 0.2295  Val: 0.2516\n",
      "Epoch 110/200  Train: 0.2355  Val: 0.3536\n",
      "Epoch 111/200  Train: 0.3183  Val: 0.1879\n",
      "Epoch 112/200  Train: 0.1857  Val: 0.2603\n",
      "Epoch 113/200  Train: 0.1814  Val: 0.2252\n",
      "Epoch 114/200  Train: 0.2027  Val: 0.3504\n",
      "Epoch 115/200  Train: 0.2129  Val: 0.3184\n",
      "Epoch 116/200  Train: 0.1683  Val: 0.2235\n",
      "Epoch 117/200  Train: 0.1729  Val: 0.1733\n",
      "Epoch 118/200  Train: 0.1732  Val: 0.1578\n",
      "Epoch 119/200  Train: 0.2252  Val: 0.2911\n",
      "Epoch 120/200  Train: 0.1819  Val: 0.2584\n",
      "Epoch 121/200  Train: 0.1411  Val: 0.3022\n",
      "Epoch 122/200  Train: 0.1975  Val: 0.1542\n",
      "Epoch 123/200  Train: 0.1739  Val: 0.2106\n",
      "Epoch 124/200  Train: 0.1401  Val: 0.2586\n",
      "Epoch 125/200  Train: 0.1309  Val: 0.2104\n",
      "Epoch 126/200  Train: 0.1726  Val: 0.2218\n",
      "Epoch 127/200  Train: 0.2490  Val: 0.2101\n",
      "Epoch 128/200  Train: 0.2124  Val: 0.2719\n",
      "Epoch 129/200  Train: 0.2053  Val: 0.3139\n",
      "Epoch 130/200  Train: 0.1664  Val: 0.1473\n",
      "Epoch 131/200  Train: 0.1197  Val: 0.1028\n",
      "Epoch 132/200  Train: 0.1228  Val: 0.3526\n",
      "Epoch 133/200  Train: 0.1583  Val: 0.4788\n",
      "Epoch 134/200  Train: 0.1561  Val: 0.3284\n",
      "Epoch 135/200  Train: 0.1186  Val: 0.2159\n",
      "Epoch 136/200  Train: 0.1627  Val: 0.5306\n",
      "Epoch 137/200  Train: 0.1946  Val: 0.2476\n",
      "Epoch 138/200  Train: 0.1269  Val: 0.3996\n",
      "Epoch 139/200  Train: 0.2017  Val: 0.3345\n",
      "Epoch 140/200  Train: 0.2321  Val: 0.2866\n",
      "Epoch 141/200  Train: 0.1246  Val: 0.1473\n",
      "Epoch 142/200  Train: 0.0865  Val: 0.2085\n",
      "Epoch 143/200  Train: 0.1024  Val: 0.4134\n",
      "Epoch 144/200  Train: 0.1398  Val: 0.2878\n",
      "Epoch 145/200  Train: 0.1017  Val: 0.2430\n",
      "Epoch 146/200  Train: 0.0877  Val: 0.2608\n",
      "Epoch 147/200  Train: 0.1036  Val: 0.1458\n",
      "Epoch 148/200  Train: 0.1478  Val: 0.1736\n",
      "Epoch 149/200  Train: 0.1192  Val: 0.3158\n",
      "Epoch 150/200  Train: 0.1855  Val: 0.4531\n",
      "Epoch 151/200  Train: 0.1651  Val: 0.2459\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:45,903]\u001b[0m Trial 35 finished with value: 0.1028049111366272 and parameters: {'batch_size': 32, 'lr': 8.961279833099312e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 5, 'noise_steps': 581, 'beta_end': 0.016245937821554236, 'dropout': 0.01846937054241441}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 156.1422  Val: 4.6518\n",
      "Epoch 2/200  Train: 21.3842  Val: 20.2733\n",
      "Epoch 3/200  Train: 7.6513  Val: 6.5548\n",
      "Epoch 4/200  Train: 4.0045  Val: 1.6226\n",
      "Epoch 5/200  Train: 2.2458  Val: 1.0390\n",
      "Epoch 6/200  Train: 1.3943  Val: 1.3672\n",
      "Epoch 7/200  Train: 1.1364  Val: 1.0440\n",
      "Epoch 8/200  Train: 0.8930  Val: 1.1947\n",
      "Epoch 9/200  Train: 0.9188  Val: 1.0234\n",
      "Epoch 10/200  Train: 1.1422  Val: 1.0877\n",
      "Epoch 11/200  Train: 0.9572  Val: 0.9154\n",
      "Epoch 12/200  Train: 1.0816  Val: 0.9957\n",
      "Epoch 13/200  Train: 0.9419  Val: 1.0914\n",
      "Epoch 14/200  Train: 1.0767  Val: 0.9993\n",
      "Epoch 15/200  Train: 0.9545  Val: 0.9452\n",
      "Epoch 16/200  Train: 0.9265  Val: 0.9668\n",
      "Epoch 17/200  Train: 0.9403  Val: 0.9219\n",
      "Epoch 18/200  Train: 1.0016  Val: 0.8029\n",
      "Epoch 19/200  Train: 0.9351  Val: 1.0411\n",
      "Epoch 20/200  Train: 0.9867  Val: 1.0412\n",
      "Epoch 21/200  Train: 0.8572  Val: 0.8723\n",
      "Epoch 22/200  Train: 1.0545  Val: 0.8753\n",
      "Epoch 23/200  Train: 0.8936  Val: 0.9047\n",
      "Epoch 24/200  Train: 0.9956  Val: 0.7677\n",
      "Epoch 25/200  Train: 0.9453  Val: 0.8050\n",
      "Epoch 26/200  Train: 0.8309  Val: 0.8401\n",
      "Epoch 27/200  Train: 0.9432  Val: 1.0575\n",
      "Epoch 28/200  Train: 1.1280  Val: 0.7380\n",
      "Epoch 29/200  Train: 0.8743  Val: 0.9854\n",
      "Epoch 30/200  Train: 0.9857  Val: 0.8166\n",
      "Epoch 31/200  Train: 1.0211  Val: 0.9042\n",
      "Epoch 32/200  Train: 0.9526  Val: 1.0971\n",
      "Epoch 33/200  Train: 0.8856  Val: 1.1868\n",
      "Epoch 34/200  Train: 1.0257  Val: 1.0894\n",
      "Epoch 35/200  Train: 0.9338  Val: 0.8172\n",
      "Epoch 36/200  Train: 0.8438  Val: 0.6661\n",
      "Epoch 37/200  Train: 0.9275  Val: 0.7813\n",
      "Epoch 38/200  Train: 0.8267  Val: 0.9250\n",
      "Epoch 39/200  Train: 0.8661  Val: 0.8527\n",
      "Epoch 40/200  Train: 0.9633  Val: 0.8765\n",
      "Epoch 41/200  Train: 0.8904  Val: 0.9080\n",
      "Epoch 42/200  Train: 0.8953  Val: 0.7706\n",
      "Epoch 43/200  Train: 0.8268  Val: 0.7042\n",
      "Epoch 44/200  Train: 0.8389  Val: 0.7501\n",
      "Epoch 45/200  Train: 0.8194  Val: 0.9223\n",
      "Epoch 46/200  Train: 0.8033  Val: 0.8854\n",
      "Epoch 47/200  Train: 0.8228  Val: 0.9289\n",
      "Epoch 48/200  Train: 0.7239  Val: 0.8341\n",
      "Epoch 49/200  Train: 0.7939  Val: 0.8149\n",
      "Epoch 50/200  Train: 0.7856  Val: 0.9278\n",
      "Epoch 51/200  Train: 0.8757  Val: 0.8297\n",
      "Epoch 52/200  Train: 0.7713  Val: 1.0389\n",
      "Epoch 53/200  Train: 0.7718  Val: 0.7538\n",
      "Epoch 54/200  Train: 0.7546  Val: 0.9730\n",
      "Epoch 55/200  Train: 0.7332  Val: 0.8047\n",
      "Epoch 56/200  Train: 0.8740  Val: 0.7114\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:49,682]\u001b[0m Trial 36 finished with value: 0.6661027193069458 and parameters: {'batch_size': 64, 'lr': 8.800774541437497e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 8, 'noise_steps': 607, 'beta_end': 0.016218877567991865, 'dropout': 0.019930022191376864}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 27.0857  Val: 11.8543\n",
      "Epoch 2/200  Train: 7.6220  Val: 9.6723\n",
      "Epoch 3/200  Train: 3.8749  Val: 5.0158\n",
      "Epoch 4/200  Train: 3.8603  Val: 1.2484\n",
      "Epoch 5/200  Train: 2.3832  Val: 1.5893\n",
      "Epoch 6/200  Train: 1.6166  Val: 2.2469\n",
      "Epoch 7/200  Train: 1.5312  Val: 1.3482\n",
      "Epoch 8/200  Train: 1.3553  Val: 1.1336\n",
      "Epoch 9/200  Train: 1.1961  Val: 1.0405\n",
      "Epoch 10/200  Train: 1.0375  Val: 0.9746\n",
      "Epoch 11/200  Train: 1.0306  Val: 1.2500\n",
      "Epoch 12/200  Train: 0.9821  Val: 0.9521\n",
      "Epoch 13/200  Train: 1.0509  Val: 0.9997\n",
      "Epoch 14/200  Train: 0.9909  Val: 0.9556\n",
      "Epoch 15/200  Train: 0.9412  Val: 0.7891\n",
      "Epoch 16/200  Train: 0.8910  Val: 0.8296\n",
      "Epoch 17/200  Train: 1.0198  Val: 1.0573\n",
      "Epoch 18/200  Train: 0.9540  Val: 1.0310\n",
      "Epoch 19/200  Train: 0.9133  Val: 0.7585\n",
      "Epoch 20/200  Train: 0.9503  Val: 0.9382\n",
      "Epoch 21/200  Train: 0.9307  Val: 0.9952\n",
      "Epoch 22/200  Train: 0.9612  Val: 0.9269\n",
      "Epoch 23/200  Train: 0.8957  Val: 0.9962\n",
      "Epoch 24/200  Train: 0.9670  Val: 0.8778\n",
      "Epoch 25/200  Train: 1.0465  Val: 0.9404\n",
      "Epoch 26/200  Train: 0.9176  Val: 0.9933\n",
      "Epoch 27/200  Train: 0.9870  Val: 0.8445\n",
      "Epoch 28/200  Train: 0.9241  Val: 0.7732\n",
      "Epoch 29/200  Train: 1.0318  Val: 0.9031\n",
      "Epoch 30/200  Train: 0.9195  Val: 0.9948\n",
      "Epoch 31/200  Train: 0.9032  Val: 0.9248\n",
      "Epoch 32/200  Train: 0.9298  Val: 0.8332\n",
      "Epoch 33/200  Train: 0.8848  Val: 0.8777\n",
      "Epoch 34/200  Train: 0.7815  Val: 0.9653\n",
      "Epoch 35/200  Train: 0.9492  Val: 0.8536\n",
      "Epoch 36/200  Train: 0.8466  Val: 0.8980\n",
      "Epoch 37/200  Train: 0.8926  Val: 0.9770\n",
      "Epoch 38/200  Train: 0.7785  Val: 0.9312\n",
      "Epoch 39/200  Train: 0.8729  Val: 0.7506\n",
      "Epoch 40/200  Train: 0.9311  Val: 0.9583\n",
      "Epoch 41/200  Train: 0.8205  Val: 1.0505\n",
      "Epoch 42/200  Train: 0.8729  Val: 0.9118\n",
      "Epoch 43/200  Train: 0.9955  Val: 1.0086\n",
      "Epoch 44/200  Train: 0.8721  Val: 0.9846\n",
      "Epoch 45/200  Train: 0.9062  Val: 0.9375\n",
      "Epoch 46/200  Train: 0.8772  Val: 0.9012\n",
      "Epoch 47/200  Train: 0.8532  Val: 0.9032\n",
      "Epoch 48/200  Train: 0.8513  Val: 0.7914\n",
      "Epoch 49/200  Train: 0.9372  Val: 0.8575\n",
      "Epoch 50/200  Train: 0.8598  Val: 0.8636\n",
      "Epoch 51/200  Train: 0.9671  Val: 0.9990\n",
      "Epoch 52/200  Train: 0.8934  Val: 0.8561\n",
      "Epoch 53/200  Train: 0.8330  Val: 0.8709\n",
      "Epoch 54/200  Train: 0.8877  Val: 0.7757\n",
      "Epoch 55/200  Train: 0.7961  Val: 0.9658\n",
      "Epoch 56/200  Train: 0.9074  Val: 0.7777\n",
      "Epoch 57/200  Train: 0.8593  Val: 0.9020\n",
      "Epoch 58/200  Train: 0.8292  Val: 0.9167\n",
      "Epoch 59/200  Train: 0.8348  Val: 0.8938\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:38:51,073]\u001b[0m Trial 37 finished with value: 0.7506063342094421 and parameters: {'batch_size': 128, 'lr': 8.530107936786062e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 5, 'noise_steps': 730, 'beta_end': 0.015243158756433426, 'dropout': 0.018020038282171816}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200  Train: 71.8888  Val: 22.2104\n",
      "Epoch 2/200  Train: 8.4651  Val: 2.5476\n",
      "Epoch 3/200  Train: 2.0360  Val: 1.4755\n",
      "Epoch 4/200  Train: 1.1090  Val: 1.1894\n",
      "Epoch 5/200  Train: 1.0950  Val: 0.9629\n",
      "Epoch 6/200  Train: 1.2243  Val: 1.3079\n",
      "Epoch 7/200  Train: 1.0131  Val: 0.8818\n",
      "Epoch 8/200  Train: 0.9445  Val: 1.1715\n",
      "Epoch 9/200  Train: 1.0351  Val: 0.8777\n",
      "Epoch 10/200  Train: 0.9347  Val: 1.2367\n",
      "Epoch 11/200  Train: 1.0964  Val: 1.2294\n",
      "Epoch 12/200  Train: 0.9960  Val: 0.9685\n",
      "Epoch 13/200  Train: 0.8891  Val: 1.2514\n",
      "Epoch 14/200  Train: 1.3386  Val: 1.5225\n",
      "Epoch 15/200  Train: 1.3245  Val: 0.8395\n",
      "Epoch 16/200  Train: 1.1819  Val: 1.2609\n",
      "Epoch 17/200  Train: 1.0574  Val: 1.1018\n",
      "Epoch 18/200  Train: 0.9556  Val: 0.6979\n",
      "Epoch 19/200  Train: 1.0250  Val: 0.7948\n",
      "Epoch 20/200  Train: 0.9396  Val: 0.8598\n",
      "Epoch 21/200  Train: 0.9358  Val: 1.4356\n",
      "Epoch 22/200  Train: 1.0070  Val: 1.0572\n",
      "Epoch 23/200  Train: 1.0058  Val: 1.2443\n",
      "Epoch 24/200  Train: 0.9752  Val: 0.8533\n",
      "Epoch 25/200  Train: 1.0966  Val: 0.7148\n",
      "Epoch 26/200  Train: 0.8738  Val: 0.8799\n",
      "Epoch 27/200  Train: 0.8612  Val: 0.9707\n",
      "Epoch 28/200  Train: 1.0255  Val: 0.8165\n",
      "Epoch 29/200  Train: 0.9032  Val: 0.8081\n",
      "Epoch 30/200  Train: 1.3188  Val: 0.7412\n",
      "Epoch 31/200  Train: 0.8613  Val: 1.0129\n",
      "Epoch 32/200  Train: 0.8313  Val: 1.4857\n",
      "Epoch 33/200  Train: 1.0583  Val: 0.9474\n",
      "Epoch 34/200  Train: 1.0766  Val: 0.9070\n",
      "Epoch 35/200  Train: 0.7123  Val: 0.6561\n",
      "Epoch 36/200  Train: 0.7241  Val: 0.8644\n",
      "Epoch 37/200  Train: 0.9116  Val: 0.6162\n",
      "Epoch 38/200  Train: 0.9536  Val: 1.0694\n",
      "Epoch 39/200  Train: 1.0002  Val: 0.9436\n",
      "Epoch 40/200  Train: 1.0044  Val: 0.9252\n",
      "Epoch 41/200  Train: 0.8626  Val: 0.9854\n",
      "Epoch 42/200  Train: 0.7760  Val: 0.7571\n",
      "Epoch 43/200  Train: 0.7040  Val: 0.8491\n",
      "Epoch 44/200  Train: 0.6452  Val: 0.7165\n",
      "Epoch 45/200  Train: 0.7089  Val: 1.2683\n",
      "Epoch 46/200  Train: 0.6162  Val: 0.5124\n",
      "Epoch 47/200  Train: 0.7099  Val: 0.7109\n",
      "Epoch 48/200  Train: 0.6440  Val: 0.5587\n",
      "Epoch 49/200  Train: 0.7226  Val: 0.6468\n",
      "Epoch 50/200  Train: 0.6964  Val: 0.6978\n",
      "Epoch 51/200  Train: 0.6481  Val: 0.5906\n",
      "Epoch 52/200  Train: 0.7730  Val: 0.5840\n",
      "Epoch 53/200  Train: 1.0769  Val: 0.7363\n",
      "Epoch 54/200  Train: 0.8650  Val: 0.5000\n",
      "Epoch 55/200  Train: 0.6111  Val: 0.5105\n",
      "Epoch 56/200  Train: 0.9094  Val: 0.6800\n",
      "Epoch 57/200  Train: 1.2820  Val: 0.7625\n",
      "Epoch 58/200  Train: 0.8865  Val: 0.5633\n",
      "Epoch 59/200  Train: 0.7059  Val: 0.4673\n",
      "Epoch 60/200  Train: 0.6499  Val: 0.5188\n",
      "Epoch 61/200  Train: 0.6557  Val: 1.5658\n",
      "Epoch 62/200  Train: 0.9003  Val: 0.7613\n",
      "Epoch 63/200  Train: 0.8036  Val: 0.5743\n",
      "Epoch 64/200  Train: 0.7552  Val: 0.5781\n",
      "Epoch 65/200  Train: 0.7125  Val: 0.5126\n",
      "Epoch 66/200  Train: 0.5952  Val: 0.5270\n",
      "Epoch 67/200  Train: 0.7136  Val: 0.7161\n",
      "Epoch 68/200  Train: 0.6339  Val: 0.4860\n",
      "Epoch 69/200  Train: 0.5894  Val: 0.4942\n",
      "Epoch 70/200  Train: 0.5715  Val: 0.3989\n",
      "Epoch 71/200  Train: 0.4818  Val: 0.5013\n",
      "Epoch 72/200  Train: 0.6683  Val: 0.4785\n",
      "Epoch 73/200  Train: 0.5667  Val: 0.4701\n",
      "Epoch 74/200  Train: 0.5186  Val: 0.5108\n",
      "Epoch 75/200  Train: 0.5129  Val: 0.6577\n",
      "Epoch 76/200  Train: 0.6813  Val: 0.4242\n",
      "Epoch 77/200  Train: 0.5197  Val: 0.5936\n",
      "Epoch 78/200  Train: 0.4882  Val: 0.4892\n",
      "Epoch 79/200  Train: 0.4551  Val: 0.3972\n",
      "Epoch 80/200  Train: 0.5708  Val: 0.4342\n",
      "Epoch 81/200  Train: 0.4907  Val: 0.6743\n",
      "Epoch 82/200  Train: 0.5230  Val: 0.9554\n",
      "Epoch 83/200  Train: 1.0942  Val: 0.6493\n",
      "Epoch 84/200  Train: 1.0000  Val: 0.5939\n",
      "Epoch 85/200  Train: 0.5773  Val: 0.6033\n",
      "Epoch 86/200  Train: 0.4030  Val: 0.5587\n",
      "Epoch 87/200  Train: 0.4160  Val: 0.3760\n",
      "Epoch 88/200  Train: 0.3578  Val: 0.4177\n",
      "Epoch 89/200  Train: 0.4330  Val: 0.3048\n",
      "Epoch 90/200  Train: 0.3738  Val: 0.4260\n",
      "Epoch 91/200  Train: 0.3686  Val: 0.4469\n",
      "Epoch 92/200  Train: 0.3553  Val: 0.7274\n",
      "Epoch 93/200  Train: 0.5423  Val: 0.4087\n",
      "Epoch 94/200  Train: 0.3261  Val: 0.6743\n",
      "Epoch 95/200  Train: 0.3554  Val: 0.3955\n",
      "Epoch 96/200  Train: 0.4414  Val: 0.9598\n",
      "Epoch 97/200  Train: 0.5610  Val: 0.3155\n",
      "Epoch 98/200  Train: 0.3829  Val: 0.2573\n",
      "Epoch 99/200  Train: 0.3039  Val: 0.4586\n",
      "Epoch 100/200  Train: 0.3808  Val: 0.4082\n",
      "Epoch 101/200  Train: 0.5503  Val: 0.5710\n",
      "Epoch 102/200  Train: 0.4250  Val: 0.5623\n",
      "Epoch 103/200  Train: 0.3992  Val: 0.5531\n",
      "Epoch 104/200  Train: 0.4181  Val: 0.2578\n",
      "Epoch 105/200  Train: 0.3510  Val: 0.3432\n",
      "Epoch 106/200  Train: 0.3316  Val: 0.2619\n",
      "Epoch 107/200  Train: 0.3546  Val: 0.3380\n",
      "Epoch 108/200  Train: 0.4271  Val: 0.3638\n",
      "Epoch 109/200  Train: 0.4020  Val: 0.2588\n",
      "Epoch 110/200  Train: 0.3149  Val: 0.3485\n",
      "Epoch 111/200  Train: 0.2810  Val: 0.4013\n",
      "Epoch 112/200  Train: 0.2807  Val: 0.2395\n",
      "Epoch 113/200  Train: 0.2814  Val: 0.2495\n",
      "Epoch 114/200  Train: 0.2284  Val: 0.2672\n",
      "Epoch 115/200  Train: 0.3836  Val: 0.4603\n",
      "Epoch 116/200  Train: 0.2967  Val: 0.3945\n",
      "Epoch 117/200  Train: 0.2223  Val: 0.2622\n",
      "Epoch 118/200  Train: 0.2447  Val: 0.3036\n",
      "Epoch 119/200  Train: 0.2846  Val: 0.3652\n",
      "Epoch 120/200  Train: 0.2281  Val: 0.1855\n",
      "Epoch 121/200  Train: 0.2281  Val: 0.3230\n",
      "Epoch 122/200  Train: 0.3403  Val: 0.3288\n",
      "Epoch 123/200  Train: 0.2676  Val: 0.2078\n",
      "Epoch 124/200  Train: 0.2946  Val: 0.1895\n",
      "Epoch 125/200  Train: 0.2938  Val: 0.3737\n",
      "Epoch 126/200  Train: 0.2247  Val: 0.2009\n",
      "Epoch 127/200  Train: 0.2929  Val: 0.2192\n",
      "Epoch 128/200  Train: 0.1792  Val: 0.2882\n",
      "Epoch 129/200  Train: 0.2046  Val: 0.1844\n",
      "Epoch 130/200  Train: 0.2180  Val: 0.1252\n",
      "Epoch 131/200  Train: 0.1729  Val: 0.2493\n",
      "Epoch 132/200  Train: 0.3643  Val: 0.2014\n",
      "Epoch 133/200  Train: 0.1771  Val: 0.2308\n",
      "Epoch 134/200  Train: 0.1902  Val: 0.2290\n",
      "Epoch 135/200  Train: 0.2971  Val: 0.4063\n",
      "Epoch 136/200  Train: 0.2437  Val: 0.2454\n",
      "Epoch 137/200  Train: 0.2294  Val: 0.3048\n",
      "Epoch 138/200  Train: 0.2430  Val: 0.5140\n",
      "Epoch 139/200  Train: 0.2471  Val: 0.2563\n",
      "Epoch 140/200  Train: 0.2886  Val: 0.4501\n",
      "Epoch 141/200  Train: 0.3872  Val: 0.3637\n",
      "Epoch 142/200  Train: 0.2090  Val: 0.2027\n",
      "Epoch 143/200  Train: 0.1368  Val: 0.1758\n",
      "Epoch 144/200  Train: 0.1568  Val: 0.1950\n",
      "Epoch 145/200  Train: 0.1838  Val: 0.2984\n",
      "Epoch 146/200  Train: 0.2107  Val: 0.2967\n",
      "Epoch 147/200  Train: 0.1794  Val: 0.1691\n",
      "Epoch 148/200  Train: 0.1666  Val: 0.3076\n",
      "Epoch 149/200  Train: 0.2611  Val: 0.3380\n",
      "Epoch 150/200  Train: 0.2123  Val: 0.2181\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:07,381]\u001b[0m Trial 38 finished with value: 0.12522472888231279 and parameters: {'batch_size': 32, 'lr': 7.447410006390541e-05, 'hidden_dim': 1024, 'time_embed_dim': 256, 'layers': 7, 'noise_steps': 653, 'beta_end': 0.017819931867524206, 'dropout': 0.008586274071952706}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 59.6614  Val: 51.1687\n",
      "Epoch 2/200  Train: 31.9641  Val: 1.3771\n",
      "Epoch 3/200  Train: 8.7799  Val: 18.1693\n",
      "Epoch 4/200  Train: 8.3906  Val: 1.8607\n",
      "Epoch 5/200  Train: 4.9967  Val: 5.0716\n",
      "Epoch 6/200  Train: 2.5206  Val: 1.9042\n",
      "Epoch 7/200  Train: 2.7756  Val: 1.6843\n",
      "Epoch 8/200  Train: 1.2669  Val: 2.2560\n",
      "Epoch 9/200  Train: 1.7001  Val: 0.9165\n",
      "Epoch 10/200  Train: 1.2224  Val: 1.3511\n",
      "Epoch 11/200  Train: 1.1345  Val: 1.1650\n",
      "Epoch 12/200  Train: 1.1275  Val: 0.9078\n",
      "Epoch 13/200  Train: 1.0396  Val: 1.0544\n",
      "Epoch 14/200  Train: 1.0173  Val: 1.2187\n",
      "Epoch 15/200  Train: 1.0611  Val: 1.0649\n",
      "Epoch 16/200  Train: 1.0130  Val: 0.8371\n",
      "Epoch 17/200  Train: 0.9329  Val: 1.1408\n",
      "Epoch 18/200  Train: 0.9833  Val: 1.0435\n",
      "Epoch 19/200  Train: 1.0469  Val: 1.0835\n",
      "Epoch 20/200  Train: 1.0413  Val: 1.0692\n",
      "Epoch 21/200  Train: 0.9598  Val: 0.8789\n",
      "Epoch 22/200  Train: 1.0285  Val: 0.9769\n",
      "Epoch 23/200  Train: 1.0438  Val: 1.0275\n",
      "Epoch 24/200  Train: 0.9208  Val: 0.9966\n",
      "Epoch 25/200  Train: 0.9339  Val: 0.9683\n",
      "Epoch 26/200  Train: 1.0303  Val: 1.0358\n",
      "Epoch 27/200  Train: 0.9333  Val: 1.0567\n",
      "Epoch 28/200  Train: 1.0609  Val: 0.9609\n",
      "Epoch 29/200  Train: 0.8552  Val: 0.9955\n",
      "Epoch 30/200  Train: 0.9024  Val: 0.9215\n",
      "Epoch 31/200  Train: 0.9836  Val: 1.0929\n",
      "Epoch 32/200  Train: 1.0313  Val: 0.9687\n",
      "Epoch 33/200  Train: 1.0583  Val: 0.9832\n",
      "Epoch 34/200  Train: 0.9745  Val: 1.1232\n",
      "Epoch 35/200  Train: 0.8670  Val: 0.9671\n",
      "Epoch 36/200  Train: 0.9299  Val: 0.9943\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:08,786]\u001b[0m Trial 39 finished with value: 0.8370859384536743 and parameters: {'batch_size': 128, 'lr': 2.690343417011455e-05, 'hidden_dim': 1024, 'time_embed_dim': 128, 'layers': 8, 'noise_steps': 588, 'beta_end': 0.015783474194891962, 'dropout': 0.01477699004594579}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200  Train: 4.6894  Val: 1.2811\n",
      "Epoch 2/200  Train: 1.5267  Val: 1.0608\n",
      "Epoch 3/200  Train: 1.0176  Val: 0.9874\n",
      "Epoch 4/200  Train: 1.0969  Val: 1.2588\n",
      "Epoch 5/200  Train: 0.9422  Val: 1.0344\n",
      "Epoch 6/200  Train: 1.0531  Val: 0.9103\n",
      "Epoch 7/200  Train: 1.1277  Val: 1.3481\n",
      "Epoch 8/200  Train: 1.0726  Val: 0.8003\n",
      "Epoch 9/200  Train: 0.9778  Val: 1.0396\n",
      "Epoch 10/200  Train: 0.9986  Val: 1.1043\n",
      "Epoch 11/200  Train: 1.0389  Val: 0.8882\n",
      "Epoch 12/200  Train: 1.0839  Val: 0.9467\n",
      "Epoch 13/200  Train: 0.9555  Val: 0.8097\n",
      "Epoch 14/200  Train: 0.9456  Val: 0.8760\n",
      "Epoch 15/200  Train: 0.8578  Val: 0.9016\n",
      "Epoch 16/200  Train: 0.8679  Val: 1.0563\n",
      "Epoch 17/200  Train: 0.8765  Val: 0.9127\n",
      "Epoch 18/200  Train: 0.7998  Val: 0.9602\n",
      "Epoch 19/200  Train: 0.9527  Val: 0.9727\n",
      "Epoch 20/200  Train: 0.8732  Val: 0.7999\n",
      "Epoch 21/200  Train: 0.7989  Val: 0.6706\n",
      "Epoch 22/200  Train: 0.9414  Val: 0.5853\n",
      "Epoch 23/200  Train: 0.7827  Val: 1.2917\n",
      "Epoch 24/200  Train: 0.8115  Val: 0.6235\n",
      "Epoch 25/200  Train: 0.8527  Val: 0.7125\n",
      "Epoch 26/200  Train: 0.7585  Val: 1.3201\n",
      "Epoch 27/200  Train: 0.7713  Val: 0.7442\n",
      "Epoch 28/200  Train: 0.7432  Val: 0.7474\n",
      "Epoch 29/200  Train: 0.6891  Val: 0.6431\n",
      "Epoch 30/200  Train: 0.9156  Val: 1.4103\n",
      "Epoch 31/200  Train: 0.8519  Val: 0.6821\n",
      "Epoch 32/200  Train: 0.6898  Val: 0.5597\n",
      "Epoch 33/200  Train: 0.5900  Val: 0.8543\n",
      "Epoch 34/200  Train: 0.6545  Val: 0.5720\n",
      "Epoch 35/200  Train: 0.6911  Val: 0.6399\n",
      "Epoch 36/200  Train: 0.6254  Val: 0.5620\n",
      "Epoch 37/200  Train: 0.6951  Val: 0.4636\n",
      "Epoch 38/200  Train: 0.6060  Val: 0.4515\n",
      "Epoch 39/200  Train: 0.6492  Val: 0.5490\n",
      "Epoch 40/200  Train: 0.6563  Val: 0.5734\n",
      "Epoch 41/200  Train: 0.6398  Val: 0.5096\n",
      "Epoch 42/200  Train: 0.6685  Val: 0.6272\n",
      "Epoch 43/200  Train: 0.6364  Val: 1.1302\n",
      "Epoch 44/200  Train: 0.6864  Val: 0.4982\n",
      "Epoch 45/200  Train: 0.6334  Val: 0.6247\n",
      "Epoch 46/200  Train: 0.5713  Val: 0.4817\n",
      "Epoch 47/200  Train: 0.5412  Val: 0.5694\n",
      "Epoch 48/200  Train: 0.4730  Val: 0.4351\n",
      "Epoch 49/200  Train: 0.4914  Val: 0.5567\n",
      "Epoch 50/200  Train: 0.5910  Val: 0.4776\n",
      "Epoch 51/200  Train: 0.4628  Val: 0.4240\n",
      "Epoch 52/200  Train: 0.4410  Val: 0.4150\n",
      "Epoch 53/200  Train: 0.4311  Val: 0.6103\n",
      "Epoch 54/200  Train: 0.5599  Val: 0.4975\n",
      "Epoch 55/200  Train: 0.4449  Val: 0.5172\n",
      "Epoch 56/200  Train: 0.4380  Val: 0.4699\n",
      "Epoch 57/200  Train: 0.4449  Val: 0.4031\n",
      "Epoch 58/200  Train: 0.4860  Val: 0.4543\n",
      "Epoch 59/200  Train: 0.4405  Val: 0.4098\n",
      "Epoch 60/200  Train: 0.4118  Val: 0.4098\n",
      "Epoch 61/200  Train: 0.3796  Val: 0.3125\n",
      "Epoch 62/200  Train: 0.4130  Val: 0.5529\n",
      "Epoch 63/200  Train: 0.3395  Val: 0.3542\n",
      "Epoch 64/200  Train: 0.3078  Val: 0.4006\n",
      "Epoch 65/200  Train: 0.3005  Val: 0.3571\n",
      "Epoch 66/200  Train: 0.2920  Val: 0.4053\n",
      "Epoch 67/200  Train: 0.3010  Val: 0.2409\n",
      "Epoch 68/200  Train: 0.2510  Val: 0.2975\n",
      "Epoch 69/200  Train: 0.2755  Val: 0.2234\n",
      "Epoch 70/200  Train: 0.3252  Val: 0.2097\n",
      "Epoch 71/200  Train: 0.2296  Val: 0.3857\n",
      "Epoch 72/200  Train: 0.1840  Val: 0.3277\n",
      "Epoch 73/200  Train: 0.2133  Val: 0.3478\n",
      "Epoch 74/200  Train: 0.2136  Val: 0.3365\n",
      "Epoch 75/200  Train: 0.1349  Val: 0.2249\n",
      "Epoch 76/200  Train: 0.1889  Val: 0.5458\n",
      "Epoch 77/200  Train: 0.1802  Val: 0.1420\n",
      "Epoch 78/200  Train: 0.1330  Val: 0.1009\n",
      "Epoch 79/200  Train: 0.1096  Val: 0.4422\n",
      "Epoch 80/200  Train: 0.1553  Val: 0.3181\n",
      "Epoch 81/200  Train: 0.1511  Val: 0.1683\n",
      "Epoch 82/200  Train: 0.1982  Val: 0.2207\n",
      "Epoch 83/200  Train: 0.1229  Val: 0.2898\n",
      "Epoch 84/200  Train: 0.1166  Val: 0.3880\n",
      "Epoch 85/200  Train: 0.1179  Val: 0.2051\n",
      "Epoch 86/200  Train: 0.1072  Val: 0.2402\n",
      "Epoch 87/200  Train: 0.1062  Val: 0.2706\n",
      "Epoch 88/200  Train: 0.1105  Val: 0.4411\n",
      "Epoch 89/200  Train: 0.1302  Val: 0.3139\n",
      "Epoch 90/200  Train: 0.1344  Val: 0.2076\n",
      "Epoch 91/200  Train: 0.1356  Val: 0.3772\n",
      "Epoch 92/200  Train: 0.1027  Val: 0.3172\n",
      "Epoch 93/200  Train: 0.1281  Val: 0.2448\n",
      "Epoch 94/200  Train: 0.0998  Val: 0.4457\n",
      "Epoch 95/200  Train: 0.0699  Val: 0.2834\n",
      "Epoch 96/200  Train: 0.0811  Val: 0.0892\n",
      "Epoch 97/200  Train: 0.1020  Val: 0.1776\n",
      "Epoch 98/200  Train: 0.1157  Val: 0.1854\n",
      "Epoch 99/200  Train: 0.1150  Val: 0.2754\n",
      "Epoch 100/200  Train: 0.0975  Val: 0.5559\n",
      "Epoch 101/200  Train: 0.0844  Val: 0.0957\n",
      "Epoch 102/200  Train: 0.1101  Val: 0.1174\n",
      "Epoch 103/200  Train: 0.0593  Val: 0.3800\n",
      "Epoch 104/200  Train: 0.0581  Val: 0.6065\n",
      "Epoch 105/200  Train: 0.0929  Val: 0.2149\n",
      "Epoch 106/200  Train: 0.1171  Val: 0.3535\n",
      "Epoch 107/200  Train: 0.0776  Val: 0.1714\n",
      "Epoch 108/200  Train: 0.0930  Val: 0.7796\n",
      "Epoch 109/200  Train: 0.0883  Val: 0.3379\n",
      "Epoch 110/200  Train: 0.0682  Val: 0.2856\n",
      "Epoch 111/200  Train: 0.1083  Val: 0.6783\n",
      "Epoch 112/200  Train: 0.0587  Val: 0.2582\n",
      "Epoch 113/200  Train: 0.0626  Val: 0.1148\n",
      "Epoch 114/200  Train: 0.0759  Val: 0.7382\n",
      "Epoch 115/200  Train: 0.0583  Val: 0.4777\n",
      "Epoch 116/200  Train: 0.0857  Val: 0.2814\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:17,680]\u001b[0m Trial 40 finished with value: 0.0891891673207283 and parameters: {'batch_size': 32, 'lr': 8.863691682728442e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 533, 'beta_end': 0.019199413755836905, 'dropout': 0.019768678291046712}. Best is trial 16 with value: 0.08671222105622292.\u001b[0m\n",
      "Epoch 1/200  Train: 4.5299  Val: 1.3757\n",
      "Epoch 2/200  Train: 1.4675  Val: 1.1021\n",
      "Epoch 3/200  Train: 0.9318  Val: 0.9498\n",
      "Epoch 4/200  Train: 1.0495  Val: 1.2620\n",
      "Epoch 5/200  Train: 0.9859  Val: 1.1630\n",
      "Epoch 6/200  Train: 1.1116  Val: 0.9518\n",
      "Epoch 7/200  Train: 0.9925  Val: 1.1302\n",
      "Epoch 8/200  Train: 1.0155  Val: 0.8502\n",
      "Epoch 9/200  Train: 0.9930  Val: 1.1334\n",
      "Epoch 10/200  Train: 0.9892  Val: 1.2740\n",
      "Epoch 11/200  Train: 1.1396  Val: 1.1433\n",
      "Epoch 12/200  Train: 1.2177  Val: 0.8627\n",
      "Epoch 13/200  Train: 0.9608  Val: 0.7237\n",
      "Epoch 14/200  Train: 0.9653  Val: 0.8570\n",
      "Epoch 15/200  Train: 0.8949  Val: 0.9585\n",
      "Epoch 16/200  Train: 0.9416  Val: 0.8060\n",
      "Epoch 17/200  Train: 0.8295  Val: 0.8737\n",
      "Epoch 18/200  Train: 0.8154  Val: 0.9025\n",
      "Epoch 19/200  Train: 0.8663  Val: 0.7463\n",
      "Epoch 20/200  Train: 0.8567  Val: 0.8445\n",
      "Epoch 21/200  Train: 0.8359  Val: 0.6691\n",
      "Epoch 22/200  Train: 0.9240  Val: 0.5899\n",
      "Epoch 23/200  Train: 0.7490  Val: 1.1013\n",
      "Epoch 24/200  Train: 0.8210  Val: 0.6501\n",
      "Epoch 25/200  Train: 0.9165  Val: 0.7731\n",
      "Epoch 26/200  Train: 0.8361  Val: 1.3950\n",
      "Epoch 27/200  Train: 0.8176  Val: 0.8193\n",
      "Epoch 28/200  Train: 0.8818  Val: 0.8655\n",
      "Epoch 29/200  Train: 0.6626  Val: 0.7766\n",
      "Epoch 30/200  Train: 0.7758  Val: 1.0195\n",
      "Epoch 31/200  Train: 0.7818  Val: 0.6851\n",
      "Epoch 32/200  Train: 0.6858  Val: 0.5862\n",
      "Epoch 33/200  Train: 0.6740  Val: 1.0166\n",
      "Epoch 34/200  Train: 0.6559  Val: 0.5763\n",
      "Epoch 35/200  Train: 0.6431  Val: 0.6429\n",
      "Epoch 36/200  Train: 0.6988  Val: 0.5452\n",
      "Epoch 37/200  Train: 0.7372  Val: 0.4222\n",
      "Epoch 38/200  Train: 0.5977  Val: 0.4791\n",
      "Epoch 39/200  Train: 0.6300  Val: 0.5451\n",
      "Epoch 40/200  Train: 0.6353  Val: 0.5749\n",
      "Epoch 41/200  Train: 0.6702  Val: 0.5597\n",
      "Epoch 42/200  Train: 0.6501  Val: 0.5537\n",
      "Epoch 43/200  Train: 0.6233  Val: 0.9101\n",
      "Epoch 44/200  Train: 0.7226  Val: 0.5875\n",
      "Epoch 45/200  Train: 0.5916  Val: 0.5669\n",
      "Epoch 46/200  Train: 0.5627  Val: 0.4917\n",
      "Epoch 47/200  Train: 0.5034  Val: 0.6149\n",
      "Epoch 48/200  Train: 0.4736  Val: 0.4472\n",
      "Epoch 49/200  Train: 0.4730  Val: 0.4898\n",
      "Epoch 50/200  Train: 0.5220  Val: 0.5318\n",
      "Epoch 51/200  Train: 0.4918  Val: 0.3776\n",
      "Epoch 52/200  Train: 0.4173  Val: 0.4634\n",
      "Epoch 53/200  Train: 0.3893  Val: 0.4763\n",
      "Epoch 54/200  Train: 0.4626  Val: 0.5291\n",
      "Epoch 55/200  Train: 0.3676  Val: 0.3573\n",
      "Epoch 56/200  Train: 0.4030  Val: 0.4668\n",
      "Epoch 57/200  Train: 0.2987  Val: 0.6345\n",
      "Epoch 58/200  Train: 0.3755  Val: 0.2999\n",
      "Epoch 59/200  Train: 0.3422  Val: 0.2873\n",
      "Epoch 60/200  Train: 0.3150  Val: 0.5071\n",
      "Epoch 61/200  Train: 0.2915  Val: 0.2040\n",
      "Epoch 62/200  Train: 0.2286  Val: 0.2734\n",
      "Epoch 63/200  Train: 0.2123  Val: 0.2342\n",
      "Epoch 64/200  Train: 0.2059  Val: 0.2612\n",
      "Epoch 65/200  Train: 0.1989  Val: 0.2288\n",
      "Epoch 66/200  Train: 0.1908  Val: 0.3918\n",
      "Epoch 67/200  Train: 0.2089  Val: 0.3119\n",
      "Epoch 68/200  Train: 0.1984  Val: 0.2455\n",
      "Epoch 69/200  Train: 0.1264  Val: 0.2065\n",
      "Epoch 70/200  Train: 0.1263  Val: 0.2509\n",
      "Epoch 71/200  Train: 0.1695  Val: 0.3081\n",
      "Epoch 72/200  Train: 0.1794  Val: 0.1973\n",
      "Epoch 73/200  Train: 0.1333  Val: 0.2527\n",
      "Epoch 74/200  Train: 0.1380  Val: 0.2289\n",
      "Epoch 75/200  Train: 0.1067  Val: 0.1477\n",
      "Epoch 76/200  Train: 0.1109  Val: 0.2309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200  Train: 0.1012  Val: 0.1746\n",
      "Epoch 78/200  Train: 0.1119  Val: 0.2611\n",
      "Epoch 79/200  Train: 0.1726  Val: 0.2315\n",
      "Epoch 80/200  Train: 0.1407  Val: 0.2698\n",
      "Epoch 81/200  Train: 0.0672  Val: 0.3314\n",
      "Epoch 82/200  Train: 0.1153  Val: 0.4354\n",
      "Epoch 83/200  Train: 0.0958  Val: 0.2410\n",
      "Epoch 84/200  Train: 0.1022  Val: 0.3167\n",
      "Epoch 85/200  Train: 0.0920  Val: 0.1933\n",
      "Epoch 86/200  Train: 0.1436  Val: 0.4192\n",
      "Epoch 87/200  Train: 0.1350  Val: 0.3175\n",
      "Epoch 88/200  Train: 0.0985  Val: 0.1503\n",
      "Epoch 89/200  Train: 0.1737  Val: 0.3334\n",
      "Epoch 90/200  Train: 0.1144  Val: 0.2640\n",
      "Epoch 91/200  Train: 0.0678  Val: 0.2195\n",
      "Epoch 92/200  Train: 0.0887  Val: 0.2320\n",
      "Epoch 93/200  Train: 0.0758  Val: 0.1250\n",
      "Epoch 94/200  Train: 0.1107  Val: 0.2808\n",
      "Epoch 95/200  Train: 0.1049  Val: 0.3780\n",
      "Epoch 96/200  Train: 0.0755  Val: 0.6069\n",
      "Epoch 97/200  Train: 0.0655  Val: 0.3866\n",
      "Epoch 98/200  Train: 0.0738  Val: 0.2404\n",
      "Epoch 99/200  Train: 0.0716  Val: 0.3413\n",
      "Epoch 100/200  Train: 0.0783  Val: 0.2547\n",
      "Epoch 101/200  Train: 0.0783  Val: 0.2772\n",
      "Epoch 102/200  Train: 0.0633  Val: 0.3091\n",
      "Epoch 103/200  Train: 0.0794  Val: 0.2200\n",
      "Epoch 104/200  Train: 0.0602  Val: 0.2392\n",
      "Epoch 105/200  Train: 0.0829  Val: 0.1191\n",
      "Epoch 106/200  Train: 0.1067  Val: 0.8769\n",
      "Epoch 107/200  Train: 0.0974  Val: 0.1010\n",
      "Epoch 108/200  Train: 0.0906  Val: 0.3073\n",
      "Epoch 109/200  Train: 0.0803  Val: 0.3230\n",
      "Epoch 110/200  Train: 0.0504  Val: 0.2881\n",
      "Epoch 111/200  Train: 0.0431  Val: 0.5329\n",
      "Epoch 112/200  Train: 0.0450  Val: 0.3972\n",
      "Epoch 113/200  Train: 0.0468  Val: 0.3816\n",
      "Epoch 114/200  Train: 0.0480  Val: 0.3842\n",
      "Epoch 115/200  Train: 0.0543  Val: 0.5959\n",
      "Epoch 116/200  Train: 0.0492  Val: 0.4136\n",
      "Epoch 117/200  Train: 0.0413  Val: 0.1449\n",
      "Epoch 118/200  Train: 0.0533  Val: 0.2637\n",
      "Epoch 119/200  Train: 0.0500  Val: 0.9783\n",
      "Epoch 120/200  Train: 0.0525  Val: 0.6581\n",
      "Epoch 121/200  Train: 0.0383  Val: 0.2080\n",
      "Epoch 122/200  Train: 0.0460  Val: 0.1965\n",
      "Epoch 123/200  Train: 0.0378  Val: 0.4798\n",
      "Epoch 124/200  Train: 0.0392  Val: 0.6946\n",
      "Epoch 125/200  Train: 0.0620  Val: 0.3252\n",
      "Epoch 126/200  Train: 0.0554  Val: 0.0863\n",
      "Epoch 127/200  Train: 0.0632  Val: 0.1260\n",
      "Epoch 128/200  Train: 0.0468  Val: 0.3276\n",
      "Epoch 129/200  Train: 0.0578  Val: 0.2478\n",
      "Epoch 130/200  Train: 0.0440  Val: 0.3592\n",
      "Epoch 131/200  Train: 0.0576  Val: 0.4943\n",
      "Epoch 132/200  Train: 0.0582  Val: 0.3058\n",
      "Epoch 133/200  Train: 0.0825  Val: 0.3770\n",
      "Epoch 134/200  Train: 0.0544  Val: 0.1238\n",
      "Epoch 135/200  Train: 0.0340  Val: 0.2858\n",
      "Epoch 136/200  Train: 0.0342  Val: 0.2734\n",
      "Epoch 137/200  Train: 0.0732  Val: 0.3082\n",
      "Epoch 138/200  Train: 0.0391  Val: 0.6139\n",
      "Epoch 139/200  Train: 0.0252  Val: 0.3768\n",
      "Epoch 140/200  Train: 0.0425  Val: 0.3266\n",
      "Epoch 141/200  Train: 0.0515  Val: 0.7014\n",
      "Epoch 142/200  Train: 0.0305  Val: 0.1025\n",
      "Epoch 143/200  Train: 0.0154  Val: 0.1175\n",
      "Epoch 144/200  Train: 0.0336  Val: 1.3418\n",
      "Epoch 145/200  Train: 0.0354  Val: 0.1636\n",
      "Epoch 146/200  Train: 0.0251  Val: 0.4505\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:28,883]\u001b[0m Trial 41 finished with value: 0.08633538112044334 and parameters: {'batch_size': 32, 'lr': 9.052759914986536e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 532, 'beta_end': 0.01922007818691324, 'dropout': 0.0203953812770869}. Best is trial 41 with value: 0.08633538112044334.\u001b[0m\n",
      "Epoch 1/200  Train: 4.1463  Val: 2.2318\n",
      "Epoch 2/200  Train: 1.1929  Val: 1.0065\n",
      "Epoch 3/200  Train: 0.9180  Val: 0.9997\n",
      "Epoch 4/200  Train: 1.0587  Val: 1.1719\n",
      "Epoch 5/200  Train: 0.9141  Val: 1.2100\n",
      "Epoch 6/200  Train: 1.0871  Val: 0.9369\n",
      "Epoch 7/200  Train: 1.1491  Val: 1.3950\n",
      "Epoch 8/200  Train: 1.1250  Val: 0.7693\n",
      "Epoch 9/200  Train: 1.0297  Val: 1.0763\n",
      "Epoch 10/200  Train: 1.0049  Val: 1.0872\n",
      "Epoch 11/200  Train: 1.0214  Val: 0.8719\n",
      "Epoch 12/200  Train: 1.0646  Val: 0.9174\n",
      "Epoch 13/200  Train: 0.9314  Val: 0.7921\n",
      "Epoch 14/200  Train: 0.9318  Val: 0.8520\n",
      "Epoch 15/200  Train: 0.8398  Val: 0.8749\n",
      "Epoch 16/200  Train: 0.8549  Val: 1.0339\n",
      "Epoch 17/200  Train: 0.8633  Val: 0.8895\n",
      "Epoch 18/200  Train: 0.7793  Val: 0.9406\n",
      "Epoch 19/200  Train: 0.9370  Val: 0.9620\n",
      "Epoch 20/200  Train: 0.8572  Val: 0.7854\n",
      "Epoch 21/200  Train: 0.7849  Val: 0.6600\n",
      "Epoch 22/200  Train: 0.9172  Val: 0.5701\n",
      "Epoch 23/200  Train: 0.7698  Val: 1.2745\n",
      "Epoch 24/200  Train: 0.8030  Val: 0.6139\n",
      "Epoch 25/200  Train: 0.8316  Val: 0.7096\n",
      "Epoch 26/200  Train: 0.7585  Val: 1.3041\n",
      "Epoch 27/200  Train: 0.7574  Val: 0.7211\n",
      "Epoch 28/200  Train: 0.7315  Val: 0.7207\n",
      "Epoch 29/200  Train: 0.6751  Val: 0.6264\n",
      "Epoch 30/200  Train: 0.8860  Val: 1.3421\n",
      "Epoch 31/200  Train: 0.8283  Val: 0.6644\n",
      "Epoch 32/200  Train: 0.6571  Val: 0.5429\n",
      "Epoch 33/200  Train: 0.5737  Val: 0.8237\n",
      "Epoch 34/200  Train: 0.6304  Val: 0.5892\n",
      "Epoch 35/200  Train: 0.6698  Val: 0.6296\n",
      "Epoch 36/200  Train: 0.6042  Val: 0.5260\n",
      "Epoch 37/200  Train: 0.6621  Val: 0.4408\n",
      "Epoch 38/200  Train: 0.5645  Val: 0.4320\n",
      "Epoch 39/200  Train: 0.6134  Val: 0.5052\n",
      "Epoch 40/200  Train: 0.6059  Val: 0.5590\n",
      "Epoch 41/200  Train: 0.5883  Val: 0.4981\n",
      "Epoch 42/200  Train: 0.6346  Val: 0.5929\n",
      "Epoch 43/200  Train: 0.5882  Val: 1.3314\n",
      "Epoch 44/200  Train: 0.6478  Val: 0.5582\n",
      "Epoch 45/200  Train: 0.6356  Val: 0.5658\n",
      "Epoch 46/200  Train: 0.5110  Val: 0.4065\n",
      "Epoch 47/200  Train: 0.4886  Val: 0.5344\n",
      "Epoch 48/200  Train: 0.4237  Val: 0.3532\n",
      "Epoch 49/200  Train: 0.4573  Val: 0.5350\n",
      "Epoch 50/200  Train: 0.5040  Val: 0.4444\n",
      "Epoch 51/200  Train: 0.5110  Val: 0.4260\n",
      "Epoch 52/200  Train: 0.4002  Val: 0.4088\n",
      "Epoch 53/200  Train: 0.3669  Val: 0.4061\n",
      "Epoch 54/200  Train: 0.4060  Val: 0.3922\n",
      "Epoch 55/200  Train: 0.3713  Val: 0.3795\n",
      "Epoch 56/200  Train: 0.3266  Val: 0.3251\n",
      "Epoch 57/200  Train: 0.3056  Val: 0.4488\n",
      "Epoch 58/200  Train: 0.3672  Val: 0.2531\n",
      "Epoch 59/200  Train: 0.2930  Val: 0.3543\n",
      "Epoch 60/200  Train: 0.2745  Val: 0.4978\n",
      "Epoch 61/200  Train: 0.2427  Val: 0.3772\n",
      "Epoch 62/200  Train: 0.3021  Val: 0.1693\n",
      "Epoch 63/200  Train: 0.1629  Val: 0.3489\n",
      "Epoch 64/200  Train: 0.2074  Val: 0.3608\n",
      "Epoch 65/200  Train: 0.1838  Val: 0.2112\n",
      "Epoch 66/200  Train: 0.1525  Val: 0.4834\n",
      "Epoch 67/200  Train: 0.1688  Val: 0.2118\n",
      "Epoch 68/200  Train: 0.1494  Val: 0.3155\n",
      "Epoch 69/200  Train: 0.1995  Val: 0.1115\n",
      "Epoch 70/200  Train: 0.2371  Val: 0.1541\n",
      "Epoch 71/200  Train: 0.1773  Val: 0.4459\n",
      "Epoch 72/200  Train: 0.1275  Val: 0.2739\n",
      "Epoch 73/200  Train: 0.1457  Val: 0.4004\n",
      "Epoch 74/200  Train: 0.1326  Val: 0.2060\n",
      "Epoch 75/200  Train: 0.0864  Val: 0.2997\n",
      "Epoch 76/200  Train: 0.0950  Val: 0.5016\n",
      "Epoch 77/200  Train: 0.1309  Val: 0.1097\n",
      "Epoch 78/200  Train: 0.1196  Val: 0.1019\n",
      "Epoch 79/200  Train: 0.0848  Val: 0.3880\n",
      "Epoch 80/200  Train: 0.1245  Val: 0.1737\n",
      "Epoch 81/200  Train: 0.1324  Val: 0.1810\n",
      "Epoch 82/200  Train: 0.1220  Val: 0.2864\n",
      "Epoch 83/200  Train: 0.1184  Val: 0.3344\n",
      "Epoch 84/200  Train: 0.0773  Val: 0.3706\n",
      "Epoch 85/200  Train: 0.0944  Val: 0.2627\n",
      "Epoch 86/200  Train: 0.0855  Val: 0.2623\n",
      "Epoch 87/200  Train: 0.0855  Val: 0.2351\n",
      "Epoch 88/200  Train: 0.0992  Val: 0.5825\n",
      "Epoch 89/200  Train: 0.1255  Val: 0.2328\n",
      "Epoch 90/200  Train: 0.1229  Val: 0.1056\n",
      "Epoch 91/200  Train: 0.0878  Val: 0.3202\n",
      "Epoch 92/200  Train: 0.0753  Val: 0.2676\n",
      "Epoch 93/200  Train: 0.0937  Val: 0.3079\n",
      "Epoch 94/200  Train: 0.0891  Val: 0.4353\n",
      "Epoch 95/200  Train: 0.0588  Val: 0.3073\n",
      "Epoch 96/200  Train: 0.0793  Val: 0.0700\n",
      "Epoch 97/200  Train: 0.1218  Val: 0.1603\n",
      "Epoch 98/200  Train: 0.1043  Val: 0.2469\n",
      "Epoch 99/200  Train: 0.1455  Val: 0.3208\n",
      "Epoch 100/200  Train: 0.0706  Val: 0.4896\n",
      "Epoch 101/200  Train: 0.0699  Val: 0.1004\n",
      "Epoch 102/200  Train: 0.0490  Val: 0.0949\n",
      "Epoch 103/200  Train: 0.0611  Val: 0.3124\n",
      "Epoch 104/200  Train: 0.0613  Val: 0.5300\n",
      "Epoch 105/200  Train: 0.0827  Val: 0.2330\n",
      "Epoch 106/200  Train: 0.1029  Val: 0.4000\n",
      "Epoch 107/200  Train: 0.0439  Val: 0.1044\n",
      "Epoch 108/200  Train: 0.0484  Val: 0.4950\n",
      "Epoch 109/200  Train: 0.0388  Val: 0.4085\n",
      "Epoch 110/200  Train: 0.0601  Val: 0.2405\n",
      "Epoch 111/200  Train: 0.0497  Val: 0.5567\n",
      "Epoch 112/200  Train: 0.0576  Val: 0.1779\n",
      "Epoch 113/200  Train: 0.0624  Val: 0.0950\n",
      "Epoch 114/200  Train: 0.0840  Val: 0.6125\n",
      "Epoch 115/200  Train: 0.0645  Val: 0.3906\n",
      "Epoch 116/200  Train: 0.0709  Val: 0.1820\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:37,771]\u001b[0m Trial 42 finished with value: 0.07002598345279694 and parameters: {'batch_size': 32, 'lr': 9.022756652043167e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 533, 'beta_end': 0.019387569104149138, 'dropout': 0.020581691838598468}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200  Train: 2.8917  Val: 1.8380\n",
      "Epoch 2/200  Train: 1.2425  Val: 1.0958\n",
      "Epoch 3/200  Train: 0.9706  Val: 1.0431\n",
      "Epoch 4/200  Train: 1.0748  Val: 1.2537\n",
      "Epoch 5/200  Train: 1.0335  Val: 1.4378\n",
      "Epoch 6/200  Train: 1.3323  Val: 0.9716\n",
      "Epoch 7/200  Train: 1.2760  Val: 1.4589\n",
      "Epoch 8/200  Train: 1.2692  Val: 0.8037\n",
      "Epoch 9/200  Train: 1.0512  Val: 1.0412\n",
      "Epoch 10/200  Train: 1.0047  Val: 1.2325\n",
      "Epoch 11/200  Train: 1.0952  Val: 0.9610\n",
      "Epoch 12/200  Train: 1.1351  Val: 0.9361\n",
      "Epoch 13/200  Train: 0.9124  Val: 0.7324\n",
      "Epoch 14/200  Train: 0.9631  Val: 0.8466\n",
      "Epoch 15/200  Train: 0.9145  Val: 0.9218\n",
      "Epoch 16/200  Train: 0.9606  Val: 0.7565\n",
      "Epoch 17/200  Train: 0.8335  Val: 0.8747\n",
      "Epoch 18/200  Train: 0.8298  Val: 1.0791\n",
      "Epoch 19/200  Train: 0.9348  Val: 0.8332\n",
      "Epoch 20/200  Train: 0.8705  Val: 0.8666\n",
      "Epoch 21/200  Train: 0.9008  Val: 0.7826\n",
      "Epoch 22/200  Train: 0.8527  Val: 0.5661\n",
      "Epoch 23/200  Train: 0.8344  Val: 1.4123\n",
      "Epoch 24/200  Train: 0.8962  Val: 0.6979\n",
      "Epoch 25/200  Train: 0.9022  Val: 0.7839\n",
      "Epoch 26/200  Train: 0.8642  Val: 1.1329\n",
      "Epoch 27/200  Train: 0.8257  Val: 0.7670\n",
      "Epoch 28/200  Train: 0.8249  Val: 0.7544\n",
      "Epoch 29/200  Train: 0.7411  Val: 0.7537\n",
      "Epoch 30/200  Train: 0.8250  Val: 0.8396\n",
      "Epoch 31/200  Train: 0.7453  Val: 0.8185\n",
      "Epoch 32/200  Train: 0.7557  Val: 0.6511\n",
      "Epoch 33/200  Train: 0.6510  Val: 0.9752\n",
      "Epoch 34/200  Train: 0.6707  Val: 0.5757\n",
      "Epoch 35/200  Train: 0.7319  Val: 0.8450\n",
      "Epoch 36/200  Train: 0.7352  Val: 0.6502\n",
      "Epoch 37/200  Train: 0.6714  Val: 0.4242\n",
      "Epoch 38/200  Train: 0.5991  Val: 0.5754\n",
      "Epoch 39/200  Train: 0.6871  Val: 0.6096\n",
      "Epoch 40/200  Train: 0.7297  Val: 0.6070\n",
      "Epoch 41/200  Train: 0.6550  Val: 0.5847\n",
      "Epoch 42/200  Train: 0.6815  Val: 0.5565\n",
      "Epoch 43/200  Train: 0.6361  Val: 0.5526\n",
      "Epoch 44/200  Train: 0.5933  Val: 0.5031\n",
      "Epoch 45/200  Train: 0.5223  Val: 0.5400\n",
      "Epoch 46/200  Train: 0.5768  Val: 0.6090\n",
      "Epoch 47/200  Train: 0.5665  Val: 0.6150\n",
      "Epoch 48/200  Train: 0.4981  Val: 0.4863\n",
      "Epoch 49/200  Train: 0.5476  Val: 0.4597\n",
      "Epoch 50/200  Train: 0.6292  Val: 0.4694\n",
      "Epoch 51/200  Train: 0.4871  Val: 0.5624\n",
      "Epoch 52/200  Train: 0.5057  Val: 0.5154\n",
      "Epoch 53/200  Train: 0.4161  Val: 0.6571\n",
      "Epoch 54/200  Train: 0.5928  Val: 0.4983\n",
      "Epoch 55/200  Train: 0.4463  Val: 0.5532\n",
      "Epoch 56/200  Train: 0.4671  Val: 0.5769\n",
      "Epoch 57/200  Train: 0.4803  Val: 0.4216\n",
      "Epoch 58/200  Train: 0.5046  Val: 0.5953\n",
      "Epoch 59/200  Train: 0.5451  Val: 0.4295\n",
      "Epoch 60/200  Train: 0.5364  Val: 0.3873\n",
      "Epoch 61/200  Train: 0.4001  Val: 0.3871\n",
      "Epoch 62/200  Train: 0.3451  Val: 0.6064\n",
      "Epoch 63/200  Train: 0.2916  Val: 0.4171\n",
      "Epoch 64/200  Train: 0.2745  Val: 0.2688\n",
      "Epoch 65/200  Train: 0.2501  Val: 0.2240\n",
      "Epoch 66/200  Train: 0.2716  Val: 0.2597\n",
      "Epoch 67/200  Train: 0.2393  Val: 0.3680\n",
      "Epoch 68/200  Train: 0.1986  Val: 0.1776\n",
      "Epoch 69/200  Train: 0.1613  Val: 0.2506\n",
      "Epoch 70/200  Train: 0.2403  Val: 0.1262\n",
      "Epoch 71/200  Train: 0.2274  Val: 0.4597\n",
      "Epoch 72/200  Train: 0.1677  Val: 0.2968\n",
      "Epoch 73/200  Train: 0.1645  Val: 0.2554\n",
      "Epoch 74/200  Train: 0.1453  Val: 0.2148\n",
      "Epoch 75/200  Train: 0.1188  Val: 0.2489\n",
      "Epoch 76/200  Train: 0.1294  Val: 0.1341\n",
      "Epoch 77/200  Train: 0.1106  Val: 0.3420\n",
      "Epoch 78/200  Train: 0.1280  Val: 0.1720\n",
      "Epoch 79/200  Train: 0.1124  Val: 0.0916\n",
      "Epoch 80/200  Train: 0.0791  Val: 0.1147\n",
      "Epoch 81/200  Train: 0.0795  Val: 0.3575\n",
      "Epoch 82/200  Train: 0.1096  Val: 0.1671\n",
      "Epoch 83/200  Train: 0.1750  Val: 0.2441\n",
      "Epoch 84/200  Train: 0.1043  Val: 0.1713\n",
      "Epoch 85/200  Train: 0.0975  Val: 0.0847\n",
      "Epoch 86/200  Train: 0.0869  Val: 0.1267\n",
      "Epoch 87/200  Train: 0.0947  Val: 0.1277\n",
      "Epoch 88/200  Train: 0.0837  Val: 0.5279\n",
      "Epoch 89/200  Train: 0.0847  Val: 0.1273\n",
      "Epoch 90/200  Train: 0.0814  Val: 0.2312\n",
      "Epoch 91/200  Train: 0.1032  Val: 0.3884\n",
      "Epoch 92/200  Train: 0.0900  Val: 0.4195\n",
      "Epoch 93/200  Train: 0.0649  Val: 0.1496\n",
      "Epoch 94/200  Train: 0.0696  Val: 0.2096\n",
      "Epoch 95/200  Train: 0.0766  Val: 0.3546\n",
      "Epoch 96/200  Train: 0.0665  Val: 0.3125\n",
      "Epoch 97/200  Train: 0.0685  Val: 0.1989\n",
      "Epoch 98/200  Train: 0.0664  Val: 0.1487\n",
      "Epoch 99/200  Train: 0.1158  Val: 0.3930\n",
      "Epoch 100/200  Train: 0.0727  Val: 0.2916\n",
      "Epoch 101/200  Train: 0.0581  Val: 0.4018\n",
      "Epoch 102/200  Train: 0.0724  Val: 0.3446\n",
      "Epoch 103/200  Train: 0.0860  Val: 0.1904\n",
      "Epoch 104/200  Train: 0.0697  Val: 0.2156\n",
      "Epoch 105/200  Train: 0.0654  Val: 0.2753\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:45,826]\u001b[0m Trial 43 finished with value: 0.08466166853904725 and parameters: {'batch_size': 32, 'lr': 8.369775890139917e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 535, 'beta_end': 0.019439528018505174, 'dropout': 0.02481873149933269}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/200  Train: 4.6257  Val: 2.5340\n",
      "Epoch 2/200  Train: 1.4634  Val: 0.9855\n",
      "Epoch 3/200  Train: 0.9982  Val: 1.0443\n",
      "Epoch 4/200  Train: 1.0865  Val: 1.0966\n",
      "Epoch 5/200  Train: 0.9441  Val: 1.0296\n",
      "Epoch 6/200  Train: 1.0367  Val: 1.1547\n",
      "Epoch 7/200  Train: 1.0647  Val: 0.9245\n",
      "Epoch 8/200  Train: 0.9969  Val: 0.9650\n",
      "Epoch 9/200  Train: 0.9784  Val: 0.9316\n",
      "Epoch 10/200  Train: 0.9809  Val: 1.0334\n",
      "Epoch 11/200  Train: 1.0870  Val: 0.8606\n",
      "Epoch 12/200  Train: 1.0254  Val: 0.8886\n",
      "Epoch 13/200  Train: 0.8886  Val: 0.8036\n",
      "Epoch 14/200  Train: 1.0149  Val: 0.8562\n",
      "Epoch 15/200  Train: 0.8946  Val: 0.9091\n",
      "Epoch 16/200  Train: 0.9364  Val: 0.8265\n",
      "Epoch 17/200  Train: 0.8357  Val: 0.9300\n",
      "Epoch 18/200  Train: 0.8241  Val: 0.9507\n",
      "Epoch 19/200  Train: 0.9219  Val: 0.7784\n",
      "Epoch 20/200  Train: 0.8757  Val: 0.8577\n",
      "Epoch 21/200  Train: 0.8274  Val: 0.7315\n",
      "Epoch 22/200  Train: 0.8805  Val: 0.5648\n",
      "Epoch 23/200  Train: 0.8997  Val: 1.5425\n",
      "Epoch 24/200  Train: 0.8931  Val: 0.7580\n",
      "Epoch 25/200  Train: 0.8507  Val: 0.6740\n",
      "Epoch 26/200  Train: 0.7715  Val: 0.8067\n",
      "Epoch 27/200  Train: 0.8250  Val: 0.7478\n",
      "Epoch 28/200  Train: 0.8215  Val: 0.8700\n",
      "Epoch 29/200  Train: 0.7144  Val: 0.7318\n",
      "Epoch 30/200  Train: 0.7658  Val: 0.7265\n",
      "Epoch 31/200  Train: 0.8067  Val: 0.7294\n",
      "Epoch 32/200  Train: 0.6964  Val: 0.6074\n",
      "Epoch 33/200  Train: 0.6114  Val: 0.8840\n",
      "Epoch 34/200  Train: 0.6524  Val: 0.5973\n",
      "Epoch 35/200  Train: 0.6961  Val: 0.7607\n",
      "Epoch 36/200  Train: 0.6916  Val: 0.6224\n",
      "Epoch 37/200  Train: 0.6731  Val: 0.4681\n",
      "Epoch 38/200  Train: 0.6667  Val: 0.8022\n",
      "Epoch 39/200  Train: 0.6380  Val: 0.6160\n",
      "Epoch 40/200  Train: 0.6150  Val: 0.6390\n",
      "Epoch 41/200  Train: 0.6130  Val: 0.5655\n",
      "Epoch 42/200  Train: 0.6135  Val: 0.6471\n",
      "Epoch 43/200  Train: 0.6263  Val: 0.6496\n",
      "Epoch 44/200  Train: 0.6196  Val: 0.4583\n",
      "Epoch 45/200  Train: 0.5049  Val: 0.5468\n",
      "Epoch 46/200  Train: 0.6267  Val: 0.6303\n",
      "Epoch 47/200  Train: 0.6058  Val: 0.6293\n",
      "Epoch 48/200  Train: 0.5255  Val: 0.5498\n",
      "Epoch 49/200  Train: 0.4663  Val: 0.4778\n",
      "Epoch 50/200  Train: 0.5211  Val: 0.4257\n",
      "Epoch 51/200  Train: 0.4213  Val: 0.4646\n",
      "Epoch 52/200  Train: 0.3771  Val: 0.3645\n",
      "Epoch 53/200  Train: 0.3158  Val: 0.6135\n",
      "Epoch 54/200  Train: 0.4621  Val: 0.4726\n",
      "Epoch 55/200  Train: 0.3334  Val: 0.3297\n",
      "Epoch 56/200  Train: 0.3674  Val: 0.3192\n",
      "Epoch 57/200  Train: 0.2335  Val: 0.3831\n",
      "Epoch 58/200  Train: 0.3749  Val: 0.2360\n",
      "Epoch 59/200  Train: 0.2517  Val: 0.3315\n",
      "Epoch 60/200  Train: 0.2163  Val: 0.3577\n",
      "Epoch 61/200  Train: 0.2383  Val: 0.3784\n",
      "Epoch 62/200  Train: 0.2953  Val: 0.2279\n",
      "Epoch 63/200  Train: 0.1683  Val: 0.2116\n",
      "Epoch 64/200  Train: 0.1552  Val: 0.1814\n",
      "Epoch 65/200  Train: 0.1446  Val: 0.4527\n",
      "Epoch 66/200  Train: 0.1543  Val: 0.3670\n",
      "Epoch 67/200  Train: 0.1813  Val: 0.2512\n",
      "Epoch 68/200  Train: 0.1752  Val: 0.3197\n",
      "Epoch 69/200  Train: 0.1848  Val: 0.1701\n",
      "Epoch 70/200  Train: 0.1151  Val: 0.3343\n",
      "Epoch 71/200  Train: 0.1378  Val: 0.1844\n",
      "Epoch 72/200  Train: 0.1076  Val: 0.2273\n",
      "Epoch 73/200  Train: 0.1509  Val: 0.2234\n",
      "Epoch 74/200  Train: 0.1512  Val: 0.3862\n",
      "Epoch 75/200  Train: 0.1134  Val: 0.2345\n",
      "Epoch 76/200  Train: 0.1557  Val: 0.3333\n",
      "Epoch 77/200  Train: 0.1334  Val: 0.3555\n",
      "Epoch 78/200  Train: 0.1288  Val: 0.2201\n",
      "Epoch 79/200  Train: 0.1056  Val: 0.1806\n",
      "Epoch 80/200  Train: 0.1103  Val: 0.0967\n",
      "Epoch 81/200  Train: 0.0635  Val: 0.2972\n",
      "Epoch 82/200  Train: 0.0802  Val: 0.3339\n",
      "Epoch 83/200  Train: 0.1212  Val: 0.2834\n",
      "Epoch 84/200  Train: 0.1292  Val: 0.2336\n",
      "Epoch 85/200  Train: 0.0835  Val: 0.1935\n",
      "Epoch 86/200  Train: 0.0669  Val: 0.1288\n",
      "Epoch 87/200  Train: 0.0647  Val: 0.1674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200  Train: 0.0868  Val: 0.1947\n",
      "Epoch 89/200  Train: 0.0675  Val: 0.2924\n",
      "Epoch 90/200  Train: 0.0973  Val: 0.3548\n",
      "Epoch 91/200  Train: 0.0512  Val: 0.0819\n",
      "Epoch 92/200  Train: 0.0584  Val: 0.1308\n",
      "Epoch 93/200  Train: 0.0780  Val: 0.2436\n",
      "Epoch 94/200  Train: 0.0827  Val: 0.2511\n",
      "Epoch 95/200  Train: 0.0426  Val: 0.1647\n",
      "Epoch 96/200  Train: 0.0466  Val: 0.4031\n",
      "Epoch 97/200  Train: 0.0787  Val: 0.2478\n",
      "Epoch 98/200  Train: 0.0861  Val: 0.2597\n",
      "Epoch 99/200  Train: 0.0695  Val: 0.2250\n",
      "Epoch 100/200  Train: 0.0815  Val: 0.3992\n",
      "Epoch 101/200  Train: 0.0591  Val: 0.2960\n",
      "Epoch 102/200  Train: 0.0671  Val: 0.1454\n",
      "Epoch 103/200  Train: 0.0427  Val: 0.4932\n",
      "Epoch 104/200  Train: 0.0691  Val: 0.1237\n",
      "Epoch 105/200  Train: 0.0896  Val: 0.1462\n",
      "Epoch 106/200  Train: 0.0590  Val: 0.2432\n",
      "Epoch 107/200  Train: 0.0469  Val: 0.1672\n",
      "Epoch 108/200  Train: 0.0682  Val: 0.0923\n",
      "Epoch 109/200  Train: 0.0567  Val: 0.5689\n",
      "Epoch 110/200  Train: 0.0492  Val: 0.5180\n",
      "Epoch 111/200  Train: 0.0670  Val: 0.4744\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:39:54,334]\u001b[0m Trial 44 finished with value: 0.0818699449300766 and parameters: {'batch_size': 32, 'lr': 7.840619550486156e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 534, 'beta_end': 0.019509515351104668, 'dropout': 0.025413481400420764}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/200  Train: 15.7382  Val: 4.2781\n",
      "Epoch 2/200  Train: 1.9901  Val: 1.2519\n",
      "Epoch 3/200  Train: 1.0667  Val: 1.1358\n",
      "Epoch 4/200  Train: 1.0492  Val: 1.1022\n",
      "Epoch 5/200  Train: 0.9015  Val: 0.9432\n",
      "Epoch 6/200  Train: 0.9584  Val: 0.9840\n",
      "Epoch 7/200  Train: 0.9742  Val: 0.9012\n",
      "Epoch 8/200  Train: 0.9591  Val: 0.8244\n",
      "Epoch 9/200  Train: 0.9466  Val: 0.9531\n",
      "Epoch 10/200  Train: 0.9573  Val: 1.0057\n",
      "Epoch 11/200  Train: 1.0074  Val: 0.8845\n",
      "Epoch 12/200  Train: 1.0922  Val: 0.9699\n",
      "Epoch 13/200  Train: 0.9347  Val: 0.7403\n",
      "Epoch 14/200  Train: 1.0078  Val: 0.9031\n",
      "Epoch 15/200  Train: 0.8709  Val: 1.0305\n",
      "Epoch 16/200  Train: 0.9355  Val: 0.7904\n",
      "Epoch 17/200  Train: 0.8663  Val: 0.9292\n",
      "Epoch 18/200  Train: 0.8283  Val: 0.9484\n",
      "Epoch 19/200  Train: 0.9360  Val: 0.7667\n",
      "Epoch 20/200  Train: 0.8943  Val: 0.9685\n",
      "Epoch 21/200  Train: 0.8652  Val: 0.8029\n",
      "Epoch 22/200  Train: 0.8775  Val: 0.6011\n",
      "Epoch 23/200  Train: 0.8136  Val: 1.0682\n",
      "Epoch 24/200  Train: 0.9015  Val: 0.7059\n",
      "Epoch 25/200  Train: 1.0297  Val: 0.7240\n",
      "Epoch 26/200  Train: 0.8520  Val: 0.9177\n",
      "Epoch 27/200  Train: 0.8380  Val: 0.9055\n",
      "Epoch 28/200  Train: 0.9329  Val: 0.8201\n",
      "Epoch 29/200  Train: 0.7301  Val: 0.9340\n",
      "Epoch 30/200  Train: 0.8150  Val: 0.7551\n",
      "Epoch 31/200  Train: 0.8737  Val: 0.8679\n",
      "Epoch 32/200  Train: 0.9361  Val: 0.9062\n",
      "Epoch 33/200  Train: 0.8217  Val: 1.0590\n",
      "Epoch 34/200  Train: 0.7017  Val: 0.6288\n",
      "Epoch 35/200  Train: 0.7286  Val: 0.7325\n",
      "Epoch 36/200  Train: 0.7369  Val: 0.6458\n",
      "Epoch 37/200  Train: 0.7333  Val: 0.5338\n",
      "Epoch 38/200  Train: 0.6616  Val: 0.5578\n",
      "Epoch 39/200  Train: 0.6847  Val: 0.6191\n",
      "Epoch 40/200  Train: 0.6739  Val: 0.5949\n",
      "Epoch 41/200  Train: 0.7138  Val: 0.6242\n",
      "Epoch 42/200  Train: 0.6645  Val: 0.6351\n",
      "Epoch 43/200  Train: 0.7256  Val: 0.5652\n",
      "Epoch 44/200  Train: 0.7457  Val: 0.6066\n",
      "Epoch 45/200  Train: 0.6255  Val: 0.7540\n",
      "Epoch 46/200  Train: 0.6477  Val: 0.6541\n",
      "Epoch 47/200  Train: 0.6424  Val: 0.7043\n",
      "Epoch 48/200  Train: 0.6409  Val: 0.5234\n",
      "Epoch 49/200  Train: 0.6046  Val: 0.5141\n",
      "Epoch 50/200  Train: 0.6050  Val: 0.4404\n",
      "Epoch 51/200  Train: 0.5526  Val: 0.5162\n",
      "Epoch 52/200  Train: 0.5437  Val: 0.4747\n",
      "Epoch 53/200  Train: 0.5427  Val: 0.4894\n",
      "Epoch 54/200  Train: 0.5661  Val: 0.6527\n",
      "Epoch 55/200  Train: 0.4993  Val: 0.5097\n",
      "Epoch 56/200  Train: 0.5044  Val: 0.4779\n",
      "Epoch 57/200  Train: 0.4832  Val: 0.4613\n",
      "Epoch 58/200  Train: 0.4678  Val: 0.5407\n",
      "Epoch 59/200  Train: 0.6031  Val: 0.5427\n",
      "Epoch 60/200  Train: 0.5404  Val: 0.5206\n",
      "Epoch 61/200  Train: 0.4870  Val: 0.3340\n",
      "Epoch 62/200  Train: 0.5000  Val: 0.4698\n",
      "Epoch 63/200  Train: 0.4686  Val: 0.3936\n",
      "Epoch 64/200  Train: 0.4744  Val: 0.3380\n",
      "Epoch 65/200  Train: 0.4418  Val: 0.6540\n",
      "Epoch 66/200  Train: 0.4753  Val: 0.5762\n",
      "Epoch 67/200  Train: 0.4850  Val: 0.4068\n",
      "Epoch 68/200  Train: 0.4061  Val: 0.4359\n",
      "Epoch 69/200  Train: 0.3962  Val: 0.3458\n",
      "Epoch 70/200  Train: 0.4080  Val: 0.3965\n",
      "Epoch 71/200  Train: 0.3921  Val: 0.3512\n",
      "Epoch 72/200  Train: 0.3110  Val: 0.3173\n",
      "Epoch 73/200  Train: 0.3370  Val: 0.3142\n",
      "Epoch 74/200  Train: 0.3013  Val: 0.2533\n",
      "Epoch 75/200  Train: 0.2905  Val: 0.2220\n",
      "Epoch 76/200  Train: 0.3099  Val: 0.3443\n",
      "Epoch 77/200  Train: 0.3016  Val: 0.3110\n",
      "Epoch 78/200  Train: 0.2646  Val: 0.3297\n",
      "Epoch 79/200  Train: 0.2542  Val: 0.2894\n",
      "Epoch 80/200  Train: 0.2642  Val: 0.2816\n",
      "Epoch 81/200  Train: 0.2032  Val: 0.5076\n",
      "Epoch 82/200  Train: 0.2482  Val: 0.2185\n",
      "Epoch 83/200  Train: 0.1790  Val: 0.2512\n",
      "Epoch 84/200  Train: 0.1713  Val: 0.1802\n",
      "Epoch 85/200  Train: 0.1628  Val: 0.1994\n",
      "Epoch 86/200  Train: 0.1469  Val: 0.2645\n",
      "Epoch 87/200  Train: 0.1490  Val: 0.4601\n",
      "Epoch 88/200  Train: 0.1544  Val: 0.2958\n",
      "Epoch 89/200  Train: 0.1632  Val: 0.3322\n",
      "Epoch 90/200  Train: 0.1201  Val: 0.2117\n",
      "Epoch 91/200  Train: 0.0860  Val: 0.3502\n",
      "Epoch 92/200  Train: 0.1710  Val: 0.3641\n",
      "Epoch 93/200  Train: 0.1655  Val: 0.3696\n",
      "Epoch 94/200  Train: 0.1213  Val: 0.2189\n",
      "Epoch 95/200  Train: 0.1251  Val: 0.5377\n",
      "Epoch 96/200  Train: 0.1319  Val: 0.2674\n",
      "Epoch 97/200  Train: 0.0628  Val: 0.0741\n",
      "Epoch 98/200  Train: 0.0674  Val: 0.2159\n",
      "Epoch 99/200  Train: 0.0791  Val: 0.2215\n",
      "Epoch 100/200  Train: 0.0891  Val: 0.1065\n",
      "Epoch 101/200  Train: 0.0841  Val: 0.3865\n",
      "Epoch 102/200  Train: 0.1015  Val: 0.2112\n",
      "Epoch 103/200  Train: 0.1082  Val: 0.1613\n",
      "Epoch 104/200  Train: 0.0792  Val: 0.4453\n",
      "Epoch 105/200  Train: 0.0682  Val: 0.5780\n",
      "Epoch 106/200  Train: 0.0811  Val: 0.2923\n",
      "Epoch 107/200  Train: 0.0485  Val: 0.2902\n",
      "Epoch 108/200  Train: 0.0610  Val: 0.2911\n",
      "Epoch 109/200  Train: 0.0492  Val: 0.1809\n",
      "Epoch 110/200  Train: 0.0691  Val: 0.0993\n",
      "Epoch 111/200  Train: 0.0829  Val: 0.3337\n",
      "Epoch 112/200  Train: 0.1079  Val: 0.5557\n",
      "Epoch 113/200  Train: 0.0750  Val: 0.2888\n",
      "Epoch 114/200  Train: 0.0833  Val: 0.2728\n",
      "Epoch 115/200  Train: 0.0430  Val: 0.1873\n",
      "Epoch 116/200  Train: 0.0626  Val: 0.1543\n",
      "Epoch 117/200  Train: 0.0726  Val: 0.3965\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:40:03,288]\u001b[0m Trial 45 finished with value: 0.07409305721521378 and parameters: {'batch_size': 32, 'lr': 8.067273181154678e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 544, 'beta_end': 0.019734150268181753, 'dropout': 0.025591060516039682}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/200  Train: 8.2364  Val: 5.2127\n",
      "Epoch 2/200  Train: 3.7269  Val: 3.5830\n",
      "Epoch 3/200  Train: 2.2679  Val: 2.9928\n",
      "Epoch 4/200  Train: 1.5173  Val: 2.1802\n",
      "Epoch 5/200  Train: 1.5255  Val: 1.6137\n",
      "Epoch 6/200  Train: 1.3173  Val: 1.4253\n",
      "Epoch 7/200  Train: 1.0584  Val: 1.0462\n",
      "Epoch 8/200  Train: 0.9816  Val: 1.0031\n",
      "Epoch 9/200  Train: 0.9745  Val: 0.9734\n",
      "Epoch 10/200  Train: 0.8904  Val: 1.0604\n",
      "Epoch 11/200  Train: 1.0494  Val: 0.9123\n",
      "Epoch 12/200  Train: 0.9985  Val: 0.9769\n",
      "Epoch 13/200  Train: 0.9475  Val: 1.0289\n",
      "Epoch 14/200  Train: 1.1192  Val: 1.0790\n",
      "Epoch 15/200  Train: 0.9934  Val: 1.0844\n",
      "Epoch 16/200  Train: 1.0062  Val: 1.1001\n",
      "Epoch 17/200  Train: 0.9588  Val: 0.8755\n",
      "Epoch 18/200  Train: 1.0264  Val: 0.9338\n",
      "Epoch 19/200  Train: 0.8980  Val: 1.1206\n",
      "Epoch 20/200  Train: 1.0109  Val: 1.0051\n",
      "Epoch 21/200  Train: 0.9659  Val: 0.9158\n",
      "Epoch 22/200  Train: 1.0380  Val: 0.9113\n",
      "Epoch 23/200  Train: 1.0000  Val: 0.8546\n",
      "Epoch 24/200  Train: 0.9443  Val: 1.0541\n",
      "Epoch 25/200  Train: 0.9198  Val: 1.1086\n",
      "Epoch 26/200  Train: 0.9422  Val: 0.7764\n",
      "Epoch 27/200  Train: 0.8371  Val: 1.0137\n",
      "Epoch 28/200  Train: 0.9424  Val: 1.0649\n",
      "Epoch 29/200  Train: 0.9902  Val: 0.8985\n",
      "Epoch 30/200  Train: 0.9385  Val: 0.8930\n",
      "Epoch 31/200  Train: 0.8745  Val: 0.9348\n",
      "Epoch 32/200  Train: 1.0361  Val: 0.9203\n",
      "Epoch 33/200  Train: 0.9354  Val: 1.0346\n",
      "Epoch 34/200  Train: 1.0416  Val: 0.8884\n",
      "Epoch 35/200  Train: 0.9203  Val: 0.8297\n",
      "Epoch 36/200  Train: 0.9979  Val: 0.8252\n",
      "Epoch 37/200  Train: 0.8800  Val: 0.9730\n",
      "Epoch 38/200  Train: 0.9513  Val: 0.8283\n",
      "Epoch 39/200  Train: 0.9102  Val: 0.9313\n",
      "Epoch 40/200  Train: 1.0147  Val: 0.9414\n",
      "Epoch 41/200  Train: 0.9068  Val: 1.1324\n",
      "Epoch 42/200  Train: 0.9284  Val: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200  Train: 0.8915  Val: 0.9162\n",
      "Epoch 44/200  Train: 0.8578  Val: 0.7442\n",
      "Epoch 45/200  Train: 0.9195  Val: 0.9074\n",
      "Epoch 46/200  Train: 0.8336  Val: 1.1207\n",
      "Epoch 47/200  Train: 0.8879  Val: 0.8466\n",
      "Epoch 48/200  Train: 0.9130  Val: 0.9323\n",
      "Epoch 49/200  Train: 0.8790  Val: 0.8391\n",
      "Epoch 50/200  Train: 0.9483  Val: 0.8992\n",
      "Epoch 51/200  Train: 0.7501  Val: 0.7701\n",
      "Epoch 52/200  Train: 0.8884  Val: 0.8385\n",
      "Epoch 53/200  Train: 0.8937  Val: 0.7206\n",
      "Epoch 54/200  Train: 0.9293  Val: 0.9651\n",
      "Epoch 55/200  Train: 0.8307  Val: 0.7933\n",
      "Epoch 56/200  Train: 0.8515  Val: 0.8109\n",
      "Epoch 57/200  Train: 0.8635  Val: 0.9544\n",
      "Epoch 58/200  Train: 0.8006  Val: 0.9701\n",
      "Epoch 59/200  Train: 0.8754  Val: 0.8704\n",
      "Epoch 60/200  Train: 0.7862  Val: 1.0161\n",
      "Epoch 61/200  Train: 0.8537  Val: 0.7875\n",
      "Epoch 62/200  Train: 0.9024  Val: 0.9961\n",
      "Epoch 63/200  Train: 0.8916  Val: 0.8563\n",
      "Epoch 64/200  Train: 0.8766  Val: 0.8866\n",
      "Epoch 65/200  Train: 0.8000  Val: 0.8538\n",
      "Epoch 66/200  Train: 0.8154  Val: 0.6824\n",
      "Epoch 67/200  Train: 0.8244  Val: 0.8242\n",
      "Epoch 68/200  Train: 0.9164  Val: 0.7309\n",
      "Epoch 69/200  Train: 0.8912  Val: 0.7599\n",
      "Epoch 70/200  Train: 0.9328  Val: 0.8819\n",
      "Epoch 71/200  Train: 0.8041  Val: 0.8026\n",
      "Epoch 72/200  Train: 0.7932  Val: 0.7803\n",
      "Epoch 73/200  Train: 0.8229  Val: 0.8344\n",
      "Epoch 74/200  Train: 0.9256  Val: 0.9228\n",
      "Epoch 75/200  Train: 0.7708  Val: 0.8265\n",
      "Epoch 76/200  Train: 0.8667  Val: 0.7641\n",
      "Epoch 77/200  Train: 0.8046  Val: 0.7900\n",
      "Epoch 78/200  Train: 0.7972  Val: 0.7810\n",
      "Epoch 79/200  Train: 0.8249  Val: 0.5017\n",
      "Epoch 80/200  Train: 0.8160  Val: 0.7923\n",
      "Epoch 81/200  Train: 0.8116  Val: 0.9743\n",
      "Epoch 82/200  Train: 0.7711  Val: 0.8508\n",
      "Epoch 83/200  Train: 0.7140  Val: 0.8978\n",
      "Epoch 84/200  Train: 0.8425  Val: 0.9216\n",
      "Epoch 85/200  Train: 0.8094  Val: 0.7434\n",
      "Epoch 86/200  Train: 0.8521  Val: 0.7421\n",
      "Epoch 87/200  Train: 0.7296  Val: 0.7180\n",
      "Epoch 88/200  Train: 0.6886  Val: 0.8122\n",
      "Epoch 89/200  Train: 0.7605  Val: 0.6833\n",
      "Epoch 90/200  Train: 0.7845  Val: 0.7185\n",
      "Epoch 91/200  Train: 0.7834  Val: 0.8083\n",
      "Epoch 92/200  Train: 0.7867  Val: 0.7536\n",
      "Epoch 93/200  Train: 0.7537  Val: 0.7970\n",
      "Epoch 94/200  Train: 0.7433  Val: 0.8051\n",
      "Epoch 95/200  Train: 0.7753  Val: 0.7873\n",
      "Epoch 96/200  Train: 0.7500  Val: 0.8081\n",
      "Epoch 97/200  Train: 0.8027  Val: 0.9677\n",
      "Epoch 98/200  Train: 0.8471  Val: 0.8100\n",
      "Epoch 99/200  Train: 0.8896  Val: 1.1023\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:40:05,986]\u001b[0m Trial 46 finished with value: 0.501652717590332 and parameters: {'batch_size': 128, 'lr': 8.131375223044457e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 7, 'noise_steps': 539, 'beta_end': 0.01996835373604093, 'dropout': 0.02593959780006852}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/200  Train: 1.5905  Val: 1.0789\n",
      "Epoch 2/200  Train: 0.9990  Val: 0.9577\n",
      "Epoch 3/200  Train: 0.9034  Val: 0.9928\n",
      "Epoch 4/200  Train: 1.0718  Val: 1.1115\n",
      "Epoch 5/200  Train: 0.8931  Val: 1.0136\n",
      "Epoch 6/200  Train: 1.0333  Val: 1.0779\n",
      "Epoch 7/200  Train: 1.0998  Val: 0.9601\n",
      "Epoch 8/200  Train: 1.0174  Val: 0.8828\n",
      "Epoch 9/200  Train: 0.9970  Val: 1.0153\n",
      "Epoch 10/200  Train: 1.0368  Val: 1.0387\n",
      "Epoch 11/200  Train: 1.0503  Val: 0.8173\n",
      "Epoch 12/200  Train: 1.1017  Val: 1.0047\n",
      "Epoch 13/200  Train: 0.9765  Val: 0.8553\n",
      "Epoch 14/200  Train: 1.0569  Val: 0.9539\n",
      "Epoch 15/200  Train: 0.9715  Val: 1.0617\n",
      "Epoch 16/200  Train: 0.9823  Val: 0.8462\n",
      "Epoch 17/200  Train: 0.9284  Val: 0.9799\n",
      "Epoch 18/200  Train: 0.9195  Val: 1.0428\n",
      "Epoch 19/200  Train: 1.0202  Val: 0.9087\n",
      "Epoch 20/200  Train: 1.0088  Val: 1.0570\n",
      "Epoch 21/200  Train: 0.9746  Val: 0.8665\n",
      "Epoch 22/200  Train: 0.9672  Val: 0.7157\n",
      "Epoch 23/200  Train: 0.9329  Val: 1.3998\n",
      "Epoch 24/200  Train: 0.9730  Val: 0.7987\n",
      "Epoch 25/200  Train: 1.0328  Val: 0.9453\n",
      "Epoch 26/200  Train: 0.8388  Val: 1.1081\n",
      "Epoch 27/200  Train: 0.9915  Val: 1.0709\n",
      "Epoch 28/200  Train: 0.9935  Val: 1.1168\n",
      "Epoch 29/200  Train: 0.9337  Val: 1.2767\n",
      "Epoch 30/200  Train: 1.0028  Val: 0.8582\n",
      "Epoch 31/200  Train: 1.0476  Val: 0.9715\n",
      "Epoch 32/200  Train: 0.9040  Val: 0.8612\n",
      "Epoch 33/200  Train: 0.9006  Val: 1.0327\n",
      "Epoch 34/200  Train: 0.9254  Val: 0.8752\n",
      "Epoch 35/200  Train: 0.9662  Val: 1.0475\n",
      "Epoch 36/200  Train: 1.0274  Val: 1.0049\n",
      "Epoch 37/200  Train: 1.0144  Val: 0.6958\n",
      "Epoch 38/200  Train: 0.8758  Val: 0.7023\n",
      "Epoch 39/200  Train: 0.8917  Val: 0.8162\n",
      "Epoch 40/200  Train: 0.9155  Val: 0.9166\n",
      "Epoch 41/200  Train: 0.9721  Val: 0.9260\n",
      "Epoch 42/200  Train: 0.9811  Val: 1.1164\n",
      "Epoch 43/200  Train: 0.9343  Val: 0.7985\n",
      "Epoch 44/200  Train: 0.9154  Val: 0.8674\n",
      "Epoch 45/200  Train: 0.7997  Val: 1.0765\n",
      "Epoch 46/200  Train: 0.8761  Val: 0.9133\n",
      "Epoch 47/200  Train: 0.9462  Val: 1.0954\n",
      "Epoch 48/200  Train: 1.0335  Val: 0.9359\n",
      "Epoch 49/200  Train: 0.8544  Val: 0.7982\n",
      "Epoch 50/200  Train: 1.0028  Val: 0.8903\n",
      "Epoch 51/200  Train: 0.8979  Val: 0.9036\n",
      "Epoch 52/200  Train: 0.8429  Val: 0.8510\n",
      "Epoch 53/200  Train: 0.7857  Val: 0.8755\n",
      "Epoch 54/200  Train: 0.9677  Val: 1.0156\n",
      "Epoch 55/200  Train: 0.7982  Val: 0.9599\n",
      "Epoch 56/200  Train: 0.8897  Val: 0.6949\n",
      "Epoch 57/200  Train: 0.7445  Val: 0.7310\n",
      "Epoch 58/200  Train: 0.8415  Val: 0.8682\n",
      "Epoch 59/200  Train: 0.8398  Val: 1.0310\n",
      "Epoch 60/200  Train: 0.8659  Val: 0.7472\n",
      "Epoch 61/200  Train: 0.9085  Val: 0.6879\n",
      "Epoch 62/200  Train: 0.9245  Val: 0.9651\n",
      "Epoch 63/200  Train: 0.8028  Val: 1.0101\n",
      "Epoch 64/200  Train: 0.7596  Val: 0.7341\n",
      "Epoch 65/200  Train: 0.8420  Val: 0.8455\n",
      "Epoch 66/200  Train: 0.8190  Val: 0.7034\n",
      "Epoch 67/200  Train: 0.8270  Val: 0.6925\n",
      "Epoch 68/200  Train: 0.7547  Val: 0.9347\n",
      "Epoch 69/200  Train: 0.8433  Val: 0.6832\n",
      "Epoch 70/200  Train: 0.8921  Val: 0.7717\n",
      "Epoch 71/200  Train: 0.7813  Val: 0.7557\n",
      "Epoch 72/200  Train: 0.7193  Val: 0.7692\n",
      "Epoch 73/200  Train: 0.7387  Val: 0.7878\n",
      "Epoch 74/200  Train: 0.8415  Val: 0.6292\n",
      "Epoch 75/200  Train: 0.8261  Val: 0.7613\n",
      "Epoch 76/200  Train: 0.7324  Val: 0.8334\n",
      "Epoch 77/200  Train: 0.8210  Val: 0.7682\n",
      "Epoch 78/200  Train: 0.6821  Val: 0.7248\n",
      "Epoch 79/200  Train: 0.7345  Val: 0.6760\n",
      "Epoch 80/200  Train: 0.7506  Val: 0.5747\n",
      "Epoch 81/200  Train: 0.7374  Val: 0.9499\n",
      "Epoch 82/200  Train: 0.7766  Val: 0.9905\n",
      "Epoch 83/200  Train: 0.8942  Val: 0.7011\n",
      "Epoch 84/200  Train: 0.7817  Val: 0.7695\n",
      "Epoch 85/200  Train: 0.7440  Val: 0.6442\n",
      "Epoch 86/200  Train: 0.7549  Val: 0.6696\n",
      "Epoch 87/200  Train: 0.6555  Val: 0.7870\n",
      "Epoch 88/200  Train: 0.7996  Val: 0.7322\n",
      "Epoch 89/200  Train: 0.7050  Val: 0.5902\n",
      "Epoch 90/200  Train: 0.7019  Val: 0.7487\n",
      "Epoch 91/200  Train: 0.7055  Val: 0.7412\n",
      "Epoch 92/200  Train: 0.6545  Val: 0.7525\n",
      "Epoch 93/200  Train: 0.7268  Val: 0.6726\n",
      "Epoch 94/200  Train: 0.6399  Val: 0.7186\n",
      "Epoch 95/200  Train: 0.6887  Val: 0.6713\n",
      "Epoch 96/200  Train: 0.6397  Val: 0.8324\n",
      "Epoch 97/200  Train: 0.7143  Val: 0.6336\n",
      "Epoch 98/200  Train: 0.6791  Val: 0.6211\n",
      "Epoch 99/200  Train: 0.6897  Val: 0.6906\n",
      "Epoch 100/200  Train: 0.6287  Val: 0.5436\n",
      "Epoch 101/200  Train: 0.6439  Val: 0.7388\n",
      "Epoch 102/200  Train: 0.6531  Val: 0.9055\n",
      "Epoch 103/200  Train: 0.7768  Val: 0.9530\n",
      "Epoch 104/200  Train: 0.6685  Val: 0.7468\n",
      "Epoch 105/200  Train: 0.6159  Val: 0.5999\n",
      "Epoch 106/200  Train: 0.5652  Val: 0.6107\n",
      "Epoch 107/200  Train: 0.6714  Val: 0.6851\n",
      "Epoch 108/200  Train: 0.5697  Val: 0.6747\n",
      "Epoch 109/200  Train: 0.5585  Val: 0.7769\n",
      "Epoch 110/200  Train: 0.6152  Val: 0.5286\n",
      "Epoch 111/200  Train: 0.6041  Val: 0.6068\n",
      "Epoch 112/200  Train: 0.6139  Val: 0.6395\n",
      "Epoch 113/200  Train: 0.5613  Val: 0.5317\n",
      "Epoch 114/200  Train: 0.4813  Val: 0.5479\n",
      "Epoch 115/200  Train: 0.5346  Val: 0.5361\n",
      "Epoch 116/200  Train: 0.5474  Val: 0.4593\n",
      "Epoch 117/200  Train: 0.6653  Val: 0.4248\n",
      "Epoch 118/200  Train: 0.5733  Val: 0.4650\n",
      "Epoch 119/200  Train: 0.4898  Val: 0.4750\n",
      "Epoch 120/200  Train: 0.5869  Val: 0.4824\n",
      "Epoch 121/200  Train: 0.6497  Val: 0.4631\n",
      "Epoch 122/200  Train: 0.5315  Val: 0.4525\n",
      "Epoch 123/200  Train: 0.4863  Val: 0.6450\n",
      "Epoch 124/200  Train: 0.5521  Val: 0.4445\n",
      "Epoch 125/200  Train: 0.4660  Val: 0.4042\n",
      "Epoch 126/200  Train: 0.4415  Val: 0.4306\n",
      "Epoch 127/200  Train: 0.4359  Val: 0.4366\n",
      "Epoch 128/200  Train: 0.5039  Val: 0.5181\n",
      "Epoch 129/200  Train: 0.4200  Val: 0.4335\n",
      "Epoch 130/200  Train: 0.4309  Val: 0.4194\n",
      "Epoch 131/200  Train: 0.4181  Val: 0.5686\n",
      "Epoch 132/200  Train: 0.4004  Val: 0.4260\n",
      "Epoch 133/200  Train: 0.3638  Val: 0.4198\n",
      "Epoch 134/200  Train: 0.3623  Val: 0.3504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200  Train: 0.3729  Val: 0.3972\n",
      "Epoch 136/200  Train: 0.4099  Val: 0.4913\n",
      "Epoch 137/200  Train: 0.3893  Val: 0.3480\n",
      "Epoch 138/200  Train: 0.3465  Val: 0.3890\n",
      "Epoch 139/200  Train: 0.2815  Val: 0.3248\n",
      "Epoch 140/200  Train: 0.2633  Val: 0.4507\n",
      "Epoch 141/200  Train: 0.2892  Val: 0.3121\n",
      "Epoch 142/200  Train: 0.2106  Val: 0.3036\n",
      "Epoch 143/200  Train: 0.2993  Val: 0.3683\n",
      "Epoch 144/200  Train: 0.2304  Val: 0.2898\n",
      "Epoch 145/200  Train: 0.2202  Val: 0.3644\n",
      "Epoch 146/200  Train: 0.2343  Val: 0.4891\n",
      "Epoch 147/200  Train: 0.2106  Val: 0.3010\n",
      "Epoch 148/200  Train: 0.2308  Val: 0.4140\n",
      "Epoch 149/200  Train: 0.2121  Val: 0.2880\n",
      "Epoch 150/200  Train: 0.1807  Val: 0.5564\n",
      "Epoch 151/200  Train: 0.1597  Val: 0.3367\n",
      "Epoch 152/200  Train: 0.2114  Val: 0.5164\n",
      "Epoch 153/200  Train: 0.2476  Val: 0.2935\n",
      "Epoch 154/200  Train: 0.1826  Val: 0.3538\n",
      "Epoch 155/200  Train: 0.2438  Val: 0.2575\n",
      "Epoch 156/200  Train: 0.1212  Val: 0.3375\n",
      "Epoch 157/200  Train: 0.1208  Val: 0.2807\n",
      "Epoch 158/200  Train: 0.1017  Val: 0.5223\n",
      "Epoch 159/200  Train: 0.1497  Val: 0.1794\n",
      "Epoch 160/200  Train: 0.1474  Val: 0.4696\n",
      "Epoch 161/200  Train: 0.1070  Val: 0.3336\n",
      "Epoch 162/200  Train: 0.0976  Val: 0.3136\n",
      "Epoch 163/200  Train: 0.1271  Val: 0.3129\n",
      "Epoch 164/200  Train: 0.1146  Val: 0.2613\n",
      "Epoch 165/200  Train: 0.1131  Val: 0.3564\n",
      "Epoch 166/200  Train: 0.0951  Val: 0.2333\n",
      "Epoch 167/200  Train: 0.0936  Val: 0.1855\n",
      "Epoch 168/200  Train: 0.0779  Val: 0.2571\n",
      "Epoch 169/200  Train: 0.1004  Val: 0.3170\n",
      "Epoch 170/200  Train: 0.1143  Val: 0.1366\n",
      "Epoch 171/200  Train: 0.1219  Val: 0.4310\n",
      "Epoch 172/200  Train: 0.1233  Val: 0.2782\n",
      "Epoch 173/200  Train: 0.0825  Val: 0.6448\n",
      "Epoch 174/200  Train: 0.1005  Val: 0.2779\n",
      "Epoch 175/200  Train: 0.1298  Val: 0.1665\n",
      "Epoch 176/200  Train: 0.0621  Val: 0.2272\n",
      "Epoch 177/200  Train: 0.0609  Val: 0.2317\n",
      "Epoch 178/200  Train: 0.1062  Val: 0.2042\n",
      "Epoch 179/200  Train: 0.0774  Val: 0.1339\n",
      "Epoch 180/200  Train: 0.0989  Val: 0.3374\n",
      "Epoch 181/200  Train: 0.0852  Val: 0.3590\n",
      "Epoch 182/200  Train: 0.0841  Val: 0.3995\n",
      "Epoch 183/200  Train: 0.0788  Val: 0.2283\n",
      "Epoch 184/200  Train: 0.0711  Val: 0.2684\n",
      "Epoch 185/200  Train: 0.0870  Val: 0.2605\n",
      "Epoch 186/200  Train: 0.0800  Val: 0.3725\n",
      "Epoch 187/200  Train: 0.0766  Val: 0.3846\n",
      "Epoch 188/200  Train: 0.1073  Val: 0.4097\n",
      "Epoch 189/200  Train: 0.1094  Val: 0.2942\n",
      "Epoch 190/200  Train: 0.1099  Val: 0.4500\n",
      "Epoch 191/200  Train: 0.0677  Val: 0.2336\n",
      "Epoch 192/200  Train: 0.0861  Val: 0.6068\n",
      "Epoch 193/200  Train: 0.0857  Val: 0.2895\n",
      "Epoch 194/200  Train: 0.0566  Val: 0.1334\n",
      "Epoch 195/200  Train: 0.0759  Val: 0.3988\n",
      "Epoch 196/200  Train: 0.0714  Val: 0.2481\n",
      "Epoch 197/200  Train: 0.0862  Val: 0.4094\n",
      "Epoch 198/200  Train: 0.0811  Val: 0.6226\n",
      "Epoch 199/200  Train: 0.0735  Val: 0.1726\n",
      "Epoch 200/200  Train: 0.0582  Val: 0.3786\n",
      "\u001b[32m[I 2025-06-22 16:40:21,306]\u001b[0m Trial 47 finished with value: 0.1334122583270073 and parameters: {'batch_size': 32, 'lr': 1.911576069253373e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 617, 'beta_end': 0.019545489243288718, 'dropout': 0.0218799632034226}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/200  Train: 7.8697  Val: 3.4232\n",
      "Epoch 2/200  Train: 2.1583  Val: 2.4661\n",
      "Epoch 3/200  Train: 1.5733  Val: 1.0556\n",
      "Epoch 4/200  Train: 1.0548  Val: 1.0786\n",
      "Epoch 5/200  Train: 1.0888  Val: 1.1181\n",
      "Epoch 6/200  Train: 1.1244  Val: 1.0068\n",
      "Epoch 7/200  Train: 0.9983  Val: 0.9226\n",
      "Epoch 8/200  Train: 1.0326  Val: 0.8869\n",
      "Epoch 9/200  Train: 1.0444  Val: 1.0165\n",
      "Epoch 10/200  Train: 0.9342  Val: 1.0279\n",
      "Epoch 11/200  Train: 0.9955  Val: 0.9940\n",
      "Epoch 12/200  Train: 0.9358  Val: 1.0987\n",
      "Epoch 13/200  Train: 1.0545  Val: 0.8347\n",
      "Epoch 14/200  Train: 0.9651  Val: 0.8201\n",
      "Epoch 15/200  Train: 0.9536  Val: 0.9334\n",
      "Epoch 16/200  Train: 0.9568  Val: 0.9843\n",
      "Epoch 17/200  Train: 1.0113  Val: 0.9566\n",
      "Epoch 18/200  Train: 0.9298  Val: 0.9047\n",
      "Epoch 19/200  Train: 0.9096  Val: 0.9588\n",
      "Epoch 20/200  Train: 0.9866  Val: 0.8127\n",
      "Epoch 21/200  Train: 0.8719  Val: 0.8864\n",
      "Epoch 22/200  Train: 0.9287  Val: 0.7807\n",
      "Epoch 23/200  Train: 0.9188  Val: 0.9570\n",
      "Epoch 24/200  Train: 0.9268  Val: 0.8138\n",
      "Epoch 25/200  Train: 0.9298  Val: 0.9998\n",
      "Epoch 26/200  Train: 0.9152  Val: 1.1617\n",
      "Epoch 27/200  Train: 0.9043  Val: 0.8742\n",
      "Epoch 28/200  Train: 0.7876  Val: 0.8154\n",
      "Epoch 29/200  Train: 0.8219  Val: 0.7302\n",
      "Epoch 30/200  Train: 0.9330  Val: 0.9552\n",
      "Epoch 31/200  Train: 0.8536  Val: 0.7703\n",
      "Epoch 32/200  Train: 0.8160  Val: 0.8599\n",
      "Epoch 33/200  Train: 0.7945  Val: 0.8112\n",
      "Epoch 34/200  Train: 0.8596  Val: 1.0629\n",
      "Epoch 35/200  Train: 0.9852  Val: 0.8350\n",
      "Epoch 36/200  Train: 0.8430  Val: 0.9067\n",
      "Epoch 37/200  Train: 0.8802  Val: 0.8979\n",
      "Epoch 38/200  Train: 0.9137  Val: 0.6767\n",
      "Epoch 39/200  Train: 0.8711  Val: 0.6880\n",
      "Epoch 40/200  Train: 0.8317  Val: 0.7930\n",
      "Epoch 41/200  Train: 0.8544  Val: 0.8430\n",
      "Epoch 42/200  Train: 0.7892  Val: 0.7699\n",
      "Epoch 43/200  Train: 0.8607  Val: 0.7457\n",
      "Epoch 44/200  Train: 0.7796  Val: 0.8307\n",
      "Epoch 45/200  Train: 0.8047  Val: 0.9546\n",
      "Epoch 46/200  Train: 0.7776  Val: 0.9609\n",
      "Epoch 47/200  Train: 0.7524  Val: 0.7218\n",
      "Epoch 48/200  Train: 0.8119  Val: 0.6963\n",
      "Epoch 49/200  Train: 0.7804  Val: 0.6037\n",
      "Epoch 50/200  Train: 0.7711  Val: 0.6965\n",
      "Epoch 51/200  Train: 0.7560  Val: 0.6263\n",
      "Epoch 52/200  Train: 0.7842  Val: 0.6878\n",
      "Epoch 53/200  Train: 0.7419  Val: 0.7552\n",
      "Epoch 54/200  Train: 0.7931  Val: 0.8285\n",
      "Epoch 55/200  Train: 0.6724  Val: 0.6408\n",
      "Epoch 56/200  Train: 0.7231  Val: 0.7076\n",
      "Epoch 57/200  Train: 0.6590  Val: 0.7210\n",
      "Epoch 58/200  Train: 0.7085  Val: 0.7757\n",
      "Epoch 59/200  Train: 0.7367  Val: 0.7677\n",
      "Epoch 60/200  Train: 0.7145  Val: 0.7352\n",
      "Epoch 61/200  Train: 0.7142  Val: 0.6661\n",
      "Epoch 62/200  Train: 0.7529  Val: 0.7158\n",
      "Epoch 63/200  Train: 0.6744  Val: 0.7350\n",
      "Epoch 64/200  Train: 0.6844  Val: 0.7252\n",
      "Epoch 65/200  Train: 0.6143  Val: 0.6556\n",
      "Epoch 66/200  Train: 0.6340  Val: 0.6821\n",
      "Epoch 67/200  Train: 0.7692  Val: 0.8629\n",
      "Epoch 68/200  Train: 0.8847  Val: 0.7098\n",
      "Epoch 69/200  Train: 0.7674  Val: 0.6740\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:40:24,280]\u001b[0m Trial 48 finished with value: 0.6036582350730896 and parameters: {'batch_size': 64, 'lr': 7.750377842790717e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 500, 'beta_end': 0.019509101144175946, 'dropout': 0.024638344051338926}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/200  Train: 16.3098  Val: 4.3564\n",
      "Epoch 2/200  Train: 2.0126  Val: 1.1255\n",
      "Epoch 3/200  Train: 0.9167  Val: 0.9522\n",
      "Epoch 4/200  Train: 1.0241  Val: 1.0911\n",
      "Epoch 5/200  Train: 0.8702  Val: 0.9840\n",
      "Epoch 6/200  Train: 0.9648  Val: 0.9936\n",
      "Epoch 7/200  Train: 0.9560  Val: 0.8701\n",
      "Epoch 8/200  Train: 0.9614  Val: 0.8512\n",
      "Epoch 9/200  Train: 0.9380  Val: 0.9544\n",
      "Epoch 10/200  Train: 0.9584  Val: 0.9732\n",
      "Epoch 11/200  Train: 0.9881  Val: 0.7598\n",
      "Epoch 12/200  Train: 1.0105  Val: 0.9372\n",
      "Epoch 13/200  Train: 0.9353  Val: 0.8188\n",
      "Epoch 14/200  Train: 1.0073  Val: 0.9167\n",
      "Epoch 15/200  Train: 0.8813  Val: 0.9382\n",
      "Epoch 16/200  Train: 0.9496  Val: 0.8307\n",
      "Epoch 17/200  Train: 0.8631  Val: 0.9379\n",
      "Epoch 18/200  Train: 0.8643  Val: 0.9659\n",
      "Epoch 19/200  Train: 0.9736  Val: 0.8752\n",
      "Epoch 20/200  Train: 0.9315  Val: 0.9467\n",
      "Epoch 21/200  Train: 0.8775  Val: 0.8144\n",
      "Epoch 22/200  Train: 0.8852  Val: 0.6520\n",
      "Epoch 23/200  Train: 0.8776  Val: 1.2622\n",
      "Epoch 24/200  Train: 0.8727  Val: 0.7098\n",
      "Epoch 25/200  Train: 0.9540  Val: 0.8947\n",
      "Epoch 26/200  Train: 0.7628  Val: 1.0461\n",
      "Epoch 27/200  Train: 0.8629  Val: 1.0687\n",
      "Epoch 28/200  Train: 0.9610  Val: 0.9884\n",
      "Epoch 29/200  Train: 0.7927  Val: 1.0801\n",
      "Epoch 30/200  Train: 0.8797  Val: 0.7587\n",
      "Epoch 31/200  Train: 0.8940  Val: 0.8770\n",
      "Epoch 32/200  Train: 0.7937  Val: 0.7708\n",
      "Epoch 33/200  Train: 0.7841  Val: 0.8441\n",
      "Epoch 34/200  Train: 0.8394  Val: 0.7871\n",
      "Epoch 35/200  Train: 0.8335  Val: 0.8789\n",
      "Epoch 36/200  Train: 0.8240  Val: 0.7528\n",
      "Epoch 37/200  Train: 0.8428  Val: 0.5853\n",
      "Epoch 38/200  Train: 0.7599  Val: 0.6139\n",
      "Epoch 39/200  Train: 0.8075  Val: 0.7546\n",
      "Epoch 40/200  Train: 0.7794  Val: 0.7316\n",
      "Epoch 41/200  Train: 0.8132  Val: 0.7449\n",
      "Epoch 42/200  Train: 0.7849  Val: 1.0050\n",
      "Epoch 43/200  Train: 0.7798  Val: 0.6582\n",
      "Epoch 44/200  Train: 0.7870  Val: 0.6840\n",
      "Epoch 45/200  Train: 0.7235  Val: 0.8045\n",
      "Epoch 46/200  Train: 0.7192  Val: 0.7351\n",
      "Epoch 47/200  Train: 0.7324  Val: 0.8566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200  Train: 0.7636  Val: 0.7423\n",
      "Epoch 49/200  Train: 0.7607  Val: 0.6401\n",
      "Epoch 50/200  Train: 0.7661  Val: 0.6615\n",
      "Epoch 51/200  Train: 0.6524  Val: 0.7414\n",
      "Epoch 52/200  Train: 0.6570  Val: 0.5756\n",
      "Epoch 53/200  Train: 0.6293  Val: 0.6599\n",
      "Epoch 54/200  Train: 0.6519  Val: 0.7304\n",
      "Epoch 55/200  Train: 0.5956  Val: 0.7094\n",
      "Epoch 56/200  Train: 0.6531  Val: 0.5389\n",
      "Epoch 57/200  Train: 0.5553  Val: 0.6593\n",
      "Epoch 58/200  Train: 0.6535  Val: 0.6029\n",
      "Epoch 59/200  Train: 0.6720  Val: 0.6215\n",
      "Epoch 60/200  Train: 0.6248  Val: 0.6873\n",
      "Epoch 61/200  Train: 0.6952  Val: 0.7220\n",
      "Epoch 62/200  Train: 0.7178  Val: 0.7142\n",
      "Epoch 63/200  Train: 0.6457  Val: 0.6991\n",
      "Epoch 64/200  Train: 0.6077  Val: 0.5107\n",
      "Epoch 65/200  Train: 0.6035  Val: 0.6470\n",
      "Epoch 66/200  Train: 0.6429  Val: 0.6198\n",
      "Epoch 67/200  Train: 0.6658  Val: 0.5069\n",
      "Epoch 68/200  Train: 0.5868  Val: 0.6377\n",
      "Epoch 69/200  Train: 0.6190  Val: 0.5099\n",
      "Epoch 70/200  Train: 0.6144  Val: 0.6247\n",
      "Epoch 71/200  Train: 0.5716  Val: 0.4992\n",
      "Epoch 72/200  Train: 0.4959  Val: 0.5377\n",
      "Epoch 73/200  Train: 0.5630  Val: 0.6161\n",
      "Epoch 74/200  Train: 0.6851  Val: 0.7192\n",
      "Epoch 75/200  Train: 0.5569  Val: 0.4331\n",
      "Epoch 76/200  Train: 0.4896  Val: 0.5787\n",
      "Epoch 77/200  Train: 0.5179  Val: 0.5945\n",
      "Epoch 78/200  Train: 0.4645  Val: 0.5538\n",
      "Epoch 79/200  Train: 0.4891  Val: 0.4401\n",
      "Epoch 80/200  Train: 0.4776  Val: 0.3701\n",
      "Epoch 81/200  Train: 0.4813  Val: 0.5284\n",
      "Epoch 82/200  Train: 0.4577  Val: 0.4426\n",
      "Epoch 83/200  Train: 0.4562  Val: 0.4415\n",
      "Epoch 84/200  Train: 0.4441  Val: 0.3828\n",
      "Epoch 85/200  Train: 0.5151  Val: 0.5470\n",
      "Epoch 86/200  Train: 0.3939  Val: 0.3625\n",
      "Epoch 87/200  Train: 0.4044  Val: 0.4596\n",
      "Epoch 88/200  Train: 0.4120  Val: 0.5973\n",
      "Epoch 89/200  Train: 0.4512  Val: 0.3846\n",
      "Epoch 90/200  Train: 0.3538  Val: 0.5171\n",
      "Epoch 91/200  Train: 0.3891  Val: 0.3107\n",
      "Epoch 92/200  Train: 0.4189  Val: 0.4525\n",
      "Epoch 93/200  Train: 0.3493  Val: 0.4607\n",
      "Epoch 94/200  Train: 0.3312  Val: 0.4402\n",
      "Epoch 95/200  Train: 0.3330  Val: 0.2539\n",
      "Epoch 96/200  Train: 0.2935  Val: 0.3981\n",
      "Epoch 97/200  Train: 0.4027  Val: 0.5253\n",
      "Epoch 98/200  Train: 0.3099  Val: 0.3737\n",
      "Epoch 99/200  Train: 0.2869  Val: 0.2610\n",
      "Epoch 100/200  Train: 0.2248  Val: 0.1816\n",
      "Epoch 101/200  Train: 0.2469  Val: 0.4199\n",
      "Epoch 102/200  Train: 0.2109  Val: 0.2194\n",
      "Epoch 103/200  Train: 0.1950  Val: 0.2265\n",
      "Epoch 104/200  Train: 0.1506  Val: 0.2236\n",
      "Epoch 105/200  Train: 0.2063  Val: 0.4782\n",
      "Epoch 106/200  Train: 0.2634  Val: 0.2746\n",
      "Epoch 107/200  Train: 0.1386  Val: 0.2252\n",
      "Epoch 108/200  Train: 0.1418  Val: 0.2903\n",
      "Epoch 109/200  Train: 0.1264  Val: 0.1520\n",
      "Epoch 110/200  Train: 0.1269  Val: 0.3965\n",
      "Epoch 111/200  Train: 0.1533  Val: 0.1684\n",
      "Epoch 112/200  Train: 0.1984  Val: 0.3031\n",
      "Epoch 113/200  Train: 0.1280  Val: 0.3024\n",
      "Epoch 114/200  Train: 0.0923  Val: 0.1238\n",
      "Epoch 115/200  Train: 0.2241  Val: 0.3542\n",
      "Epoch 116/200  Train: 0.1142  Val: 0.3697\n",
      "Epoch 117/200  Train: 0.1460  Val: 0.2236\n",
      "Epoch 118/200  Train: 0.1091  Val: 0.2049\n",
      "Epoch 119/200  Train: 0.0813  Val: 0.3196\n",
      "Epoch 120/200  Train: 0.1306  Val: 0.3147\n",
      "Epoch 121/200  Train: 0.0983  Val: 0.0998\n",
      "Epoch 122/200  Train: 0.1142  Val: 0.2193\n",
      "Epoch 123/200  Train: 0.0884  Val: 0.1227\n",
      "Epoch 124/200  Train: 0.0822  Val: 0.1977\n",
      "Epoch 125/200  Train: 0.1340  Val: 0.3460\n",
      "Epoch 126/200  Train: 0.1083  Val: 0.3669\n",
      "Epoch 127/200  Train: 0.0499  Val: 0.3678\n",
      "Epoch 128/200  Train: 0.0761  Val: 0.3503\n",
      "Epoch 129/200  Train: 0.0742  Val: 0.2916\n",
      "Epoch 130/200  Train: 0.0880  Val: 0.1322\n",
      "Epoch 131/200  Train: 0.0768  Val: 0.5870\n",
      "Epoch 132/200  Train: 0.0946  Val: 0.1608\n",
      "Epoch 133/200  Train: 0.0792  Val: 0.3035\n",
      "Epoch 134/200  Train: 0.0646  Val: 0.1167\n",
      "Epoch 135/200  Train: 0.0654  Val: 0.4316\n",
      "Epoch 136/200  Train: 0.0558  Val: 0.4000\n",
      "Epoch 137/200  Train: 0.0812  Val: 0.3000\n",
      "Epoch 138/200  Train: 0.0964  Val: 0.4658\n",
      "Epoch 139/200  Train: 0.0839  Val: 0.2540\n",
      "Epoch 140/200  Train: 0.0524  Val: 0.2152\n",
      "Epoch 141/200  Train: 0.0654  Val: 0.2139\n",
      "Early stopping.\n",
      "\u001b[32m[I 2025-06-22 16:40:35,065]\u001b[0m Trial 49 finished with value: 0.09980519711971284 and parameters: {'batch_size': 32, 'lr': 5.1576266588724005e-05, 'hidden_dim': 512, 'time_embed_dim': 64, 'layers': 6, 'noise_steps': 549, 'beta_end': 0.01889183006216342, 'dropout': 0.030751802480224404}. Best is trial 42 with value: 0.07002598345279694.\u001b[0m\n",
      "Epoch 1/1000  Train: 4.9763  Val: 2.9083\n",
      "Epoch 2/1000  Train: 1.6451  Val: 1.1430\n",
      "Epoch 3/1000  Train: 1.0060  Val: 1.0847\n",
      "Epoch 4/1000  Train: 1.0789  Val: 1.1201\n",
      "Epoch 5/1000  Train: 0.8962  Val: 0.9805\n",
      "Epoch 6/1000  Train: 0.9989  Val: 0.9555\n",
      "Epoch 7/1000  Train: 1.1949  Val: 0.9973\n",
      "Epoch 8/1000  Train: 1.0083  Val: 0.8130\n",
      "Epoch 9/1000  Train: 0.9696  Val: 1.0531\n",
      "Epoch 10/1000  Train: 1.0485  Val: 1.1943\n",
      "Epoch 11/1000  Train: 1.2189  Val: 0.8005\n",
      "Epoch 12/1000  Train: 1.0280  Val: 0.8406\n",
      "Epoch 13/1000  Train: 0.9258  Val: 0.8190\n",
      "Epoch 14/1000  Train: 1.0207  Val: 0.8649\n",
      "Epoch 15/1000  Train: 0.8553  Val: 0.8468\n",
      "Epoch 16/1000  Train: 0.8756  Val: 1.0028\n",
      "Epoch 17/1000  Train: 0.8586  Val: 0.9156\n",
      "Epoch 18/1000  Train: 0.8077  Val: 0.9565\n",
      "Epoch 19/1000  Train: 0.9609  Val: 0.9213\n",
      "Epoch 20/1000  Train: 0.8947  Val: 0.8633\n",
      "Epoch 21/1000  Train: 0.8331  Val: 0.6976\n",
      "Epoch 22/1000  Train: 0.9224  Val: 0.5623\n",
      "Epoch 23/1000  Train: 0.7601  Val: 1.1061\n",
      "Epoch 24/1000  Train: 0.8492  Val: 0.6123\n",
      "Epoch 25/1000  Train: 0.8455  Val: 0.8138\n",
      "Epoch 26/1000  Train: 0.8910  Val: 1.5698\n",
      "Epoch 27/1000  Train: 0.8818  Val: 0.7357\n",
      "Epoch 28/1000  Train: 0.7399  Val: 0.7373\n",
      "Epoch 29/1000  Train: 0.6587  Val: 0.6938\n",
      "Epoch 30/1000  Train: 0.9028  Val: 1.3481\n",
      "Epoch 31/1000  Train: 0.8223  Val: 0.7237\n",
      "Epoch 32/1000  Train: 0.7203  Val: 0.6133\n",
      "Epoch 33/1000  Train: 0.6513  Val: 1.0139\n",
      "Epoch 34/1000  Train: 0.7104  Val: 0.5571\n",
      "Epoch 35/1000  Train: 0.7312  Val: 0.6699\n",
      "Epoch 36/1000  Train: 0.6549  Val: 0.5748\n",
      "Epoch 37/1000  Train: 0.7151  Val: 0.4910\n",
      "Epoch 38/1000  Train: 0.6370  Val: 0.4569\n",
      "Epoch 39/1000  Train: 0.6602  Val: 0.5703\n",
      "Epoch 40/1000  Train: 0.6811  Val: 0.5697\n",
      "Epoch 41/1000  Train: 0.6373  Val: 0.5087\n",
      "Epoch 42/1000  Train: 0.6383  Val: 0.5982\n",
      "Epoch 43/1000  Train: 0.6001  Val: 1.1071\n",
      "Epoch 44/1000  Train: 0.6582  Val: 0.5134\n",
      "Epoch 45/1000  Train: 0.6023  Val: 0.5884\n",
      "Epoch 46/1000  Train: 0.5868  Val: 0.4732\n",
      "Epoch 47/1000  Train: 0.5548  Val: 0.5784\n",
      "Epoch 48/1000  Train: 0.4919  Val: 0.4636\n",
      "Epoch 49/1000  Train: 0.4666  Val: 0.5383\n",
      "Epoch 50/1000  Train: 0.5419  Val: 0.4553\n",
      "Epoch 51/1000  Train: 0.4165  Val: 0.4210\n",
      "Epoch 52/1000  Train: 0.3979  Val: 0.4645\n",
      "Epoch 53/1000  Train: 0.3916  Val: 0.4033\n",
      "Epoch 54/1000  Train: 0.4255  Val: 0.3909\n",
      "Epoch 55/1000  Train: 0.3844  Val: 0.4208\n",
      "Epoch 56/1000  Train: 0.3297  Val: 0.3572\n",
      "Epoch 57/1000  Train: 0.3430  Val: 0.4662\n",
      "Epoch 58/1000  Train: 0.3886  Val: 0.2638\n",
      "Epoch 59/1000  Train: 0.3313  Val: 0.3415\n",
      "Epoch 60/1000  Train: 0.2900  Val: 0.4622\n",
      "Epoch 61/1000  Train: 0.2511  Val: 0.4617\n",
      "Epoch 62/1000  Train: 0.3311  Val: 0.1715\n",
      "Epoch 63/1000  Train: 0.1812  Val: 0.2729\n",
      "Epoch 64/1000  Train: 0.2005  Val: 0.3232\n",
      "Epoch 65/1000  Train: 0.1808  Val: 0.2309\n",
      "Epoch 66/1000  Train: 0.1600  Val: 0.2725\n",
      "Epoch 67/1000  Train: 0.1612  Val: 0.1576\n",
      "Epoch 68/1000  Train: 0.1804  Val: 0.3641\n",
      "Epoch 69/1000  Train: 0.2522  Val: 0.2146\n",
      "Epoch 70/1000  Train: 0.2810  Val: 0.2315\n",
      "Epoch 71/1000  Train: 0.1703  Val: 0.3645\n",
      "Epoch 72/1000  Train: 0.0962  Val: 0.2778\n",
      "Epoch 73/1000  Train: 0.1225  Val: 0.3653\n",
      "Epoch 74/1000  Train: 0.1116  Val: 0.1865\n",
      "Epoch 75/1000  Train: 0.0890  Val: 0.3248\n",
      "Epoch 76/1000  Train: 0.1128  Val: 0.4325\n",
      "Epoch 77/1000  Train: 0.1136  Val: 0.0890\n",
      "Epoch 78/1000  Train: 0.0886  Val: 0.0766\n",
      "Epoch 79/1000  Train: 0.0610  Val: 0.3520\n",
      "Epoch 80/1000  Train: 0.1506  Val: 0.2824\n",
      "Epoch 81/1000  Train: 0.1866  Val: 0.3114\n",
      "Epoch 82/1000  Train: 0.1950  Val: 0.2476\n",
      "Epoch 83/1000  Train: 0.1114  Val: 0.2459\n",
      "Epoch 84/1000  Train: 0.0932  Val: 0.3978\n",
      "Epoch 85/1000  Train: 0.0795  Val: 0.2678\n",
      "Epoch 86/1000  Train: 0.0873  Val: 0.2620\n",
      "Epoch 87/1000  Train: 0.0968  Val: 0.1997\n",
      "Epoch 88/1000  Train: 0.0747  Val: 0.4915\n",
      "Epoch 89/1000  Train: 0.1050  Val: 0.3055\n",
      "Epoch 90/1000  Train: 0.0793  Val: 0.0906\n",
      "Epoch 91/1000  Train: 0.0829  Val: 0.3664\n",
      "Epoch 92/1000  Train: 0.0518  Val: 0.2550\n",
      "Epoch 93/1000  Train: 0.0772  Val: 0.3351\n",
      "Epoch 94/1000  Train: 0.0975  Val: 0.3999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000  Train: 0.0492  Val: 0.2923\n",
      "Epoch 96/1000  Train: 0.0639  Val: 0.0871\n",
      "Epoch 97/1000  Train: 0.0648  Val: 0.2414\n",
      "Epoch 98/1000  Train: 0.0692  Val: 0.3184\n",
      "Epoch 99/1000  Train: 0.0655  Val: 0.2828\n",
      "Epoch 100/1000  Train: 0.0574  Val: 0.5145\n",
      "Epoch 101/1000  Train: 0.0711  Val: 0.0900\n",
      "Epoch 102/1000  Train: 0.0568  Val: 0.0992\n",
      "Epoch 103/1000  Train: 0.0499  Val: 0.2556\n",
      "Epoch 104/1000  Train: 0.0496  Val: 0.6185\n",
      "Epoch 105/1000  Train: 0.0777  Val: 0.2581\n",
      "Epoch 106/1000  Train: 0.1398  Val: 0.5518\n",
      "Epoch 107/1000  Train: 0.0909  Val: 0.1674\n",
      "Epoch 108/1000  Train: 0.0655  Val: 0.5829\n",
      "Epoch 109/1000  Train: 0.0370  Val: 0.3979\n",
      "Epoch 110/1000  Train: 0.0437  Val: 0.2889\n",
      "Epoch 111/1000  Train: 0.0454  Val: 0.5999\n",
      "Epoch 112/1000  Train: 0.0470  Val: 0.2186\n",
      "Epoch 113/1000  Train: 0.0803  Val: 0.0978\n",
      "Epoch 114/1000  Train: 0.1250  Val: 0.7462\n",
      "Epoch 115/1000  Train: 0.0746  Val: 0.4580\n",
      "Epoch 116/1000  Train: 0.0860  Val: 0.2661\n",
      "Epoch 117/1000  Train: 0.0866  Val: 0.4353\n",
      "Epoch 118/1000  Train: 0.0660  Val: 0.1077\n",
      "Epoch 119/1000  Train: 0.0595  Val: 0.4348\n",
      "Epoch 120/1000  Train: 0.0496  Val: 0.4054\n",
      "Epoch 121/1000  Train: 0.0427  Val: 0.1404\n",
      "Epoch 122/1000  Train: 0.0374  Val: 0.1844\n",
      "Epoch 123/1000  Train: 0.0469  Val: 0.1161\n",
      "Epoch 124/1000  Train: 0.0468  Val: 0.5172\n",
      "Epoch 125/1000  Train: 0.0679  Val: 0.6640\n",
      "Epoch 126/1000  Train: 0.0766  Val: 0.1437\n",
      "Epoch 127/1000  Train: 0.0674  Val: 0.4874\n",
      "Epoch 128/1000  Train: 0.0510  Val: 0.4702\n",
      "Epoch 129/1000  Train: 0.0597  Val: 0.3125\n",
      "Epoch 130/1000  Train: 0.0430  Val: 0.1781\n",
      "Epoch 131/1000  Train: 0.0652  Val: 0.3288\n",
      "Epoch 132/1000  Train: 0.0447  Val: 0.2339\n",
      "Epoch 133/1000  Train: 0.0347  Val: 0.3718\n",
      "Epoch 134/1000  Train: 0.0490  Val: 0.2621\n",
      "Epoch 135/1000  Train: 0.0603  Val: 0.1403\n",
      "Epoch 136/1000  Train: 0.0593  Val: 0.1441\n",
      "Epoch 137/1000  Train: 0.0282  Val: 0.3204\n",
      "Epoch 138/1000  Train: 0.0368  Val: 0.0978\n",
      "Epoch 139/1000  Train: 0.0281  Val: 0.1231\n",
      "Epoch 140/1000  Train: 0.0448  Val: 0.1234\n",
      "Epoch 141/1000  Train: 0.0272  Val: 0.3597\n",
      "Epoch 142/1000  Train: 0.0402  Val: 0.4925\n",
      "Epoch 143/1000  Train: 0.0678  Val: 0.8222\n",
      "Epoch 144/1000  Train: 0.0670  Val: 0.7977\n",
      "Epoch 145/1000  Train: 0.1189  Val: 0.6919\n",
      "Epoch 146/1000  Train: 0.0710  Val: 0.1387\n",
      "Epoch 147/1000  Train: 0.0637  Val: 0.1835\n",
      "Epoch 148/1000  Train: 0.0512  Val: 0.2985\n",
      "Epoch 149/1000  Train: 0.0434  Val: 0.3286\n",
      "Epoch 150/1000  Train: 0.0329  Val: 0.2600\n",
      "Epoch 151/1000  Train: 0.0326  Val: 0.0606\n",
      "Epoch 152/1000  Train: 0.0528  Val: 0.2657\n",
      "Epoch 153/1000  Train: 0.0515  Val: 0.5912\n",
      "Epoch 154/1000  Train: 0.0600  Val: 0.1705\n",
      "Epoch 155/1000  Train: 0.0453  Val: 0.3689\n",
      "Epoch 156/1000  Train: 0.0287  Val: 0.2764\n",
      "Epoch 157/1000  Train: 0.0587  Val: 0.1205\n",
      "Epoch 158/1000  Train: 0.0410  Val: 0.5302\n",
      "Epoch 159/1000  Train: 0.0290  Val: 0.4219\n",
      "Epoch 160/1000  Train: 0.0278  Val: 0.2558\n",
      "Epoch 161/1000  Train: 0.0376  Val: 0.1660\n",
      "Epoch 162/1000  Train: 0.0539  Val: 0.3791\n",
      "Epoch 163/1000  Train: 0.0378  Val: 0.1460\n",
      "Epoch 164/1000  Train: 0.0351  Val: 0.4170\n",
      "Epoch 165/1000  Train: 0.0251  Val: 0.2278\n",
      "Epoch 166/1000  Train: 0.0458  Val: 0.7125\n",
      "Epoch 167/1000  Train: 0.0474  Val: 0.1638\n",
      "Epoch 168/1000  Train: 0.0225  Val: 0.5257\n",
      "Epoch 169/1000  Train: 0.0583  Val: 0.5338\n",
      "Epoch 170/1000  Train: 0.0447  Val: 0.2234\n",
      "Epoch 171/1000  Train: 0.0584  Val: 0.3643\n",
      "Epoch 172/1000  Train: 0.0306  Val: 0.4473\n",
      "Epoch 173/1000  Train: 0.0533  Val: 0.6222\n",
      "Epoch 174/1000  Train: 0.0335  Val: 0.3837\n",
      "Epoch 175/1000  Train: 0.0437  Val: 0.2988\n",
      "Epoch 176/1000  Train: 0.0313  Val: 0.2656\n",
      "Epoch 177/1000  Train: 0.0402  Val: 0.7163\n",
      "Epoch 178/1000  Train: 0.0285  Val: 0.6462\n",
      "Epoch 179/1000  Train: 0.1302  Val: 0.2826\n",
      "Epoch 180/1000  Train: 0.1037  Val: 0.2002\n",
      "Epoch 181/1000  Train: 0.0415  Val: 0.2871\n",
      "Epoch 182/1000  Train: 0.0394  Val: 0.3351\n",
      "Epoch 183/1000  Train: 0.0689  Val: 0.2169\n",
      "Epoch 184/1000  Train: 0.0466  Val: 0.1622\n",
      "Epoch 185/1000  Train: 0.0552  Val: 0.2976\n",
      "Epoch 186/1000  Train: 0.0550  Val: 0.2190\n",
      "Epoch 187/1000  Train: 0.0300  Val: 0.2728\n",
      "Epoch 188/1000  Train: 0.0294  Val: 0.5832\n",
      "Epoch 189/1000  Train: 0.0344  Val: 0.0893\n",
      "Epoch 190/1000  Train: 0.0420  Val: 0.5807\n",
      "Epoch 191/1000  Train: 0.0614  Val: 0.1226\n",
      "Epoch 192/1000  Train: 0.0420  Val: 0.1936\n",
      "Epoch 193/1000  Train: 0.0270  Val: 0.4289\n",
      "Epoch 194/1000  Train: 0.0275  Val: 0.2181\n",
      "Epoch 195/1000  Train: 0.0405  Val: 0.1984\n",
      "Epoch 196/1000  Train: 0.0288  Val: 0.4398\n",
      "Epoch 197/1000  Train: 0.0275  Val: 0.3021\n",
      "Epoch 198/1000  Train: 0.0350  Val: 0.2361\n",
      "Epoch 199/1000  Train: 0.0397  Val: 0.3504\n",
      "Epoch 200/1000  Train: 0.0669  Val: 0.3328\n",
      "Epoch 201/1000  Train: 0.0291  Val: 0.3025\n",
      "Epoch 202/1000  Train: 0.0273  Val: 0.2173\n",
      "Epoch 203/1000  Train: 0.0339  Val: 0.0852\n",
      "Epoch 204/1000  Train: 0.0585  Val: 0.3080\n",
      "Epoch 205/1000  Train: 0.0427  Val: 0.0734\n",
      "Epoch 206/1000  Train: 0.0470  Val: 0.2113\n",
      "Epoch 207/1000  Train: 0.0493  Val: 0.2373\n",
      "Epoch 208/1000  Train: 0.0469  Val: 0.2912\n",
      "Epoch 209/1000  Train: 0.0486  Val: 0.4928\n",
      "Epoch 210/1000  Train: 0.0314  Val: 0.0947\n",
      "Epoch 211/1000  Train: 0.0338  Val: 0.5571\n",
      "Epoch 212/1000  Train: 0.0520  Val: 0.1742\n",
      "Epoch 213/1000  Train: 0.0353  Val: 0.2055\n",
      "Epoch 214/1000  Train: 0.0240  Val: 0.1400\n",
      "Epoch 215/1000  Train: 0.0181  Val: 0.1340\n",
      "Epoch 216/1000  Train: 0.0241  Val: 0.7194\n",
      "Epoch 217/1000  Train: 0.0241  Val: 0.4011\n",
      "Epoch 218/1000  Train: 0.0292  Val: 0.3082\n",
      "Epoch 219/1000  Train: 0.0290  Val: 0.3962\n",
      "Epoch 220/1000  Train: 0.0301  Val: 0.2383\n",
      "Epoch 221/1000  Train: 0.0344  Val: 0.2214\n",
      "Epoch 222/1000  Train: 0.0166  Val: 0.1046\n",
      "Epoch 223/1000  Train: 0.0287  Val: 0.1819\n",
      "Epoch 224/1000  Train: 0.0328  Val: 0.2445\n",
      "Epoch 225/1000  Train: 0.0368  Val: 0.0882\n",
      "Epoch 226/1000  Train: 0.0275  Val: 0.3541\n",
      "Epoch 227/1000  Train: 0.0236  Val: 0.3973\n",
      "Epoch 228/1000  Train: 0.0282  Val: 0.4718\n",
      "Epoch 229/1000  Train: 0.0198  Val: 0.4289\n",
      "Epoch 230/1000  Train: 0.0368  Val: 0.6712\n",
      "Epoch 231/1000  Train: 0.0132  Val: 0.4085\n",
      "Epoch 232/1000  Train: 0.0222  Val: 0.5487\n",
      "Epoch 233/1000  Train: 0.0150  Val: 0.3560\n",
      "Epoch 234/1000  Train: 0.0352  Val: 0.3446\n",
      "Epoch 235/1000  Train: 0.0198  Val: 0.1876\n",
      "Epoch 236/1000  Train: 0.0288  Val: 0.2296\n",
      "Epoch 237/1000  Train: 0.0226  Val: 0.5149\n",
      "Epoch 238/1000  Train: 0.0224  Val: 0.4519\n",
      "Epoch 239/1000  Train: 0.0158  Val: 0.3641\n",
      "Epoch 240/1000  Train: 0.0150  Val: 0.3693\n",
      "Epoch 241/1000  Train: 0.0415  Val: 0.4304\n",
      "Epoch 242/1000  Train: 0.0259  Val: 0.1068\n",
      "Epoch 243/1000  Train: 0.0282  Val: 0.2880\n",
      "Epoch 244/1000  Train: 0.0350  Val: 0.1040\n",
      "Epoch 245/1000  Train: 0.0218  Val: 0.3295\n",
      "Epoch 246/1000  Train: 0.0245  Val: 0.3404\n",
      "Epoch 247/1000  Train: 0.0424  Val: 0.3029\n",
      "Epoch 248/1000  Train: 0.0321  Val: 0.4356\n",
      "Epoch 249/1000  Train: 0.0351  Val: 0.2401\n",
      "Epoch 250/1000  Train: 0.0266  Val: 0.1457\n",
      "Epoch 251/1000  Train: 0.0247  Val: 0.5407\n",
      "Early stopping.\n",
      "Metrics saved to outputs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "script = 'main.py'\n",
    "args   = [\n",
    "    \"--data_dir\",   'data/shopee', # datapath\n",
    "    \"--seed\",       \"555\",\n",
    "    \"--hpo_trials\", \"50\",\n",
    "    \"--output_dir\", \"outputs\"\n",
    "]\n",
    "\n",
    "# this shells out to the same python that’s powering your notebook\n",
    "!{sys.executable} {script} {' '.join(args)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9937a953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ag_score\": {\n",
      "    \"accuracy\": 0.8875\n",
      "  },\n",
      "  \"accuracy\": 0.9125\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Path to your metrics file\n",
    "metrics_path = os.path.join(\"outputs\", \"metrics.json\")\n",
    "\n",
    "# Read and print\n",
    "with open(metrics_path, \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(json.dumps(metrics, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (mypy39)",
   "language": "python",
   "name": "mypy39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
